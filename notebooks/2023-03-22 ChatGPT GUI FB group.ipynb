{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"credentials.json\") as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "ig_user_id = credentials['am_ig_user_id']\n",
    "# access_token = credentials['am_ig_access_token']\n",
    "# group_id = credentials['STEMM_group_id']\n",
    "access_token = credentials['am_fb_access_token']\n",
    "group_id = credentials['SSC_group_id']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1\n",
    "## Prompt 1\n",
    "Create a python function that will make a GET request to pull the posts from a Facebook group using the Facebook API. Output the results into a DataFrame so that each post is a row along with its time stamp, message, permalink, and comments. Also output the response.json(). Include parameters for number of posts.\n",
    "\n",
    "### Response\n",
    "To make a GET request to pull posts from a Facebook group, you will need to use the Facebook Graph API. You will also need an access token with the appropriate permissions to access the group's content. Here is a Python function that uses the requests library to make the API request and outputs the results into a pandas DataFrame:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message, permalink, and comments.\n",
    "    Also outputs the response.json().\n",
    "    \n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        posts.append({\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"permalink_url\": permalink_url,\n",
    "            \"comments_count\": comments_count\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    return df, data\n",
    "```\n",
    "This function takes in three parameters:\n",
    "\n",
    "group_id: The ID of the Facebook group to pull posts from.\n",
    "access_token: An access token with the appropriate permissions to access the group's content.\n",
    "limit: The number of posts to retrieve (default is 100).\n",
    "The function constructs the API request URL and parameters using the group ID and access token. It then makes the API request using the requests library and converts the JSON response into a Python dictionary using the response.json() method.\n",
    "\n",
    "The function then extracts the relevant data from each post in the response using the get() method and appends it to a list. This list is then converted into a pandas DataFrame using the pd.DataFrame() method.\n",
    "\n",
    "Finally, the function returns the DataFrame and the original JSON response as a tuple. This allows you to inspect the raw response data if needed.\n",
    "\n",
    "Note that this function only retrieves the posts and their associated data. If you need to retrieve additional information such as post reactions or user information, you will need to modify the fields parameter in the API request URL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 2: \"how do I call the function?\"\n",
    "\n",
    "### Response: \n",
    "You can call the get_facebook_posts() function by passing in the required parameters. Here's an example:\n",
    "```python\n",
    "# Set the required parameters\n",
    "group_id = \"123456789\"  # Replace with your group ID\n",
    "access_token = \"your-access-token\"  # Replace with your access token\n",
    "\n",
    "# Call the function to retrieve the posts\n",
    "df, data = get_facebook_posts(group_id, access_token, limit=50)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df.head())\n",
    "```\n",
    "In this example, we're passing in the group_id and access_token parameters, and specifying a limit of 50 posts to retrieve. The function returns a pandas DataFrame containing the posts and their associated data, which we assign to the variable df. We also assign the original JSON response to the variable data.\n",
    "\n",
    "Finally, we print the first 5 rows of the DataFrame using the head() method. Note that you can modify the function call and DataFrame output as needed to suit your specific use case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\2023-03-19 chat GPT Instagram API.ipynb Cell 20\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/2023-03-19%20chat%20GPT%20Instagram%20API.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(posts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/2023-03-19%20chat%20GPT%20Instagram%20API.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df, data\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/2023-03-19%20chat%20GPT%20Instagram%20API.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m df, data \u001b[39m=\u001b[39m get_facebook_posts(group_id, access_token, limit\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/2023-03-19%20chat%20GPT%20Instagram%20API.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m df\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\2023-03-19 chat GPT Instagram API.ipynb Cell 20\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/2023-03-19%20chat%20GPT%20Instagram%20API.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m data \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/2023-03-19%20chat%20GPT%20Instagram%20API.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m posts \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/2023-03-19%20chat%20GPT%20Instagram%20API.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m post \u001b[39min\u001b[39;00m data[\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/2023-03-19%20chat%20GPT%20Instagram%20API.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     created_time \u001b[39m=\u001b[39m post\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcreated_time\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/2023-03-19%20chat%20GPT%20Instagram%20API.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     message \u001b[39m=\u001b[39m post\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message, permalink, and comments.\n",
    "    Also outputs the response.json().\n",
    "    \n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        posts.append({\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"permalink_url\": permalink_url,\n",
    "            \"comments_count\": comments_count\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    return df, data\n",
    "\n",
    "df, data = get_facebook_posts(group_id, access_token, limit=50)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 3: \"Modify the function to print the response status code\"\n",
    "\n",
    "### Response\n",
    "To print the response status code, you can modify the get_facebook_posts() function as follows:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message, permalink, and comments.\n",
    "    Also outputs the response.json().\n",
    "    \n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        posts.append({\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"permalink_url\": permalink_url,\n",
    "            \"comments_count\": comments_count\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    return df, data\n",
    "```\n",
    "In this modified version of the function, we added a new variable status_code to capture the response status code using the response.status_code method. We then added a print() statement to print out the status code after the API request is made.\n",
    "\n",
    "Now when you call the get_facebook_posts() function, it will print out the status code along with the DataFrame and response data. For example:\n",
    "```python\n",
    "# Set the required parameters\n",
    "group_id = \"123456789\"  # Replace with your group ID\n",
    "access_token = \"your-access-token\"  # Replace with your access token\n",
    "\n",
    "# Call the function to retrieve the posts\n",
    "df, data = get_facebook_posts(group_id, access_token, limit=50)\n",
    "\n",
    "# Print the DataFrame and response status code\n",
    "print(df.head())\n",
    "```\n",
    "This will print out the first 5 rows of the DataFrame along with the response status code, like so:\n",
    "\n",
    "```yaml\n",
    "Response Status Code: 200\n",
    "               created_time  ... comments_count\n",
    "0  2022-03-18T15:00:00+0000  ...              0\n",
    "1  2022-03-17T17:30:00+0000  ...              3\n",
    "2  2022-03-16T19:45:00+0000  ...              0\n",
    "3  2022-03-15T22:15:00+0000  ...              1\n",
    "4  2022-03-14T12:30:00+0000  ...              2\n",
    "\n",
    "[5 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code: 200\n",
      "               created_time  \\\n",
      "0  2023-03-16T18:50:55+0000   \n",
      "1  2023-03-15T20:56:22+0000   \n",
      "2  2023-03-15T07:02:37+0000   \n",
      "3  2023-03-14T19:04:59+0000   \n",
      "4  2023-03-13T18:45:59+0000   \n",
      "\n",
      "                                             message  \\\n",
      "0  If youâ€™re constantly worried about calories an...   \n",
      "1  Youâ€™ve heard the saying â€˜a dog is for life - n...   \n",
      "2  Calories in versus calories out (how do I over...   \n",
      "3  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
      "4  It would actually break your heart to read my ...   \n",
      "\n",
      "                                       permalink_url  comments_count  \n",
      "0  https://www.facebook.com/groups/strongandsassy...               0  \n",
      "1  https://www.facebook.com/groups/strongandsassy...               0  \n",
      "2  https://www.facebook.com/groups/strongandsassy...               2  \n",
      "3  https://www.facebook.com/groups/strongandsassy...               6  \n",
      "4  https://www.facebook.com/groups/strongandsassy...               0  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message, permalink, and comments.\n",
    "    Also outputs the response.json().\n",
    "    \n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        posts.append({\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"permalink_url\": permalink_url,\n",
    "            \"comments_count\": comments_count\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    return df, data\n",
    "\n",
    "df, data = get_facebook_posts(group_id, access_token, limit=5)\n",
    "\n",
    "# Print the DataFrame and response status code\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>permalink_url</th>\n",
       "      <th>comments_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-16T18:50:55+0000</td>\n",
       "      <td>If youâ€™re constantly worried about calories an...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-15T20:56:22+0000</td>\n",
       "      <td>Youâ€™ve heard the saying â€˜a dog is for life - n...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-13T18:45:59+0000</td>\n",
       "      <td>It would actually break your heart to read my ...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_time  \\\n",
       "0  2023-03-16T18:50:55+0000   \n",
       "1  2023-03-15T20:56:22+0000   \n",
       "2  2023-03-15T07:02:37+0000   \n",
       "3  2023-03-14T19:04:59+0000   \n",
       "4  2023-03-13T18:45:59+0000   \n",
       "\n",
       "                                             message  \\\n",
       "0  If youâ€™re constantly worried about calories an...   \n",
       "1  Youâ€™ve heard the saying â€˜a dog is for life - n...   \n",
       "2  Calories in versus calories out (how do I over...   \n",
       "3  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "4  It would actually break your heart to read my ...   \n",
       "\n",
       "                                       permalink_url  comments_count  \n",
       "0  https://www.facebook.com/groups/strongandsassy...               0  \n",
       "1  https://www.facebook.com/groups/strongandsassy...               0  \n",
       "2  https://www.facebook.com/groups/strongandsassy...               2  \n",
       "3  https://www.facebook.com/groups/strongandsassy...               6  \n",
       "4  https://www.facebook.com/groups/strongandsassy...               0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My thoughts\n",
    "This table includes the post message, but now the comments are only summarized as a count instead of showing the comment text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 4: \"Thank you. Please modify the function to include the post_id.\"\n",
    "\n",
    "### Response:\n",
    "Sure, you can modify the get_facebook_posts() function to include the post_id by updating the posts list to include this field:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message, permalink, comments, and post ID.\n",
    "    Also outputs the response.json().\n",
    "    \n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        post_id = post.get(\"id\")\n",
    "        posts.append({\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"permalink_url\": permalink_url,\n",
    "            \"comments_count\": comments_count,\n",
    "            \"post_id\": post_id\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    return df, data\n",
    "```\n",
    "In this modified version of the function, we added a new variable post_id to capture the post ID using the post.get(\"id\") method. We then added this field to the posts list to include it in the output DataFrame.\n",
    "\n",
    "Now when you call the get_facebook_posts() function, it will include the post_id field in the output DataFrame. For example:\n",
    "\n",
    "```python\n",
    "# Set the required parameters\n",
    "group_id = \"123456789\"  # Replace with your group ID\n",
    "access_token = \"your-access-token\"  # Replace with your access token\n",
    "\n",
    "# Call the function to retrieve the posts\n",
    "df, data = get_facebook_posts(group_id, access_token, limit=50)\n",
    "\n",
    "# Print the DataFrame and response status code\n",
    "print(df.head())\n",
    "```\n",
    "This will print out the first 5 rows of the DataFrame along with the response status code, now including the post_id field:\n",
    "\n",
    "```yaml\n",
    "Response Status Code: 200\n",
    "                created_time  ...                          post_id\n",
    "0  2022-03-18T15:00:00+0000  ...  123456789_9876543212345678901\n",
    "1  2022-03-17T17:30:00+0000  ...  123456789_8765432109876543210\n",
    "2  2022-03-16T19:45:00+0000  ...  123456789_7654321098765432109\n",
    "3  2022-03-15T22:15:00+0000  ...  123456789_6543210987654321098\n",
    "4  2022-03-14T12:\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message, permalink, comments, and post ID.\n",
    "    Also outputs the response.json().\n",
    "    \n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        post_id = post.get(\"id\")\n",
    "        posts.append({\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"permalink_url\": permalink_url,\n",
    "            \"comments_count\": comments_count,\n",
    "            \"post_id\": post_id\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    return df, data\n",
    "\n",
    "df, data = get_facebook_posts(group_id, access_token, limit=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>permalink_url</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-16T18:50:55+0000</td>\n",
       "      <td>If youâ€™re constantly worried about calories an...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>0</td>\n",
       "      <td>2139238999669147_3367071606885874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-15T20:56:22+0000</td>\n",
       "      <td>Youâ€™ve heard the saying â€˜a dog is for life - n...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>0</td>\n",
       "      <td>2139238999669147_3366477613611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>2</td>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>6</td>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-13T18:45:59+0000</td>\n",
       "      <td>It would actually break your heart to read my ...</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "      <td>0</td>\n",
       "      <td>2139238999669147_3365106907082344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_time  \\\n",
       "0  2023-03-16T18:50:55+0000   \n",
       "1  2023-03-15T20:56:22+0000   \n",
       "2  2023-03-15T07:02:37+0000   \n",
       "3  2023-03-14T19:04:59+0000   \n",
       "4  2023-03-13T18:45:59+0000   \n",
       "\n",
       "                                             message  \\\n",
       "0  If youâ€™re constantly worried about calories an...   \n",
       "1  Youâ€™ve heard the saying â€˜a dog is for life - n...   \n",
       "2  Calories in versus calories out (how do I over...   \n",
       "3  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "4  It would actually break your heart to read my ...   \n",
       "\n",
       "                                       permalink_url  comments_count  \\\n",
       "0  https://www.facebook.com/groups/strongandsassy...               0   \n",
       "1  https://www.facebook.com/groups/strongandsassy...               0   \n",
       "2  https://www.facebook.com/groups/strongandsassy...               2   \n",
       "3  https://www.facebook.com/groups/strongandsassy...               6   \n",
       "4  https://www.facebook.com/groups/strongandsassy...               0   \n",
       "\n",
       "                             post_id  \n",
       "0  2139238999669147_3367071606885874  \n",
       "1  2139238999669147_3366477613611940  \n",
       "2  2139238999669147_3366060270320341  \n",
       "3  2139238999669147_3365771280349240  \n",
       "4  2139238999669147_3365106907082344  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My thoughts\n",
    "Next step is to merge the comments and posts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 5\n",
    "Modify the function to include its reactions. The order of the first few columns in the data frame should be post_id, created_time, message, comments_count. \n",
    "\n",
    "### Response\n",
    "Sure! Here's a modified version of the get_facebook_posts() function that includes reactions data for each post and reorders the columns in the output DataFrame as requested:\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message,\n",
    "    permalink, comments count, reactions count, and post ID.\n",
    "    Also outputs the response.json().\n",
    "\n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true),reactions.limit(0).summary(true)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        reactions_count = post.get(\"reactions\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        post_id = post.get(\"id\")\n",
    "        posts.append({\n",
    "            \"post_id\": post_id,\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"comments_count\": comments_count,\n",
    "            \"reactions_count\": reactions_count,\n",
    "            \"permalink_url\": permalink_url,\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    # Reorder columns as requested\n",
    "    df = df[[\"post_id\", \"created_time\", \"message\", \"comments_count\", \"reactions_count\", \"permalink_url\"]]\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    return df, data\n",
    "```\n",
    "In this modified version of the function, we added a new field reactions_count to capture the total count of reactions for each post using the post.get(\"reactions\", {}).get(\"summary\", {}).get(\"total_count\", 0) method. We then added this field to the posts list to include it in the output DataFrame.\n",
    "\n",
    "We also reordered the columns in the output DataFrame to match the requested order by adding the line df = df[[\"post_id\", \"created_time\", \"message\", \"comments_count\", \"reactions_count\", \"permalink_url\"]] before returning the DataFrame.\n",
    "\n",
    "Now when you call the get_facebook_posts() function, it will include the reactions_count field in the output DataFrame and reorder the columns as requested. For example:\n",
    "```python\n",
    "# Set the required parameters\n",
    "group_id = \"123456789\"  # Replace with your group ID\n",
    "access_token = \"your-access-token\"  # Replace with your access token\n",
    "\n",
    "# Call the function to retrieve the posts\n",
    "df, data = get_facebook_posts(group_id, access_token, limit=50)\n",
    "\n",
    "# Print the DataFrame and response status code\n",
    "print(df.head())\n",
    "```\n",
    "This will print out the first 5 rows of the DataFrame along with the response status code, now including the reactions_count field"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 7\n",
    "Modify the function so the dataframe has a separate column for each type of reaction.\n",
    "\n",
    "### Response\n",
    "Sure! Here's a modified version of the get_facebook_posts() function that includes separate columns for each type of reaction in the output DataFrame:\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message,\n",
    "    permalink, comments count, reactions, and post ID.\n",
    "    Also outputs the response.json().\n",
    "\n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true),reactions.limit(0).summary(true).type(LIKE).as(like),reactions.limit(0).summary(true).type(LOVE).as(love),reactions.limit(0).summary(true).type(WOW).as(wow),reactions.limit(0).summary(true).type(HAHA).as(haha),reactions.limit(0).summary(true).type(SAD).as(sad),reactions.limit(0).summary(true).type(ANGRY).as(angry)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        reactions = post.get(\"like\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"love\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"wow\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"haha\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"sad\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"angry\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        post_id = post.get(\"id\")\n",
    "        posts.append({\n",
    "            \"post_id\": post_id,\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"comments_count\": comments_count,\n",
    "            \"like_count\": reactions[0],\n",
    "            \"love_count\": reactions[1],\n",
    "            \"wow_count\": reactions[2],\n",
    "            \"haha_count\": reactions[3],\n",
    "            \"sad_count\": reactions[4],\n",
    "            \"angry_count\": reactions[5],\n",
    "            \"permalink_url\": permalink_url,\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    # Reorder columns\n",
    "    df = df[[\"post_id\", \"created_time\", \"message\", \"comments_count\", \"like_count\", \"love_count\", \"wow_count\", \"haha_count\", \"sad_count\", \"angry_count\", \"permalink_url\"]]\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    return df, data\n",
    "```\n",
    "In this modified version of the function, we added separate fields for each type of reaction using the `"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message,\n",
    "    permalink, comments count, reactions, and post ID.\n",
    "    Also outputs the response.json().\n",
    "\n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true),reactions.limit(0).summary(true).type(LIKE).as(like),reactions.limit(0).summary(true).type(LOVE).as(love),reactions.limit(0).summary(true).type(WOW).as(wow),reactions.limit(0).summary(true).type(HAHA).as(haha),reactions.limit(0).summary(true).type(SAD).as(sad),reactions.limit(0).summary(true).type(ANGRY).as(angry)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        reactions = post.get(\"like\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"love\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"wow\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"haha\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"sad\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"angry\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        post_id = post.get(\"id\")\n",
    "        posts.append({\n",
    "            \"post_id\": post_id,\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"comments_count\": comments_count,\n",
    "            \"like_count\": reactions[0],\n",
    "            \"love_count\": reactions[1],\n",
    "            \"wow_count\": reactions[2],\n",
    "            \"haha_count\": reactions[3],\n",
    "            \"sad_count\": reactions[4],\n",
    "            \"angry_count\": reactions[5],\n",
    "            \"permalink_url\": permalink_url,\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    # Reorder columns\n",
    "    df = df[[\"post_id\", \"created_time\", \"message\", \"comments_count\", \"like_count\", \"love_count\", \"wow_count\", \"haha_count\", \"sad_count\", \"angry_count\", \"permalink_url\"]]\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    return df, data\n",
    "\n",
    "df, data = get_facebook_posts(group_id, access_token, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>love_count</th>\n",
       "      <th>wow_count</th>\n",
       "      <th>haha_count</th>\n",
       "      <th>sad_count</th>\n",
       "      <th>angry_count</th>\n",
       "      <th>permalink_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3367071606885874</td>\n",
       "      <td>2023-03-16T18:50:55+0000</td>\n",
       "      <td>If youâ€™re constantly worried about calories an...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3366477613611940</td>\n",
       "      <td>2023-03-15T20:56:22+0000</td>\n",
       "      <td>Youâ€™ve heard the saying â€˜a dog is for life - n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3365106907082344</td>\n",
       "      <td>2023-03-13T18:45:59+0000</td>\n",
       "      <td>It would actually break your heart to read my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_id              created_time  \\\n",
       "0  2139238999669147_3367071606885874  2023-03-16T18:50:55+0000   \n",
       "1  2139238999669147_3366477613611940  2023-03-15T20:56:22+0000   \n",
       "2  2139238999669147_3366060270320341  2023-03-15T07:02:37+0000   \n",
       "3  2139238999669147_3365771280349240  2023-03-14T19:04:59+0000   \n",
       "4  2139238999669147_3365106907082344  2023-03-13T18:45:59+0000   \n",
       "\n",
       "                                             message  comments_count  \\\n",
       "0  If youâ€™re constantly worried about calories an...               0   \n",
       "1  Youâ€™ve heard the saying â€˜a dog is for life - n...               0   \n",
       "2  Calories in versus calories out (how do I over...               2   \n",
       "3  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...               6   \n",
       "4  It would actually break your heart to read my ...               0   \n",
       "\n",
       "   like_count  love_count  wow_count  haha_count  sad_count  angry_count  \\\n",
       "0           4           1          0           0          0            0   \n",
       "1           1           4          0           0          0            0   \n",
       "2           5           3          0           0          0            0   \n",
       "3          15           6          0           0          0            0   \n",
       "4           3           0          0           0          0            0   \n",
       "\n",
       "                                       permalink_url  \n",
       "0  https://www.facebook.com/groups/strongandsassy...  \n",
       "1  https://www.facebook.com/groups/strongandsassy...  \n",
       "2  https://www.facebook.com/groups/strongandsassy...  \n",
       "3  https://www.facebook.com/groups/strongandsassy...  \n",
       "4  https://www.facebook.com/groups/strongandsassy...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_time': '2023-03-16T18:50:55+0000',\n",
       " 'message': 'If youâ€™re constantly worried about calories and macros and not worried about micros. Youâ€™re missing out and hereâ€™s why â¬‡ï¸\\n\\nFruit and veggies are jam packed with vitamins and minerals. Although needed in small quantities in the body - the absence of them can be detrimental to our overall health. \\n\\nA varied diet contains antioxidants, photo nutrients and anti inflammatory properties that is optimal for overall health (not just externally) \\n\\nThey are a source of soluble and insoluble fibre which is vitally important for gut health. Happy gut = Happy body.\\n\\nFruit is an overlooked source of energy ðŸ™Œ\\n\\nWhen it comes to your nutrition stop looking at it from an EXCLUSIVE point of view and start looking at it INCLUSIVELY! Health is not just what you look like but how you feel â¤ï¸\\n\\nDrop me a like, comment or follow if you enjoyed this!',\n",
       " 'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3367071606885874/',\n",
       " 'comments': {'data': [],\n",
       "  'summary': {'order': 'chronological',\n",
       "   'total_count': 0,\n",
       "   'can_comment': True}},\n",
       " 'like': {'data': [],\n",
       "  'summary': {'total_count': 4, 'viewer_reaction': 'NONE'}},\n",
       " 'love': {'data': [],\n",
       "  'summary': {'total_count': 1, 'viewer_reaction': 'NONE'}},\n",
       " 'wow': {'data': [], 'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       " 'haha': {'data': [],\n",
       "  'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       " 'sad': {'data': [], 'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       " 'angry': {'data': [],\n",
       "  'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       " 'id': '2139238999669147_3367071606885874'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My thoughts: This is impressive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2. Create the initial code with ChatGPT UI\n",
    "## Prompt 2.1\n",
    "Modify the `get_facebook_posts` function to also return a DataFrame that has the each post comment, but without increasing the number of API calls. Each row should have the post_id, comment message, comment time stamp, and comment author. Include the code for calling the function.\n",
    "\n",
    "Here is the `get_facebook_posts` function to modify:\n",
    "```python\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message,\n",
    "    permalink, comments count, reactions, and post ID.\n",
    "    Also outputs the response.json().\n",
    "\n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true),reactions.limit(0).summary(true).type(LIKE).as(like),reactions.limit(0).summary(true).type(LOVE).as(love),reactions.limit(0).summary(true).type(WOW).as(wow),reactions.limit(0).summary(true).type(HAHA).as(haha),reactions.limit(0).summary(true).type(SAD).as(sad),reactions.limit(0).summary(true).type(ANGRY).as(angry)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    data = response.json()\n",
    "    posts = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        reactions = post.get(\"like\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"love\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"wow\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"haha\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"sad\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"angry\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        post_id = post.get(\"id\")\n",
    "        posts.append({\n",
    "            \"post_id\": post_id,\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"comments_count\": comments_count,\n",
    "            \"like_count\": reactions[0],\n",
    "            \"love_count\": reactions[1],\n",
    "            \"wow_count\": reactions[2],\n",
    "            \"haha_count\": reactions[3],\n",
    "            \"sad_count\": reactions[4],\n",
    "            \"angry_count\": reactions[5],\n",
    "            \"permalink_url\": permalink_url,\n",
    "        })\n",
    "    df = pd.DataFrame(posts)\n",
    "    # Reorder columns\n",
    "    df = df[[\"post_id\", \"created_time\", \"message\", \"comments_count\", \"like_count\", \"love_count\", \"wow_count\", \"haha_count\", \"sad_count\", \"angry_count\", \"permalink_url\"]]\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    return df, data\n",
    "```\n",
    "### Response\n",
    "To modify the get_facebook_posts function to also return comments of each post without increasing the number of API calls, we can make use of the {post_id}/comments edge in the Facebook Graph API.\n",
    "\n",
    "Here's the modified get_facebook_posts function:\n",
    "```python\n",
    "def get_facebook_posts(group_id, access_token, limit=100):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message,\n",
    "    permalink, comments count, reactions, and post ID. The function also returns a DataFrame with each post's comments,\n",
    "    comment message, comment time stamp, and comment author.\n",
    "    Also outputs the response.json().\n",
    "\n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "\n",
    "    Returns:\n",
    "        tuple(pandas.DataFrame, pandas.DataFrame): A tuple of two DataFrames containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    # Get posts data\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    post_params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(0).summary(true),reactions.limit(0).summary(true).type(LIKE).as(like),reactions.limit(0).summary(true).type(LOVE).as(love),reactions.limit(0).summary(true).type(WOW).as(wow),reactions.limit(0).summary(true).type(HAHA).as(haha),reactions.limit(0).summary(true).type(SAD).as(sad),reactions.limit(0).summary(true).type(ANGRY).as(angry)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    post_response = requests.get(url, params=post_params)\n",
    "    post_status_code = post_response.status_code\n",
    "    post_data = post_response.json()\n",
    "\n",
    "    # Get comments data\n",
    "    comments_params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"message,from,created_time\",\n",
    "        \"filter\": \"stream\"\n",
    "    }\n",
    "    comments_df = pd.DataFrame()\n",
    "    for post in post_data[\"data\"]:\n",
    "        post_id = post[\"id\"]\n",
    "        comments_url = f\"https://graph.facebook.com/{post_id}/comments\"\n",
    "        comments_response = requests.get(comments_url, params=comments_params)\n",
    "        comments_status_code = comments_response.status_code\n",
    "        comments_data = comments_response.json()\n",
    "        comments = []\n",
    "        for comment in comments_data[\"data\"]:\n",
    "            message = comment.get(\"message\")\n",
    "            author = comment.get(\"from\", {}).get(\"name\")\n",
    "            created_time = comment.get(\"created_time\")\n",
    "            comments.append({\n",
    "                \"post_id\": post_id,\n",
    "                \"message\": message,\n",
    "                \"author\": author,\n",
    "                \"created_time\": created_time\n",
    "            })\n",
    "        comments_df = pd.concat([comments_df, pd.DataFrame(comments)])\n",
    "    comments_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Get posts DataFrame\n",
    "    posts = []\n",
    "    for post in post_data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        reactions = post.get(\"like\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"love\", {}).get(\"summary\", {}).get(\"total_count\", 0), post\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My thoughts: Code is incomplete\n",
    "I will modify the code from previous steps to create a new function to get the results with fewer API calls."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying ChatGPT's code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 4\n",
    "Separate the function into to: one to make the API call, another to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "## I will use this as part of the final code for the task\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=25):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message,\n",
    "    permalink, comments count, reactions, and post ID.\n",
    "    Also outputs the response.json().\n",
    "\n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(10).summary(true),reactions.limit(500).summary(true).type(LIKE).as(like),reactions.limit(500).summary(true).type(LOVE).as(love),reactions.limit(500).summary(true).type(WOW).as(wow),reactions.limit(500).summary(true).type(HAHA).as(haha),reactions.limit(500).summary(true).type(SAD).as(sad),reactions.limit(500).summary(true).type(ANGRY).as(angry)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "\n",
    "# Call the function\n",
    "posts_data = get_facebook_posts(group_id, access_token, limit=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'created_time': '2023-03-21T19:11:52+0000',\n",
       "  'message': '@everyone for team training this week. A vast majority of you said you struggled with nutrition - give me some nutrition questions that I can discuss on the live training this week! No question is silly - all are relevant but I want to be able to help â¤ï¸ðŸ’ª',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3370347119891656/',\n",
       "  'comments': {'data': [{'created_time': '2023-03-21T20:45:46+0000',\n",
       "     'message': 'are protein bars bad for you as they are so processed',\n",
       "     'id': '3370383936554641'},\n",
       "    {'created_time': '2023-03-21T21:25:54+0000',\n",
       "     'message': 'Is protein really important ... should do we need to take protein supplements or powder...\\nOr',\n",
       "     'id': '3370399599886408'},\n",
       "    {'created_time': '2023-03-21T23:31:32+0000',\n",
       "     'message': 'For those of us entering perimenopause, what should we be conscious of in our diet?',\n",
       "     'id': '3370448433214858'},\n",
       "    {'created_time': '2023-03-22T03:42:17+0000',\n",
       "     'message': 'What snacks should we lean more towards when snacking and what should we limit in snacking moments?',\n",
       "     'id': '3370548013204900'},\n",
       "    {'created_time': '2023-03-22T04:33:53+0000',\n",
       "     'message': 'These are bloody fantastic questions! I will cover all of these tomorrow \\U0001fae1',\n",
       "     'id': '3370568783202823'},\n",
       "    {'created_time': '2023-03-22T04:34:42+0000',\n",
       "     'message': '@everyone \\n7am Sydney Time Thursday \\n8pm Irish time \\n\\nKeep your eyes peeled!',\n",
       "     'id': '3370569076536127'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURNNE16a3pOalUxTkRZAME1Ub3hOamM1TkRNeE5UUTMZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVMk9UQTNOalV6TmpFeU56b3hOamM1TkRVNU5qZA3oZD'}},\n",
       "   'summary': {'order': 'chronological',\n",
       "    'total_count': 6,\n",
       "    'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUlVneEpyb0NxWDJJZA1NHUHZApbTlWNFRFZAjNXTDJ2cmlRMTR6QkJqc3owSGFwSnI3dmd6RUtEZAHBTNExBdzZA1SnQZD',\n",
       "     'after': 'QVFIUnprcWpZAVF9sWm1mQnV3RXJnNHpBVW5jR2JSbGJUNGdhZAjgtZATAzZAEZA5dWZAhUUNObUFHUjBkTHNJeGhFbWdDWWUZD'}},\n",
       "   'summary': {'total_count': 2, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3370347119891656'},\n",
       " {'created_time': '2023-03-21T19:02:42+0000',\n",
       "  'message': 'How shocked would you be if I told you - there is not even 1kg weight loss between these two photos?\\n\\nWell thatâ€™s the truth!!!!\\n\\nYou see the scales does not reflect body composition change!\\n\\nWhen we look at a scale weight itâ€™s made up of water weight, skeletal mass, muscle mass and body fat! \\n\\nWhen we hop on a scales and see fluctuations:\\nâŒ What we think - â€˜Iâ€™ve gained or lost fatâ€™\\n\\nâœ… Whatâ€™s actually happened - â€˜My water has fluctuatedâ€™ - more often than not!\\n\\nScale weight only measures an overall accumulation of these components so please please remember that when you hop on one!\\n\\nYou can make huge changes to body composition without losing a single Kg!',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3370342969892071/',\n",
       "  'comments': {'data': [{'created_time': '2023-03-22T05:39:10+0000',\n",
       "     'message': 'Ree Waugh',\n",
       "     'id': '3370594463200255'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVNU5EUTJNekl3TURJMU5Ub3hOamM1TkRZAek5UVXgZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVNU5EUTJNekl3TURJMU5Ub3hOamM1TkRZAek5UVXgZD'}},\n",
       "   'summary': {'order': 'chronological',\n",
       "    'total_count': 1,\n",
       "    'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUkRZAME9YMFdmWUhabmtLOXF6NWs5ZA1Rid0RnUlFYdVBQdFhlWmpwOXhuaU1URXVZAdlJwdjYyVHY2dl9TQXVLMzkZD',\n",
       "     'after': 'QVFIUkJrYUlaV1JvSEpDVEs4Ui05T0pYNE5Kc0hZAQXFUXzc2ZAWRteTR2enhPVWpsVTNSVHZAHSXdyQ2FVYVNJLVpwdTMZD'}},\n",
       "   'summary': {'total_count': 3, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUk1EakU5QmFNWU51U0pmb1BoUFFtbFA0QmVBa0JKTFZAwdEwteGQ1SENfWjBXTmcyTWdad1RMYTd1VTBvM3E1WFY0TnFTRl84TjNOdnRpMFRQZAXRodXVn',\n",
       "     'after': 'QVFIUmEwTlBVbGpfLVlDMXVsY1o4R0tpRmxJdF9SRVh1dkVHSWVfWi1ZATEd3T2V1QmxkcnJ1SEFmR1NkY2d0ai1hdmYZD'}},\n",
       "   'summary': {'total_count': 6, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUnctTnhtN2hWSjgxSF9QVDZAQSFhqT3dDRGRSckVfY2M5UjNBMW1Ub2VWZAUc3OGNYYkM1ZAWNVNTNQVUZA4RmtHR0dEcDhYOHlvNnpPVkxRT0ZAyZAU5uNGh3',\n",
       "     'after': 'QVFIUkpBNlNGVE1MZAl96NnZABVFRrYmJMR3A3U1prTnJPTEFBVFhiUFlxanRvQ01XVnY2enpzOElPQklvdzZArMERSMExrbzVWYmJrcjVSY3BYdmJYTWhieGRB'}},\n",
       "   'summary': {'total_count': 3, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3370342969892071'},\n",
       " {'created_time': '2023-03-20T18:56:34+0000',\n",
       "  'message': 'Why your morning routine may actually be NEGATIVELY impacting your goals Sleep is one of the most under utilised tools when it comes to your goals - fat loss, weight loss, performance etc. Yet we still donâ€™t seem to prioritise it! We still think that morning workout is king ðŸ‘‘ after 4 hours of shitty sleep! We still get up to watch the sunrise - because thatâ€™s what all the cool kids do obvs ðŸ’\\u200dâ™€ï¸ Arriving with our eyes popping out of our heads with tiredness ðŸ˜´Let me tell you itâ€™s actually no laughing matter! As mentioned above, sleep is often the missing link for our goals but more importantly itâ€™s important for our overall physical and mental health! Thereâ€™s actually too many statistics to show the support of increased disease and health risks in those with low and poor quality sleep ðŸ’¤ âœ… Start prioritising sleep the same way youâ€™d prioritise nutrition and exercise. âœ… Your night time routine is probably more important than your morning routineâœ… Make life easier - less screen time, use lamps, donâ€™t eat right before bed, cool room etc.Take this as your sign to start prioritising your sleep today ðŸ’ª',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3369703796622655/',\n",
       "  'comments': {'data': [{'created_time': '2023-03-21T04:42:48+0000',\n",
       "     'message': 'Set my alarm for 5am today to walk Eddie and be at cardio for 6am. Unfortunately, Eddie had different ideas (not his fault, our neighbour keeps feeding him cheap supermarket dog treats)....walked Ed at 2.30am and 4.45am and ended up sleeping until 12 ðŸ˜­',\n",
       "     'id': '3369936533266048'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yT1Rrek5qVXpNekkyTmpBME9Eb3hOamM1TXpjek56WTQZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yT1Rrek5qVXpNekkyTmpBME9Eb3hOamM1TXpjek56WTQZD'}},\n",
       "   'summary': {'order': 'chronological',\n",
       "    'total_count': 1,\n",
       "    'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUi1xQmZAwNGJ4bW9QdVFMTS1tVGp1R1gxdDZAlMjRBZA1FTdm5yRlpNM1FtZA0F4ckt3alE1TVU4cVR2VTdaYnQxNGFFVXBRQWJRQ2lOVGpaVTVmekozVG1n',\n",
       "     'after': 'QVFIUmFFX1V3MEstQXFMWEdRU1ZA3MmZAXUmVHYVFYOXZAzd0NRLTZAxNWp6a2FOYlR5eVRrWmxvdFBaekllcktLX0Q0ZAWIZD'}},\n",
       "   'summary': {'total_count': 5, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3369703796622655'},\n",
       " {'created_time': '2023-03-16T18:50:55+0000',\n",
       "  'message': 'If youâ€™re constantly worried about calories and macros and not worried about micros. Youâ€™re missing out and hereâ€™s why â¬‡ï¸\\n\\nFruit and veggies are jam packed with vitamins and minerals. Although needed in small quantities in the body - the absence of them can be detrimental to our overall health. \\n\\nA varied diet contains antioxidants, photo nutrients and anti inflammatory properties that is optimal for overall health (not just externally) \\n\\nThey are a source of soluble and insoluble fibre which is vitally important for gut health. Happy gut = Happy body.\\n\\nFruit is an overlooked source of energy ðŸ™Œ\\n\\nWhen it comes to your nutrition stop looking at it from an EXCLUSIVE point of view and start looking at it INCLUSIVELY! Health is not just what you look like but how you feel â¤ï¸\\n\\nDrop me a like, comment or follow if you enjoyed this!',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3367071606885874/',\n",
       "  'comments': {'data': [],\n",
       "   'summary': {'order': 'chronological',\n",
       "    'total_count': 0,\n",
       "    'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUk1aUFJ3NFM2aVRCTFYxZAEI2UXhMcC1TWUxZAbmJIdVd1VDMxbHdwVFZAVUnpuME9WQ1lPNk9BUW9GSDZAmMXNxUEhSbXhYSERmRl9vLTdzYzZAVQzVFZAm1B',\n",
       "     'after': 'QVFIUkR2aG5aRmd1RUNPSXlKejVmV09WbnlhUGhBbzZANQ3plRi1WcVFMQVVyYl9uSjNBU1NkcFR5U1FfeEQ1eXNkRDYZD'}},\n",
       "   'summary': {'total_count': 4, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUlZA4QjlGWlprZAXlIRTRlSmJIYzc0SGxxVTBwbW5jRUs0aV83YXEwRklUeFIybVhKVko4bkJTcHRIU2t5WjNZASm8ZD',\n",
       "     'after': 'QVFIUlZA4QjlGWlprZAXlIRTRlSmJIYzc0SGxxVTBwbW5jRUs0aV83YXEwRklUeFIybVhKVko4bkJTcHRIU2t5WjNZASm8ZD'}},\n",
       "   'summary': {'total_count': 1, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3367071606885874'},\n",
       " {'created_time': '2023-03-15T20:56:22+0000',\n",
       "  'message': 'Youâ€™ve heard the saying â€˜a dog is for life - not just for Christmasâ€™. \\n\\nWell nutrition is for life - not just a 6 week challenge! \\n\\nFinding good, sustainable long term nutrition habits takes time. Getting fat loss results which LAST take time. So give yourself time to achieve them.\\n\\nSomething I hear time and time again from my clients - is that they just start getting into the swing of things by the time 3 months rolls around. They are just starting to form the habits after 3 months and usually need a bit more accountability for a further 3-6 months! \\n\\nThe average length of time my clients commit is 6-9 months but the results speak for themselves! \\n\\nWanting weight loss and wanting a long term sustainable, healthy approach to nutrition and lifestyle are 2 totally different things so remember that when youâ€™re deciding what to commit to ðŸ™',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3366477613611940/',\n",
       "  'comments': {'data': [],\n",
       "   'summary': {'order': 'chronological',\n",
       "    'total_count': 0,\n",
       "    'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUkg5Y0kzbWVTcS1xS1M2UGFLS202VG41X3YyZAzU0d0VBYkQ3S3dVZAGlkR25CNTVNRFlVWlltRTBROWxqZAlpQU20ZD',\n",
       "     'after': 'QVFIUkg5Y0kzbWVTcS1xS1M2UGFLS202VG41X3YyZAzU0d0VBYkQ3S3dVZAGlkR25CNTVNRFlVWlltRTBROWxqZAlpQU20ZD'}},\n",
       "   'summary': {'total_count': 1, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUnlhcnlhemFmUGlyS2pjTzVaV0p3ckVhSGk0OE43NjVNd05jUTZAUd3VmelVSenFvZAnlhVEhGd1VBa3U4N1ZAtWTc4RW9pUXlyV2JZALTg5QmxoMHEtYUln',\n",
       "     'after': 'QVFIUnctMDlDcFp3U3l0ZAnJoVUVzTWtSd3I4QS13T01adGxSQXFFckY0dERLTXFGRlJfWF96S0ZAIRFVWTGVBSkVkUlUZD'}},\n",
       "   'summary': {'total_count': 4, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3366477613611940'},\n",
       " {'created_time': '2023-03-15T07:02:37+0000',\n",
       "  'message': 'Calories in versus calories out (how do I overcome a plateau)\\n\\nRep ranges and what they mean in training',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3366060270320341/',\n",
       "  'comments': {'data': [{'created_time': '2023-03-15T13:38:20+0000',\n",
       "     'message': \"Thank you for the info Amanda.  I'm struggling  how to calculate how much calories, health fats and protein to consume. Thank you ðŸ˜Š\",\n",
       "     'id': '3366252306967804'},\n",
       "    {'created_time': '2023-03-15T07:39:21+0000',\n",
       "     'message': 'Thank you x',\n",
       "     'id': '3366072910319077'}],\n",
       "   'summary': {'order': 'ranked', 'total_count': 2, 'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUmlabVZA0elFkWGM2RUZAkVWpuSE5RNC16MW9xZAlZAWRFNWMWd3REZAqbTRIWS1Dcm1hb094VVIzVk5aQlVDVzR2a2JsbkNqd1otaTJ1ZAlJTTFZAuX3dTcHNB',\n",
       "     'after': 'QVFIUnNMeEJwNjhPSnNvNFZAQQ0syb0xwOWpxV0d2QlkyZA2l5Wmx5aU5wM2lFR1VyU1pwTDRlTjZAkQi1CeURWM01abG1VUXRnT0paN0lnNXBRZAm9oR0RVSXV3'}},\n",
       "   'summary': {'total_count': 5, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUi1YUEh1cDVld1ktYjZAVdTZAQZADZAWbVBJa0p0aGIyUHZAtemp2bzRqdVV6aE4wRW1QNDg4WHBaUHl5VTYzUDRIclAZD',\n",
       "     'after': 'QVFIUnlFTXBKT3pVaHVmWkFoS1gtbmtyX3UtMnpqN09oTTRXTUJVUWh4ai1ZAZAXd0UHV3ZAGlYcGVCWTdpamVNTFVfQ3cZD'}},\n",
       "   'summary': {'total_count': 3, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3366060270320341'},\n",
       " {'created_time': '2023-03-14T19:04:59+0000',\n",
       "  'message': 'The humble back photo ðŸ”™\\n\\nIn my opinion, usually my favourite of ladies photos due to the shape change and the composition change ðŸ™ðŸ’ª\\n\\nMassive shoutout to this strong back owner  Gillian NÃ­ HEachthairn who competed in her first CF Open this year.\\n\\nThis working mother has always loved exercise and needs it for her mental health (I feel you Gill). But she wanted to get a handle on her nutrition, not just for her but for her to be able to make more educated choices for her son too ðŸ™ \\n\\nGillian finished up with me last month and in the year has hit numerous milestones - including doing True Grit with me! Her determination is nothing short of inspiring ðŸ’ªðŸ™Œ\\n\\nAnd Iâ€™m excited to see where her journey will go to ðŸ¤©',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3365771280349240/',\n",
       "  'comments': {'data': [{'created_time': '2023-03-14T20:28:40+0000',\n",
       "     'message': 'ðŸ‘ðŸ™ŒðŸ‘ðŸ™Œ',\n",
       "     'id': '3365809060345462'},\n",
       "    {'created_time': '2023-03-14T20:43:52+0000',\n",
       "     'message': 'Fantastic!!!!',\n",
       "     'id': '3365815597011475'},\n",
       "    {'created_time': '2023-03-14T20:50:22+0000',\n",
       "     'message': 'wow amazing mama Gillian NÃ­ HEachthairn! ðŸ’ª',\n",
       "     'id': '3365817977011237'},\n",
       "    {'created_time': '2023-03-14T23:38:14+0000',\n",
       "     'message': 'Thanks everyone xx',\n",
       "     'id': '3365882037004831'},\n",
       "    {'created_time': '2023-03-15T02:06:26+0000',\n",
       "     'message': 'Amazing results!',\n",
       "     'id': '3365939723665729'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTlRnd09UQTJNRE0wTlRRMk1qb3hOamM0T0RJMU56SXgZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTlRrek9UY3lNelkyTlRjeU9Ub3hOamM0T0RRMU9UZAzMZD'}},\n",
       "   'summary': {'order': 'chronological',\n",
       "    'total_count': 6,\n",
       "    'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUkM0SUZAMN0RvTGVZAa2Rib3RLTHBFc2dLNjNQMnA2TS1SbXJLM2tiYU9UVWNFVkZA6c0hWcDgxb1F6Ujd3aDIteEUZD',\n",
       "     'after': 'QVFIUnhKT2owTml5X213QUJJa3JRQTBYSzNQdTY1TnNJMy1TTlVUVXdHcjZAHanpVeGE0YWxlQzM2TDJ4SVJrUVFudGMZD'}},\n",
       "   'summary': {'total_count': 15, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUnA3azVlSWM3dDU5TFdCNXhNZAm1YcTZAWdXJDVmhGNEE0RF9qQ2tpME5ERlRNM3RWdm5HMEFURXZAlMVNfeDlLUnBwRzFDZA1hiLU9DTV9SSWQwRHdkRGpB',\n",
       "     'after': 'QVFIUmU2Ymh0Q1VZAcU5QYzgwQjFSaGpHVEUwd29hM1RLX1FZAMGJGdktQQWJUNVM3WHkydVdQZA0o4R0xlbFNQcDRwdjAZD'}},\n",
       "   'summary': {'total_count': 6, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3365771280349240'},\n",
       " {'created_time': '2023-03-13T18:45:59+0000',\n",
       "  'message': 'It would actually break your heart to read my dms. Every day someone reaches out to me unhappy in their skinâ€¦Some have been trying for weeks to change, others for yearsâ€¦I canâ€™t reiterate enough that happiness is not found in a scale weight or a clothes size.But happiness can be found:                âœ… By submerging yourself in a programme focused on personal growth                                              âœ… Surrounding yourself with like minded women                               âœ… Focusing on what you can achieve rather than what you canâ€™t âœ… By becoming empowered through better nutrition choices and resistance training.                     Weight loss does not equal happiness.                                        But the Strong and Sassy programme = happiness!',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3365106907082344/',\n",
       "  'comments': {'data': [],\n",
       "   'summary': {'order': 'chronological',\n",
       "    'total_count': 0,\n",
       "    'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUnBqaDJFdnloNmwwMU9vRzF4dV9PdjRqR0FMWFJYR2szRHFENmE5djFranlsTFhDVk9mR1VzNDhyQm5jOEhUQTk3UlU2RmtnYnVpajR6dkNhdk0yQlpn',\n",
       "     'after': 'QVFIUl9ISDRvdWtiTVlLVU54bHJSdlRRc0M1YmtfR19Xc01PdUQtaHZAmbXd3Wm5QeHMwU2IyVklyVkZAsaGJqeEtOSl8ZD'}},\n",
       "   'summary': {'total_count': 3, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3365106907082344'},\n",
       " {'created_time': '2023-03-13T07:29:09+0000',\n",
       "  'message': '@everyone would love your help with the live team training this week! What would you like me to cover?',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3364783420448026/',\n",
       "  'comments': {'data': [{'created_time': '2023-03-13T07:55:08+0000',\n",
       "     'message': 'Maybe something about how to adjust if u go up in weights but the reps are lower and what a good balance is? Donâ€™t know if thatâ€™s to broad a topic though.',\n",
       "     'id': '3364794397113595'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTkRjNU5ETTVOekV4TXpVNU5Ub3hOamM0TmprME1UQTUZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTkRjNU5ETTVOekV4TXpVNU5Ub3hOamM0TmprME1UQTUZD'}},\n",
       "   'summary': {'order': 'chronological',\n",
       "    'total_count': 1,\n",
       "    'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3364783420448026'},\n",
       " {'created_time': '2023-03-12T18:50:47+0000',\n",
       "  'message': 'Have your ever tried on a pair of shorts - just to pull them straight off again!? \\n\\nHave you felt they were too tight? \\n\\nShowed too much cellulite or stretch marks? \\n\\nSam sent me this photo during the week last week. She hadnâ€™t wore shorts for ages because they were too tight.\\n\\nYou see avoiding certain clothes is something I see way too often amongst women! Unhappiness in certain clothes. A lack of self confidence! But when you start looking after yourself from the inside out - things change! \\n\\nMichelle was another example of getting outside that comfort zone. Two weeks ago Michelle wore shorts to the gym and was awkward and embarassed. Last week, she rocked up in a pair and this week sheâ€™s shopping online for new ones ðŸ¥°\\n\\nThere is nothing wrong with our bodies. Thereâ€™s nothing wrong with stretch marks or cellulite. The problem we have is that we are not happy in the only home we have. Become happier in your body and the world will change ðŸ™\\n\\n#weartheshorts #motivation #inspiration #weightloss #weightlossjourney #fitness #onlinecoaching #realresults #realnutrition',\n",
       "  'permalink_url': 'https://www.facebook.com/groups/strongandsassycommunity/permalink/3364475920478776/',\n",
       "  'comments': {'data': [{'created_time': '2023-03-13T08:16:03+0000',\n",
       "     'message': 'Love this!',\n",
       "     'id': '3364801680446200'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTkRnd01UWTRNRFEwTmpJd01Eb3hOamM0TmprMU16WTAZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTkRnd01UWTRNRFEwTmpJd01Eb3hOamM0TmprMU16WTAZD'}},\n",
       "   'summary': {'order': 'chronological',\n",
       "    'total_count': 1,\n",
       "    'can_comment': True}},\n",
       "  'like': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUjJyTVppRmYxeVZANa01IWkNXVVRFQTJyNnN0dGFoc1l1WkttejlrRkVEWkV6eTQ0Si10LXZA3Uy0tZA3lJWVJycDRsWWNrVUlGM3FhZA3RVSEFBWjd1X0hB',\n",
       "     'after': 'QVFIUjNxcGZAaS3lxOGVVaUZAyUXJoQmZAMMnluNXpqY3hJaHg1b1lyNVNsaE51N29kMXU5b3J6cE1xTTV2bVUxVzhLUEEZD'}},\n",
       "   'summary': {'total_count': 4, 'viewer_reaction': 'NONE'}},\n",
       "  'love': {'data': [],\n",
       "   'paging': {'cursors': {'before': 'QVFIUlg3RE45WnBITk1ZAU0VGWEtyRWtkZAjN3WlVRTmdtUF9penJCbmI1NFFYektvcS1XSWFWdmxXRC1HdlBLZAm94N3cZD',\n",
       "     'after': 'QVFIUnhKYjA5UG5kdG9ZASzZAGMGlIZAWpZAZAUU5ZAFJGNkM5MGtoWGxfbFJBTW5qU3NWVFozbUJuTElWTW92S09DYUtSQ0QZD'}},\n",
       "   'summary': {'total_count': 6, 'viewer_reaction': 'NONE'}},\n",
       "  'wow': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'haha': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'sad': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'angry': {'data': [],\n",
       "   'summary': {'total_count': 0, 'viewer_reaction': 'NONE'}},\n",
       "  'id': '2139238999669147_3364475920478776'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_response(data):\n",
    "    posts = []\n",
    "    comments = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        reactions = post.get(\"like\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"love\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"wow\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"haha\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"sad\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"angry\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        post_id = post.get(\"id\")\n",
    "        posts.append({\n",
    "            \"post_id\": post_id,\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"comments_count\": comments_count,\n",
    "            \"like_count\": reactions[0],\n",
    "            \"love_count\": reactions[1],\n",
    "            \"wow_count\": reactions[2],\n",
    "            \"haha_count\": reactions[3],\n",
    "            \"sad_count\": reactions[4],\n",
    "            \"angry_count\": reactions[5],\n",
    "            \"permalink_url\": permalink_url,\n",
    "        })\n",
    "        post_comments = post.get(\"comments\", {}).get(\"data\", [])\n",
    "        for comment in post_comments:\n",
    "            post_comments.append({\n",
    "                \"post_id\": post[\"id\"],\n",
    "                \"post_created_time\": post.get(\"created_time\", \"\"),\n",
    "                \"comment_id\": comment.get(\"id\", \"\"),\n",
    "                \"comment_created_time\": comment.get(\"created_time\", \"\"),\n",
    "                \"comment_message\": comment.get(\"message\", \"\"),\n",
    "            })\n",
    "    df = pd.DataFrame(posts)\n",
    "    # Reorder columns\n",
    "    df = df[[\"post_id\", \"created_time\", \"message\", \"comments_count\", \"like_count\", \"love_count\", \"wow_count\", \"haha_count\", \"sad_count\", \"angry_count\", \"permalink_url\"]]\n",
    "    \n",
    "    results = dict()\n",
    "    results['posts'] = df\n",
    "    results['comments'] = pd.DataFrame(post_comments)\n",
    "    results['response'] = data\n",
    "    return results\n",
    "\n",
    "results = process_response(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: \n",
    "API call worked as expected to return the desired data, but parsing the data into DataFrames crashed the system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 5\n",
    "Try just parsing the posts data without parsing comments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>love_count</th>\n",
       "      <th>wow_count</th>\n",
       "      <th>haha_count</th>\n",
       "      <th>sad_count</th>\n",
       "      <th>angry_count</th>\n",
       "      <th>permalink_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3369703796622655</td>\n",
       "      <td>2023-03-20T18:56:34+0000</td>\n",
       "      <td>Why your morning routine may actually be NEGAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3367071606885874</td>\n",
       "      <td>2023-03-16T18:50:55+0000</td>\n",
       "      <td>If youâ€™re constantly worried about calories an...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3366477613611940</td>\n",
       "      <td>2023-03-15T20:56:22+0000</td>\n",
       "      <td>Youâ€™ve heard the saying â€˜a dog is for life - n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2139238999669147_3365106907082344</td>\n",
       "      <td>2023-03-13T18:45:59+0000</td>\n",
       "      <td>It would actually break your heart to read my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2139238999669147_3364783420448026</td>\n",
       "      <td>2023-03-13T07:29:09+0000</td>\n",
       "      <td>@everyone would love your help with the live t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2139238999669147_3364475920478776</td>\n",
       "      <td>2023-03-12T18:50:47+0000</td>\n",
       "      <td>Have your ever tried on a pair of shorts - jus...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_id              created_time  \\\n",
       "0  2139238999669147_3370347119891656  2023-03-21T19:11:52+0000   \n",
       "1  2139238999669147_3370342969892071  2023-03-21T19:02:42+0000   \n",
       "2  2139238999669147_3369703796622655  2023-03-20T18:56:34+0000   \n",
       "3  2139238999669147_3367071606885874  2023-03-16T18:50:55+0000   \n",
       "4  2139238999669147_3366477613611940  2023-03-15T20:56:22+0000   \n",
       "5  2139238999669147_3366060270320341  2023-03-15T07:02:37+0000   \n",
       "6  2139238999669147_3365771280349240  2023-03-14T19:04:59+0000   \n",
       "7  2139238999669147_3365106907082344  2023-03-13T18:45:59+0000   \n",
       "8  2139238999669147_3364783420448026  2023-03-13T07:29:09+0000   \n",
       "9  2139238999669147_3364475920478776  2023-03-12T18:50:47+0000   \n",
       "\n",
       "                                             message  comments_count  \\\n",
       "0  @everyone for team training this week. A vast ...               6   \n",
       "1  How shocked would you be if I told you - there...               1   \n",
       "2  Why your morning routine may actually be NEGAT...               1   \n",
       "3  If youâ€™re constantly worried about calories an...               0   \n",
       "4  Youâ€™ve heard the saying â€˜a dog is for life - n...               0   \n",
       "5  Calories in versus calories out (how do I over...               2   \n",
       "6  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...               6   \n",
       "7  It would actually break your heart to read my ...               0   \n",
       "8  @everyone would love your help with the live t...               1   \n",
       "9  Have your ever tried on a pair of shorts - jus...               1   \n",
       "\n",
       "   like_count  love_count  wow_count  haha_count  sad_count  angry_count  \\\n",
       "0           2           0          0           0          0            0   \n",
       "1           3           6          3           0          0            0   \n",
       "2           5           0          0           0          0            0   \n",
       "3           4           1          0           0          0            0   \n",
       "4           1           4          0           0          0            0   \n",
       "5           5           3          0           0          0            0   \n",
       "6          15           6          0           0          0            0   \n",
       "7           3           0          0           0          0            0   \n",
       "8           0           0          0           0          0            0   \n",
       "9           4           6          0           0          0            0   \n",
       "\n",
       "                                       permalink_url  \n",
       "0  https://www.facebook.com/groups/strongandsassy...  \n",
       "1  https://www.facebook.com/groups/strongandsassy...  \n",
       "2  https://www.facebook.com/groups/strongandsassy...  \n",
       "3  https://www.facebook.com/groups/strongandsassy...  \n",
       "4  https://www.facebook.com/groups/strongandsassy...  \n",
       "5  https://www.facebook.com/groups/strongandsassy...  \n",
       "6  https://www.facebook.com/groups/strongandsassy...  \n",
       "7  https://www.facebook.com/groups/strongandsassy...  \n",
       "8  https://www.facebook.com/groups/strongandsassy...  \n",
       "9  https://www.facebook.com/groups/strongandsassy...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I will use this as part of the final code for the task\n",
    "def process_response(data):\n",
    "    posts = []\n",
    "    comments = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        reactions = post.get(\"like\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"love\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"wow\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"haha\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"sad\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"angry\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        post_id = post.get(\"id\")\n",
    "        posts.append({\n",
    "            \"post_id\": post_id,\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"comments_count\": comments_count,\n",
    "            \"like_count\": reactions[0],\n",
    "            \"love_count\": reactions[1],\n",
    "            \"wow_count\": reactions[2],\n",
    "            \"haha_count\": reactions[3],\n",
    "            \"sad_count\": reactions[4],\n",
    "            \"angry_count\": reactions[5],\n",
    "            \"permalink_url\": permalink_url,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(posts)\n",
    "    # Reorder columns\n",
    "    df = df[[\"post_id\", \"created_time\", \"message\", \"comments_count\", \"like_count\", \"love_count\", \"wow_count\", \"haha_count\", \"sad_count\", \"angry_count\", \"permalink_url\"]]\n",
    "    \n",
    "    return df\n",
    "\n",
    "posts_df = process_response(posts_data)\n",
    "posts_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Parsing posts data was not a problem. The system crashes when trying to parse the comments data. Instead I will use ChatGPT to make additioanl API calls to pull the comments from Facebook posts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3\n",
    "## Prompt 3.1 \n",
    "\"Create a python function that will make a GET request to pull comments from a Facebook group using the Facebook API. Output the results into a DataFrame so that each comment is a row along with its details and replies.\"\n",
    "\n",
    "### Response\n",
    "To make a GET request to pull comments from a Facebook group using the Facebook API in Python, you can use the requests library. Here is an example function that does this and outputs the results into a pandas DataFrame:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_fb_comments(group_id, access_token):\n",
    "    \"\"\"\n",
    "    Pulls comments from a Facebook group using the Facebook API and outputs the results into a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    group_id (str): The ID of the Facebook group to pull comments from.\n",
    "    access_token (str): A Facebook access token with the necessary permissions to access the group.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame with each comment as a row along with its details and replies.\n",
    "    \"\"\"\n",
    "    # Set up the API endpoint and parameters\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"fields\": \"comments{created_time,message,from,comments{created_time,message,from}}\",\n",
    "        \"access_token\": access_token,\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Convert the response to a DataFrame\n",
    "    comments = []\n",
    "    for post in response.json()[\"data\"]:\n",
    "        post_comments = post.get(\"comments\", {}).get(\"data\", [])\n",
    "        for comment in post_comments:\n",
    "            comment_dict = {\n",
    "                \"post_id\": post.get(\"id\"),\n",
    "                \"created_time\": comment.get(\"created_time\"),\n",
    "                \"message\": comment.get(\"message\"),\n",
    "                \"author_id\": comment.get(\"from\", {}).get(\"id\"),\n",
    "                \"author_name\": comment.get(\"from\", {}).get(\"name\"),\n",
    "                \"parent_id\": None,\n",
    "                \"parent_name\": None,\n",
    "            }\n",
    "            parent_comment = comment.get(\"comments\", {}).get(\"data\", [])\n",
    "            if parent_comment:\n",
    "                parent_comment = parent_comment[0]\n",
    "                comment_dict[\"parent_id\"] = parent_comment.get(\"id\")\n",
    "                comment_dict[\"parent_name\"] = parent_comment.get(\"from\", {}).get(\"name\")\n",
    "            comments.append(comment_dict)\n",
    "    df = pd.DataFrame(comments)\n",
    "    return df\n",
    "```\n",
    "To use this function, you'll need to provide the Facebook group ID and an access token with the necessary permissions to access the group. You can get an access token by creating a Facebook app and following the OAuth authentication flow.\n",
    "\n",
    "Here's an example of how to use the function:\n",
    "```python\n",
    "group_id = \"1234567890\"  # replace with your Facebook group ID\n",
    "access_token = \"your_access_token_here\"\n",
    "df = get_fb_comments(group_id, access_token)\n",
    "print(df.head())\n",
    "```\n",
    "This will print the first five rows of the DataFrame, which should contain the details of the comments and their replies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 3.2\n",
    "\"Modify get_fb_comment function to also return the response.json()\"\n",
    "\n",
    "### Response\n",
    "Sure, here's a modified version of the get_fb_comments function that also returns the full JSON response:\n",
    "```python\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_fb_comments(group_id, access_token):\n",
    "    \"\"\"\n",
    "    Pulls comments from a Facebook group using the Facebook API and outputs the results into a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    group_id (str): The ID of the Facebook group to pull comments from.\n",
    "    access_token (str): A Facebook access token with the necessary permissions to access the group.\n",
    "    \n",
    "    Returns:\n",
    "    Tuple(pandas.DataFrame, dict): A tuple containing a DataFrame with each comment as a row along with its details and replies,\n",
    "    and the full JSON response from the API.\n",
    "    \"\"\"\n",
    "    # Set up the API endpoint and parameters\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"fields\": \"comments{created_time,message,from,comments{created_time,message,from}}\",\n",
    "        \"access_token\": access_token,\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Convert the response to a DataFrame\n",
    "    comments = []\n",
    "    for post in response.json()[\"data\"]:\n",
    "        post_comments = post.get(\"comments\", {}).get(\"data\", [])\n",
    "        for comment in post_comments:\n",
    "            comment_dict = {\n",
    "                \"post_id\": post.get(\"id\"),\n",
    "                \"created_time\": comment.get(\"created_time\"),\n",
    "                \"message\": comment.get(\"message\"),\n",
    "                \"author_id\": comment.get(\"from\", {}).get(\"id\"),\n",
    "                \"author_name\": comment.get(\"from\", {}).get(\"name\"),\n",
    "                \"parent_id\": None,\n",
    "                \"parent_name\": None,\n",
    "            }\n",
    "            parent_comment = comment.get(\"comments\", {}).get(\"data\", [])\n",
    "            if parent_comment:\n",
    "                parent_comment = parent_comment[0]\n",
    "                comment_dict[\"parent_id\"] = parent_comment.get(\"id\")\n",
    "                comment_dict[\"parent_name\"] = parent_comment.get(\"from\", {}).get(\"name\")\n",
    "            comments.append(comment_dict)\n",
    "    df = pd.DataFrame(comments)\n",
    "    return df, response.json()\n",
    "```\n",
    "This version of the function returns a tuple containing both the DataFrame with the comments and the full JSON response from the API. You can call the function like this:\n",
    "```python\n",
    "group_id = \"1234567890\"  # replace with your Facebook group ID\n",
    "access_token = \"your_access_token_here\"\n",
    "df, response = get_fb_comments(group_id, access_token)\n",
    "print(df.head())\n",
    "print(response)\n",
    "```\n",
    "This will print the first five rows of the DataFrame and the full JSON response from the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_fb_comments(group_id, access_token):\n",
    "    \"\"\"\n",
    "    Pulls comments from a Facebook group using the Facebook API and outputs the results into a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    group_id (str): The ID of the Facebook group to pull comments from.\n",
    "    access_token (str): A Facebook access token with the necessary permissions to access the group.\n",
    "    \n",
    "    Returns:\n",
    "    Tuple(pandas.DataFrame, dict): A tuple containing a DataFrame with each comment as a row along with its details and replies,\n",
    "    and the full JSON response from the API.\n",
    "    \"\"\"\n",
    "    # Set up the API endpoint and parameters\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"fields\": \"comments{created_time,message,from,comments{created_time,message,from}}\",\n",
    "        \"access_token\": access_token,\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Convert the response to a DataFrame\n",
    "    comments = []\n",
    "    for post in response.json()[\"data\"]:\n",
    "        post_comments = post.get(\"comments\", {}).get(\"data\", [])\n",
    "        for comment in post_comments:\n",
    "            comment_dict = {\n",
    "                \"post_id\": post.get(\"id\"),\n",
    "                \"created_time\": comment.get(\"created_time\"),\n",
    "                \"message\": comment.get(\"message\"),\n",
    "                \"author_id\": comment.get(\"from\", {}).get(\"id\"),\n",
    "                \"author_name\": comment.get(\"from\", {}).get(\"name\"),\n",
    "                \"parent_id\": None,\n",
    "                \"parent_name\": None,\n",
    "            }\n",
    "            parent_comment = comment.get(\"comments\", {}).get(\"data\", [])\n",
    "            if parent_comment:\n",
    "                parent_comment = parent_comment[0]\n",
    "                comment_dict[\"parent_id\"] = parent_comment.get(\"id\")\n",
    "                comment_dict[\"parent_name\"] = parent_comment.get(\"from\", {}).get(\"name\")\n",
    "            comments.append(comment_dict)\n",
    "    df = pd.DataFrame(comments)\n",
    "    return df, response.json()\n",
    "\n",
    "\n",
    "group_id = group_id  # replace with your Facebook group ID\n",
    "access_token = access_token\n",
    "df, response = get_fb_comments(group_id, access_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>parent_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T20:45:46+0000</td>\n",
       "      <td>are protein bars bad for you as they are so pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T21:25:54+0000</td>\n",
       "      <td>Is protein really important ... should do we n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T23:31:32+0000</td>\n",
       "      <td>For those of us entering perimenopause, what s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T03:42:17+0000</td>\n",
       "      <td>What snacks should we lean more towards when s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T04:33:53+0000</td>\n",
       "      <td>These are bloody fantastic questions! I will c...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T04:34:42+0000</td>\n",
       "      <td>@everyone \\n7am Sydney Time Thursday \\n8pm Iri...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3370610399865328</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2139238999669147_3369703796622655</td>\n",
       "      <td>2023-03-21T04:42:48+0000</td>\n",
       "      <td>Set my alarm for 5am today to walk Eddie and b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3369948876598147</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>2023-03-15T13:38:20+0000</td>\n",
       "      <td>Thank you for the info Amanda.  I'm struggling...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3366487800277588</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>2023-03-15T07:39:21+0000</td>\n",
       "      <td>Thank you x</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3366074393652262</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>2023-03-14T20:28:40+0000</td>\n",
       "      <td>ðŸ‘ðŸ™ŒðŸ‘ðŸ™Œ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3365816430344725</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>2023-03-14T20:43:52+0000</td>\n",
       "      <td>Fantastic!!!!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3365816490344719</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>2023-03-14T20:50:22+0000</td>\n",
       "      <td>wow amazing mama Gillian NÃ­ HEachthairn! ðŸ’ª</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3365819093677792</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>2023-03-14T23:38:14+0000</td>\n",
       "      <td>Thanks everyone xx</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>2023-03-15T02:06:26+0000</td>\n",
       "      <td>Amazing results!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3365955733664128</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2139238999669147_3364783420448026</td>\n",
       "      <td>2023-03-13T07:55:08+0000</td>\n",
       "      <td>Maybe something about how to adjust if u go up...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2139238999669147_3364475920478776</td>\n",
       "      <td>2023-03-13T08:16:03+0000</td>\n",
       "      <td>Love this!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3364807133778988</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>2023-03-10T00:20:34+0000</td>\n",
       "      <td>@everyone should have a listen to this one! It...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>2023-03-10T01:57:44+0000</td>\n",
       "      <td>Without a doubt, when Iâ€™m believe in and am pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3362610037332031</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>2023-03-09T23:09:54+0000</td>\n",
       "      <td>ðŸ’¯ agree with how you feel about yourself effec...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3362550477337987</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>2023-03-10T09:33:47+0000</td>\n",
       "      <td>â¤ï¸</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3363181773941524</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2139238999669147_3361852350741133</td>\n",
       "      <td>2023-03-09T08:14:04+0000</td>\n",
       "      <td>Would love to do this but can't make that date...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2139238999669147_3360256357567399</td>\n",
       "      <td>2023-03-07T10:53:51+0000</td>\n",
       "      <td>Do you bulk up when you lift weights?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3360961760830192</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2139238999669147_3357641944495507</td>\n",
       "      <td>2023-03-02T21:03:53+0000</td>\n",
       "      <td>Brilliant. Thank you!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2139238999669147_3357641944495507</td>\n",
       "      <td>2023-03-05T21:07:12+0000</td>\n",
       "      <td>Thank you Amanda Mc Loone</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2139238999669147_3356343101292058</td>\n",
       "      <td>2023-02-28T19:26:21+0000</td>\n",
       "      <td>How can I eat foods and drinks I enjoy but sti...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2139238999669147_3356343101292058</td>\n",
       "      <td>2023-02-28T21:28:47+0000</td>\n",
       "      <td>Looking forward to it!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2139238999669147_3355663884693313</td>\n",
       "      <td>2023-02-28T04:20:50+0000</td>\n",
       "      <td>So much appreciate the honesty to help all of us.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3355943114665390</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2139238999669147_3354957781430590</td>\n",
       "      <td>2023-02-26T20:22:12+0000</td>\n",
       "      <td>Go Devani ðŸ‘</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3355904748002560</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2139238999669147_3354957781430590</td>\n",
       "      <td>2023-02-26T22:02:42+0000</td>\n",
       "      <td>Well done Devani!!!!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3355904931335875</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              post_id              created_time  \\\n",
       "0   2139238999669147_3370347119891656  2023-03-21T20:45:46+0000   \n",
       "1   2139238999669147_3370347119891656  2023-03-21T21:25:54+0000   \n",
       "2   2139238999669147_3370347119891656  2023-03-21T23:31:32+0000   \n",
       "3   2139238999669147_3370347119891656  2023-03-22T03:42:17+0000   \n",
       "4   2139238999669147_3370347119891656  2023-03-22T04:33:53+0000   \n",
       "5   2139238999669147_3370347119891656  2023-03-22T04:34:42+0000   \n",
       "6   2139238999669147_3370342969892071  2023-03-22T05:39:10+0000   \n",
       "7   2139238999669147_3369703796622655  2023-03-21T04:42:48+0000   \n",
       "8   2139238999669147_3366060270320341  2023-03-15T13:38:20+0000   \n",
       "9   2139238999669147_3366060270320341  2023-03-15T07:39:21+0000   \n",
       "10  2139238999669147_3365771280349240  2023-03-14T20:28:40+0000   \n",
       "11  2139238999669147_3365771280349240  2023-03-14T20:43:52+0000   \n",
       "12  2139238999669147_3365771280349240  2023-03-14T20:50:22+0000   \n",
       "13  2139238999669147_3365771280349240  2023-03-14T23:38:14+0000   \n",
       "14  2139238999669147_3365771280349240  2023-03-15T02:06:26+0000   \n",
       "15  2139238999669147_3364783420448026  2023-03-13T07:55:08+0000   \n",
       "16  2139238999669147_3364475920478776  2023-03-13T08:16:03+0000   \n",
       "17  2139238999669147_3362414344018267  2023-03-10T00:20:34+0000   \n",
       "18  2139238999669147_3362414344018267  2023-03-10T01:57:44+0000   \n",
       "19  2139238999669147_3362414344018267  2023-03-09T23:09:54+0000   \n",
       "20  2139238999669147_3362414344018267  2023-03-10T09:33:47+0000   \n",
       "21  2139238999669147_3361852350741133  2023-03-09T08:14:04+0000   \n",
       "22  2139238999669147_3360256357567399  2023-03-07T10:53:51+0000   \n",
       "23  2139238999669147_3357641944495507  2023-03-02T21:03:53+0000   \n",
       "24  2139238999669147_3357641944495507  2023-03-05T21:07:12+0000   \n",
       "25  2139238999669147_3356343101292058  2023-02-28T19:26:21+0000   \n",
       "26  2139238999669147_3356343101292058  2023-02-28T21:28:47+0000   \n",
       "27  2139238999669147_3355663884693313  2023-02-28T04:20:50+0000   \n",
       "28  2139238999669147_3354957781430590  2023-02-26T20:22:12+0000   \n",
       "29  2139238999669147_3354957781430590  2023-02-26T22:02:42+0000   \n",
       "\n",
       "                                              message author_id author_name  \\\n",
       "0   are protein bars bad for you as they are so pr...      None        None   \n",
       "1   Is protein really important ... should do we n...      None        None   \n",
       "2   For those of us entering perimenopause, what s...      None        None   \n",
       "3   What snacks should we lean more towards when s...      None        None   \n",
       "4   These are bloody fantastic questions! I will c...      None        None   \n",
       "5   @everyone \\n7am Sydney Time Thursday \\n8pm Iri...      None        None   \n",
       "6                                           Ree Waugh      None        None   \n",
       "7   Set my alarm for 5am today to walk Eddie and b...      None        None   \n",
       "8   Thank you for the info Amanda.  I'm struggling...      None        None   \n",
       "9                                         Thank you x      None        None   \n",
       "10                                               ðŸ‘ðŸ™ŒðŸ‘ðŸ™Œ      None        None   \n",
       "11                                      Fantastic!!!!      None        None   \n",
       "12         wow amazing mama Gillian NÃ­ HEachthairn! ðŸ’ª      None        None   \n",
       "13                                 Thanks everyone xx      None        None   \n",
       "14                                   Amazing results!      None        None   \n",
       "15  Maybe something about how to adjust if u go up...      None        None   \n",
       "16                                         Love this!      None        None   \n",
       "17  @everyone should have a listen to this one! It...      None        None   \n",
       "18  Without a doubt, when Iâ€™m believe in and am pr...      None        None   \n",
       "19  ðŸ’¯ agree with how you feel about yourself effec...      None        None   \n",
       "20                                                 â¤ï¸      None        None   \n",
       "21  Would love to do this but can't make that date...      None        None   \n",
       "22              Do you bulk up when you lift weights?      None        None   \n",
       "23                              Brilliant. Thank you!      None        None   \n",
       "24                          Thank you Amanda Mc Loone      None        None   \n",
       "25  How can I eat foods and drinks I enjoy but sti...      None        None   \n",
       "26                             Looking forward to it!      None        None   \n",
       "27  So much appreciate the honesty to help all of us.      None        None   \n",
       "28                                        Go Devani ðŸ‘      None        None   \n",
       "29                               Well done Devani!!!!      None        None   \n",
       "\n",
       "           parent_id parent_name  \n",
       "0               None        None  \n",
       "1               None        None  \n",
       "2               None        None  \n",
       "3               None        None  \n",
       "4               None        None  \n",
       "5               None        None  \n",
       "6   3370610399865328        None  \n",
       "7   3369948876598147        None  \n",
       "8   3366487800277588        None  \n",
       "9   3366074393652262        None  \n",
       "10  3365816430344725        None  \n",
       "11  3365816490344719        None  \n",
       "12  3365819093677792        None  \n",
       "13              None        None  \n",
       "14  3365955733664128        None  \n",
       "15              None        None  \n",
       "16  3364807133778988        None  \n",
       "17              None        None  \n",
       "18  3362610037332031        None  \n",
       "19  3362550477337987        None  \n",
       "20  3363181773941524        None  \n",
       "21              None        None  \n",
       "22  3360961760830192        None  \n",
       "23              None        None  \n",
       "24              None        None  \n",
       "25              None        None  \n",
       "26              None        None  \n",
       "27  3355943114665390        None  \n",
       "28  3355904748002560        None  \n",
       "29  3355904931335875        None  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the code to my needs\n",
    "Given the token limits for ChatGPT, it would be more practical for me to adapt ChatGPT's code to create the output I want at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use this in the final code for the task\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_fb_comments(group_id, access_token, limit=25):\n",
    "    \"\"\"\n",
    "    Pulls comments from a Facebook group using the Facebook API and outputs the results into a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    group_id (str): The ID of the Facebook group to pull comments from.\n",
    "    access_token (str): A Facebook access token with the necessary permissions to access the group.\n",
    "    \n",
    "    Returns:\n",
    "    Tuple(pandas.DataFrame, dict): A tuple containing a DataFrame with each comment as a row along with its details and replies,\n",
    "    and the full JSON response from the API.\n",
    "    \"\"\"\n",
    "    # Set up the API endpoint and parameters\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"fields\": \"comments{created_time,message,from,comments{created_time,message,from}}\",\n",
    "        \"access_token\": access_token,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Convert the response to a DataFrame\n",
    "    comments = []\n",
    "    for post in response.json()[\"data\"]:\n",
    "        post_comments = post.get(\"comments\", {}).get(\"data\", [])\n",
    "        for comment in post_comments:\n",
    "            comment_dict = {\n",
    "                \"post_id\": post.get(\"id\"),\n",
    "                \"created_time\": comment.get(\"created_time\"),\n",
    "                \"message\": comment.get(\"message\"),\n",
    "                \"author_id\": comment.get(\"from\", {}).get(\"id\"),\n",
    "                \"author_name\": comment.get(\"from\", {}).get(\"name\"),\n",
    "                \"parent_id\": None,\n",
    "                \"parent_name\": None,\n",
    "            }\n",
    "            parent_comment = comment.get(\"comments\", {}).get(\"data\", [])\n",
    "            if parent_comment:\n",
    "                parent_comment = parent_comment[0]\n",
    "                comment_dict[\"parent_id\"] = parent_comment.get(\"id\")\n",
    "                comment_dict[\"parent_name\"] = parent_comment.get(\"from\", {}).get(\"name\")\n",
    "            comments.append(comment_dict)\n",
    "    df = pd.DataFrame(comments)\n",
    "    return df, response.json()\n",
    "\n",
    "\n",
    "group_id = group_id  # replace with your Facebook group ID\n",
    "access_token = access_token\n",
    "comments_df, comments_response = get_fb_comments(group_id, access_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'comments': {'data': [{'created_time': '2023-03-21T20:45:46+0000',\n",
       "     'message': 'are protein bars bad for you as they are so processed',\n",
       "     'id': '3370383936554641'},\n",
       "    {'created_time': '2023-03-21T21:25:54+0000',\n",
       "     'message': 'Is protein really important ... should do we need to take protein supplements or powder...\\nOr',\n",
       "     'id': '3370399599886408'},\n",
       "    {'created_time': '2023-03-21T23:31:32+0000',\n",
       "     'message': 'For those of us entering perimenopause, what should we be conscious of in our diet?',\n",
       "     'id': '3370448433214858'},\n",
       "    {'created_time': '2023-03-22T03:42:17+0000',\n",
       "     'message': 'What snacks should we lean more towards when snacking and what should we limit in snacking moments?',\n",
       "     'id': '3370548013204900'},\n",
       "    {'created_time': '2023-03-22T04:33:53+0000',\n",
       "     'message': 'These are bloody fantastic questions! I will cover all of these tomorrow \\U0001fae1',\n",
       "     'id': '3370568783202823'},\n",
       "    {'created_time': '2023-03-22T04:34:42+0000',\n",
       "     'message': '@everyone \\n7am Sydney Time Thursday \\n8pm Irish time \\n\\nKeep your eyes peeled!',\n",
       "     'id': '3370569076536127'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURNNE16a3pOalUxTkRZAME1Ub3hOamM1TkRNeE5UUTMZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVMk9UQTNOalV6TmpFeU56b3hOamM1TkRVNU5qZA3oZD'}}},\n",
       "  'id': '2139238999669147_3370347119891656'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-22T05:39:10+0000',\n",
       "     'message': 'Ree Waugh',\n",
       "     'comments': {'data': [{'created_time': '2023-03-22T06:20:38+0000',\n",
       "        'message': 'Zoe Leah itâ€™s good to see isnâ€™t it?',\n",
       "        'id': '3370610399865328'},\n",
       "       {'created_time': '2023-03-22T06:21:05+0000',\n",
       "        'message': 'Amanda Mc Loone yes, very much so ðŸ¤',\n",
       "        'id': '3370610566531978'},\n",
       "       {'created_time': '2023-03-22T06:29:21+0000',\n",
       "        'message': 'Amanda Mc Loone this is so interesting to know! Iâ€™m amazed because sometimes I am always frustrated with the scale though l notice my body changing and getting toned up.',\n",
       "        'id': '3370613349865033'},\n",
       "       {'created_time': '2023-03-22T07:34:23+0000',\n",
       "        'message': 'K Bev Nyirenda scales donâ€™t always show body composition change! Unless you get a full dexa scan youâ€™ve no idea what your skeleton weighs, your water weight etc! Sam is down 600g but I think itâ€™s pretty obvious her body composition is changing?',\n",
       "        'id': '3370641649862203'},\n",
       "       {'created_time': '2023-03-22T08:25:20+0000',\n",
       "        'message': 'Amanda Mc Loone Definitely!',\n",
       "        'id': '3370661996526835'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUld1S1ZAGTUNFM0VJOXpfSTRiU19BRGZAPWE1qTk5OcnhOeGtzeHhUUTM0Y0VKNmxmSEJ0R0tsUVRLbEJZAZAjR5djJNWmdLNUgyX3NBRjNXYzdiS0h5S1p3',\n",
       "        'after': 'QVFIUkFhU28wSW5hY1lkbTZATSEo5cjFSMWhBamVxTGVKYkxUcWRrVmxDZAmJqRFE4bWZADbnVPWlNvQUlZAdnhFdUdPdmlkVG84a0V1X0NaQ3QtRkJkMmlRQmpR'}}},\n",
       "     'id': '3370594463200255'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVNU5EUTJNekl3TURJMU5Ub3hOamM1TkRZAek5UVXgZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVNU5EUTJNekl3TURJMU5Ub3hOamM1TkRZAek5UVXgZD'}}},\n",
       "  'id': '2139238999669147_3370342969892071'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-21T04:42:48+0000',\n",
       "     'message': 'Set my alarm for 5am today to walk Eddie and be at cardio for 6am. Unfortunately, Eddie had different ideas (not his fault, our neighbour keeps feeding him cheap supermarket dog treats)....walked Ed at 2.30am and 4.45am and ended up sleeping until 12 ðŸ˜­',\n",
       "     'comments': {'data': [{'created_time': '2023-03-21T05:17:56+0000',\n",
       "        'message': 'Lisa Calvert but you obvs needed the sleep ðŸ™Œ also how can you stop your neighbour from doing that? Thatâ€™s a nightmare',\n",
       "        'id': '3369948876598147'},\n",
       "       {'created_time': '2023-03-21T05:31:10+0000',\n",
       "        'message': \"Amanda Mc Loone I've asked politely a few times but may need to be a little more assertive now. Poor little guy's tummy was in bits\",\n",
       "        'id': '3369953436597691'},\n",
       "       {'created_time': '2023-03-21T05:32:01+0000',\n",
       "        'message': 'Lisa Calvert nightmare!',\n",
       "        'id': '3369953749930993'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUmU3VmdtYXNVenlKZAGtLLUNreFZAKQzRoS1BWRVBCRk1mYl9iVDk0UnZAwVWdSZAWl2dWpqdmRmT1dMeGo1dVZAfNUlkN201dDdEYTJlZAUpFUXM1ZAjc2R0l3',\n",
       "        'after': 'QVFIUnFTUnVQLXlrYWkxeGpObjRUaWZA1YlV4eV9wTDdwSmFCLTgxNWJnWk1RUkRXT1QyQVpUNk9nTUI4MWN2bDdLMFd0amlzUnNsb2k1UHpKZAHNpdk9na3pR'}}},\n",
       "     'id': '3369936533266048'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yT1Rrek5qVXpNekkyTmpBME9Eb3hOamM1TXpjek56WTQZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yT1Rrek5qVXpNekkyTmpBME9Eb3hOamM1TXpjek56WTQZD'}}},\n",
       "  'id': '2139238999669147_3369703796622655'},\n",
       " {'id': '2139238999669147_3367071606885874'},\n",
       " {'id': '2139238999669147_3366477613611940'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-15T13:38:20+0000',\n",
       "     'message': \"Thank you for the info Amanda.  I'm struggling  how to calculate how much calories, health fats and protein to consume. Thank you ðŸ˜Š\",\n",
       "     'comments': {'data': [{'created_time': '2023-03-15T21:19:52+0000',\n",
       "        'message': 'Lorraine Wilmot Iâ€™m going to message you!',\n",
       "        'id': '3366487800277588'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUm5VV09LeFVXN21SMW9oeElkVU12VHppanp6RjgyQlQ4eG84aTluQ3ZAxN3BVRTNtVmxDdUlhWUFqcDQwLXdoc2I4NE8yd1dvZADRMZA2paUVB6S1lLaHBR',\n",
       "        'after': 'QVFIUm5VV09LeFVXN21SMW9oeElkVU12VHppanp6RjgyQlQ4eG84aTluQ3ZAxN3BVRTNtVmxDdUlhWUFqcDQwLXdoc2I4NE8yd1dvZADRMZA2paUVB6S1lLaHBR'}}},\n",
       "     'id': '3366252306967804'},\n",
       "    {'created_time': '2023-03-15T07:39:21+0000',\n",
       "     'message': 'Thank you x',\n",
       "     'comments': {'data': [{'created_time': '2023-03-15T07:42:57+0000',\n",
       "        'message': 'Jessica Protopapas did you enjoy this?',\n",
       "        'id': '3366074393652262'},\n",
       "       {'created_time': '2023-03-15T08:06:22+0000',\n",
       "        'message': \"Amanda Mc Loone you always give great content. The rep range in particular.......it makes sense. \\nI'm scared of the bulking process......but now I'm underweight with a goal to build muscle. So I kinda don't have a choice.\",\n",
       "        'id': '3366092883650413'},\n",
       "       {'created_time': '2023-03-15T21:19:32+0000',\n",
       "        'message': 'Jessica Protopapas honestly bulking is SO HARD especially being underweight! But again nutrition is going to be a huge part of that! Whatâ€™s your nutrition like?',\n",
       "        'id': '3366487480277620'},\n",
       "       {'created_time': '2023-03-15T21:21:27+0000',\n",
       "        'message': 'Amanda Mc Loone excellent.  My fitness pal food log every day. Maintenance is 2200. Whole foods plus protein shake pre bedtime.',\n",
       "        'id': '3366488646944170'},\n",
       "       {'created_time': '2023-03-16T00:52:38+0000',\n",
       "        'message': 'Jessica Protopapas sounds like youâ€™re on track ðŸ™Œ if you ever need help - just reach out!',\n",
       "        'id': '3366569473602754'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUlFmeEZAPaDV6bHNlRE9YMWVwYjExQlp2MElPYzJyLXRQcmJ5ckxwbENtYjE4VUl2eXhwRHExUWVPWFIxTkJlYWhYeFRLa1V4RUdxR3RRb3NNQlZAtWlVn',\n",
       "        'after': 'QVFIUmJKS1dkWjZAabjRrN2NnaTdnTmxwX2ZAZAUzdkdkFqdERWVVdRTjdUTkZAsbkt4R3JVdDNfa1JydlRHZAlQ0QXVYcUNacXdnQmQwdi0zSTlFRTN0Q0FhR2ZAR'}}},\n",
       "     'id': '3366072910319077'}]},\n",
       "  'id': '2139238999669147_3366060270320341'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-14T20:28:40+0000',\n",
       "     'message': 'ðŸ‘ðŸ™ŒðŸ‘ðŸ™Œ',\n",
       "     'comments': {'data': [{'created_time': '2023-03-14T20:46:02+0000',\n",
       "        'message': 'Emily Davy the best supportive crew â™¥ï¸',\n",
       "        'id': '3365816430344725'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUjZAwNzV3X3lZAM3o4dm5KbG1fbDRxWmNkbzVDamtMaEhpNnpQdzJrZAlJibTNuYllJaU0tM2NVV1pHTXFyUF9NVHJDc1BtUFVXdmRXS2FaNlNQeHZAYOThR',\n",
       "        'after': 'QVFIUjZAwNzV3X3lZAM3o4dm5KbG1fbDRxWmNkbzVDamtMaEhpNnpQdzJrZAlJibTNuYllJaU0tM2NVV1pHTXFyUF9NVHJDc1BtUFVXdmRXS2FaNlNQeHZAYOThR'}}},\n",
       "     'id': '3365809060345462'},\n",
       "    {'created_time': '2023-03-14T20:43:52+0000',\n",
       "     'message': 'Fantastic!!!!',\n",
       "     'comments': {'data': [{'created_time': '2023-03-14T20:46:12+0000',\n",
       "        'message': 'Teresa Madden love the support â™¥ï¸',\n",
       "        'id': '3365816490344719'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUlFxSWpRMTRIRExQQjdRSEQyY29kYWN4UzBFUjV5R1pyM1NTQjFPMzRnUlY4WkpwVWczcjJ3Q293T1N1aC1HOVk2UzI4cVY5bVZAhN052WTVYeFRGZAk93',\n",
       "        'after': 'QVFIUlFxSWpRMTRIRExQQjdRSEQyY29kYWN4UzBFUjV5R1pyM1NTQjFPMzRnUlY4WkpwVWczcjJ3Q293T1N1aC1HOVk2UzI4cVY5bVZAhN052WTVYeFRGZAk93'}}},\n",
       "     'id': '3365815597011475'},\n",
       "    {'created_time': '2023-03-14T20:50:22+0000',\n",
       "     'message': 'wow amazing mama Gillian NÃ­ HEachthairn! ðŸ’ª',\n",
       "     'comments': {'data': [{'created_time': '2023-03-14T20:53:32+0000',\n",
       "        'message': 'Melinda Quinlan mamas supporting mamas â™¥ï¸',\n",
       "        'id': '3365819093677792'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUmRib3k4SGc5azFHODFTRHZAkSk5QTi1ueWtfOGkzY2JuMGpsakpRc21JU2MwaGdFUnVnUzI0ZAU9veWhqSWx5QUJ5N3UwTnN6cFo3VkE2VWhPaW15ejBR',\n",
       "        'after': 'QVFIUmRib3k4SGc5azFHODFTRHZAkSk5QTi1ueWtfOGkzY2JuMGpsakpRc21JU2MwaGdFUnVnUzI0ZAU9veWhqSWx5QUJ5N3UwTnN6cFo3VkE2VWhPaW15ejBR'}}},\n",
       "     'id': '3365817977011237'},\n",
       "    {'created_time': '2023-03-14T23:38:14+0000',\n",
       "     'message': 'Thanks everyone xx',\n",
       "     'id': '3365882037004831'},\n",
       "    {'created_time': '2023-03-15T02:06:26+0000',\n",
       "     'message': 'Amazing results!',\n",
       "     'comments': {'data': [{'created_time': '2023-03-15T02:45:53+0000',\n",
       "        'message': 'Devani John ðŸ™Œ',\n",
       "        'id': '3365955733664128'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUlBhb2tBbXV3Q2p3VmhndVFjdWktV0o4YjFZAZAFRpUHgyRnB4dllrOHFPcEZAMSm9haVZAKQ3ZAyYktBNU9tM1JielJaQVVTcnFCS1NxNXdJd2NSdE1Eem9B',\n",
       "        'after': 'QVFIUlBhb2tBbXV3Q2p3VmhndVFjdWktV0o4YjFZAZAFRpUHgyRnB4dllrOHFPcEZAMSm9haVZAKQ3ZAyYktBNU9tM1JielJaQVVTcnFCS1NxNXdJd2NSdE1Eem9B'}}},\n",
       "     'id': '3365939723665729'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTlRnd09UQTJNRE0wTlRRMk1qb3hOamM0T0RJMU56SXgZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTlRrek9UY3lNelkyTlRjeU9Ub3hOamM0T0RRMU9UZAzMZD'}}},\n",
       "  'id': '2139238999669147_3365771280349240'},\n",
       " {'id': '2139238999669147_3365106907082344'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-13T07:55:08+0000',\n",
       "     'message': 'Maybe something about how to adjust if u go up in weights but the reps are lower and what a good balance is? Donâ€™t know if thatâ€™s to broad a topic though.',\n",
       "     'id': '3364794397113595'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTkRjNU5ETTVOekV4TXpVNU5Ub3hOamM0TmprME1UQTUZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTkRjNU5ETTVOekV4TXpVNU5Ub3hOamM0TmprME1UQTUZD'}}},\n",
       "  'id': '2139238999669147_3364783420448026'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-13T08:16:03+0000',\n",
       "     'message': 'Love this!',\n",
       "     'comments': {'data': [{'created_time': '2023-03-13T08:30:22+0000',\n",
       "        'message': 'Devani John love the support ðŸ™Œâ¤ï¸',\n",
       "        'id': '3364807133778988'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUkhJbGtsd29rRkdYWmtBVE1xWnhiTjZAKRjNmS2QybmlGNk9uODZAjODNGanhIWDZAXUG51NF9pNnpfaXMtNmZAqQlVlSTF1V2xHNFhNd25xa0pMbm9ScGRn',\n",
       "        'after': 'QVFIUkhJbGtsd29rRkdYWmtBVE1xWnhiTjZAKRjNmS2QybmlGNk9uODZAjODNGanhIWDZAXUG51NF9pNnpfaXMtNmZAqQlVlSTF1V2xHNFhNd25xa0pMbm9ScGRn'}}},\n",
       "     'id': '3364801680446200'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTkRnd01UWTRNRFEwTmpJd01Eb3hOamM0TmprMU16WTAZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTkRnd01UWTRNRFEwTmpJd01Eb3hOamM0TmprMU16WTAZD'}}},\n",
       "  'id': '2139238999669147_3364475920478776'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-10T00:20:34+0000',\n",
       "     'message': '@everyone should have a listen to this one! Itâ€™s important ðŸ™',\n",
       "     'id': '3362550657337969'},\n",
       "    {'created_time': '2023-03-10T01:57:44+0000',\n",
       "     'message': 'Without a doubt, when Iâ€™m believe in and am proud of myself my whole family glows ðŸ’ªâ¤ï¸ your program was a god send to me.',\n",
       "     'comments': {'data': [{'created_time': '2023-03-10T02:38:52+0000',\n",
       "        'message': 'Emily Davy proof is in the pudding â¤ï¸ðŸ’ª',\n",
       "        'id': '3362610037332031'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUmNlWkhWaHdRZAUp1TUk5cE5VS0JGdU4wMnJqb0p2SW5OU09xOXBVVFBPQmtJdVY2OGNXaHlnVFdGLWpyMFNZAeFliTUlMd09LYlR5VWVoamxMNkhBNkFR',\n",
       "        'after': 'QVFIUmNlWkhWaHdRZAUp1TUk5cE5VS0JGdU4wMnJqb0p2SW5OU09xOXBVVFBPQmtJdVY2OGNXaHlnVFdGLWpyMFNZAeFliTUlMd09LYlR5VWVoamxMNkhBNkFR'}}},\n",
       "     'id': '3362592534000448'},\n",
       "    {'created_time': '2023-03-09T23:09:54+0000',\n",
       "     'message': 'ðŸ’¯ agree with how you feel about yourself effects those around you. I want to be a better version of myself, not just for me but for my partner and my kids too â¤ï¸ thanks for the video.',\n",
       "     'comments': {'data': [{'created_time': '2023-03-10T00:20:00+0000',\n",
       "        'message': 'Samantha Flanagan yes that is exactly what Iâ€™m trying to get across â¤ï¸ Sometimes we donâ€™t realise how we feel about ourselves reflects on to others - when youâ€™re shining so are the people around you ðŸ¤©Proud of you â¤ï¸ðŸ™',\n",
       "        'id': '3362550477337987'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUkw4OTVrSWJrbFdvTkxiblRid2oyZA0RqVzlpMU1sdWpaZA1RlODNjbW5yWXh4TkFRNzU1cy1XbjhFTldvR1dNel9LRVRJVmczVDRyNk1WZAWEzcFB4QmNR',\n",
       "        'after': 'QVFIUkw4OTVrSWJrbFdvTkxiblRid2oyZA0RqVzlpMU1sdWpaZA1RlODNjbW5yWXh4TkFRNzU1cy1XbjhFTldvR1dNel9LRVRJVmczVDRyNk1WZAWEzcFB4QmNR'}}},\n",
       "     'id': '3362523780673990'},\n",
       "    {'created_time': '2023-03-10T09:33:47+0000',\n",
       "     'message': 'â¤ï¸',\n",
       "     'comments': {'data': [{'created_time': '2023-03-10T22:03:05+0000',\n",
       "        'message': 'Stacey MK did you relate?',\n",
       "        'id': '3363181773941524'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUnlLNTF5TnJDZA3lqZA2lSSmpvNkZAacHNhWnlsZAVpkaE44ZA01SUWQ0TFJldllaRmhhLURLNXJoMF9xUld2MlMtLTVDS2Iyb2ZAnSVJBN2tfaTluTjNvNm1R',\n",
       "        'after': 'QVFIUnlLNTF5TnJDZA3lqZA2lSSmpvNkZAacHNhWnlsZAVpkaE44ZA01SUWQ0TFJldllaRmhhLURLNXJoMF9xUld2MlMtLTVDS2Iyb2ZAnSVJBN2tfaTluTjNvNm1R'}}},\n",
       "     'id': '3362782370648131'}]},\n",
       "  'id': '2139238999669147_3362414344018267'},\n",
       " {'id': '2139238999669147_3362409990685369'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-09T08:14:04+0000',\n",
       "     'message': \"Would love to do this but can't make that date. It will be loads of fun!\",\n",
       "     'id': '3362083374051364'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTWpBNE16TTNOREExTVRNMk5Eb3hOamM0TXpRNU5qUTEZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTWpBNE16TTNOREExTVRNMk5Eb3hOamM0TXpRNU5qUTEZD'}}},\n",
       "  'id': '2139238999669147_3361852350741133'},\n",
       " {'id': '2139238999669147_3360960114163690'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-07T10:53:51+0000',\n",
       "     'message': 'Do you bulk up when you lift weights?',\n",
       "     'comments': {'data': [{'created_time': '2023-03-07T18:47:13+0000',\n",
       "        'message': 'K Bev Nyirenda great question! This is VERY rare unless INTENTIONALLY trying to. My average client will do 3 x 45 mins weights sessions and this will NOT lead to bulking up. However, someone doing body Building will be training especially to bulk up. Does this make sense?',\n",
       "        'id': '3360961760830192'},\n",
       "       {'created_time': '2023-03-10T12:40:02+0000',\n",
       "        'message': 'Yes it does, Thank you. For me l find out that when l lift up weights (not heavy ones) my chest increases in size and my bras become tight.\\nThese days lâ€™m focusing more on light weight and a lot of reps.',\n",
       "        'id': '3362882730638095'},\n",
       "       {'created_time': '2023-03-10T22:04:39+0000',\n",
       "        'message': 'K Bev Nyirenda ironically volume (ie lots of reps) has more of a chance of increasing muscle! But nutrition will ultimately help with this! How is your nutrition?',\n",
       "        'id': '3363182303941471'},\n",
       "       {'created_time': '2023-03-10T23:08:31+0000',\n",
       "        'message': 'Amanda Mc Loone nutrition is good.',\n",
       "        'id': '3363207860605582'},\n",
       "       {'created_time': '2023-03-11T00:25:57+0000',\n",
       "        'message': 'K Bev Nyirenda also every individual is different! Some people build muscle easier than others and vice versa! Iâ€™ve personally been trying to build muscle for 10 years and I find it SO HARD!',\n",
       "        'id': '3363237553935946'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUlI4cUZAVRzFiVHl5Ql93bjVXTDFrUzRQUFZAvYkNVSVIwakFlUFFEb295THhJWGV6VlpxYnNnU1BqZAGo4aHdtblpZAUHRiRml2bmJZAOWRib0ZABSnM4UnB3',\n",
       "        'after': 'QVFIUmg1YkRQYVZAoQUlRdzJ4M1FMaGhDTkJQN3lxWG5iX3ljTGNWeHRfelB3M3J3eWotcVVJOERnWC1pc3A1YUhiNzlWTEgtcnFqTHl1TnpRUzlhXzZAPLVJn'}}},\n",
       "     'id': '3360641684195533'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTURZAME1UWTROREU1TlRVek16b3hOamM0TVRnMk5ETXkZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0yTURZAME1UWTROREU1TlRVek16b3hOamM0TVRnMk5ETXkZD'}}},\n",
       "  'id': '2139238999669147_3360256357567399'},\n",
       " {'id': '2139238999669147_3359640917628943'},\n",
       " {'id': '2139238999669147_3359623880963980'},\n",
       " {'comments': {'data': [{'created_time': '2023-03-02T21:03:53+0000',\n",
       "     'message': 'Brilliant. Thank you!',\n",
       "     'id': '3357685007824534'},\n",
       "    {'created_time': '2023-03-05T21:07:12+0000',\n",
       "     'message': 'Thank you Amanda Mc Loone',\n",
       "     'id': '3359671530959215'}]},\n",
       "  'id': '2139238999669147_3357641944495507'},\n",
       " {'id': '2139238999669147_3357632041163164'},\n",
       " {'id': '2139238999669147_3357043277888707'},\n",
       " {'comments': {'data': [{'created_time': '2023-02-28T19:26:21+0000',\n",
       "     'message': 'How can I eat foods and drinks I enjoy but still loose weight',\n",
       "     'id': '3356350691291299'},\n",
       "    {'created_time': '2023-02-28T21:28:47+0000',\n",
       "     'message': 'Looking forward to it!',\n",
       "     'id': '3356405441285824'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0xTmpNMU1EWTVNVEk1TVRJNU9Ub3hOamMzTmpFeU16ZA3kZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0xTmpRd05UUTBNVEk0TlRneU5Eb3hOamMzTmpFNU56STQZD'}}},\n",
       "  'id': '2139238999669147_3356343101292058'},\n",
       " {'id': '2139238999669147_3356342237958811'},\n",
       " {'comments': {'data': [{'created_time': '2023-02-28T04:20:50+0000',\n",
       "     'message': 'So much appreciate the honesty to help all of us.',\n",
       "     'comments': {'data': [{'created_time': '2023-02-28T06:22:47+0000',\n",
       "        'message': \"Hazel O'leary ah Iâ€™m so glad it helps Hazel â™¥ï¸\",\n",
       "        'id': '3355943114665390'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUlIxdmFZAckYzcTZAZAY1VUM1ZAiSThpajRTX1Y0UmFFMzZAwWXJzVjJpMUhXMDNFZAE5LcTFOaVVHbmtJWkNEV3RPZAFpXNjE1eHdLTV9mV0dZASUFLSWRqS1V3',\n",
       "        'after': 'QVFIUlIxdmFZAckYzcTZAZAY1VUM1ZAiSThpajRTX1Y0UmFFMzZAwWXJzVjJpMUhXMDNFZAE5LcTFOaVVHbmtJWkNEV3RPZAFpXNjE1eHdLTV9mV0dZASUFLSWRqS1V3'}}},\n",
       "     'id': '3355892908003744'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0xTlRnNU1qa3dPREF3TXpjME5Eb3hOamMzTlRVNE1EVXcZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0xTlRnNU1qa3dPREF3TXpjME5Eb3hOamMzTlRVNE1EVXcZD'}}},\n",
       "  'id': '2139238999669147_3355663884693313'},\n",
       " {'comments': {'data': [{'created_time': '2023-02-26T20:22:12+0000',\n",
       "     'message': 'Go Devani ðŸ‘',\n",
       "     'comments': {'data': [{'created_time': '2023-02-28T04:45:00+0000',\n",
       "        'message': 'Connie Kotevski next will be you with your first pull up? ðŸ˜œ',\n",
       "        'id': '3355904748002560'},\n",
       "       {'created_time': '2023-02-28T05:03:10+0000',\n",
       "        'message': 'Amanda Mc Loone donâ€™t hype me up, I think Iâ€™m still a way off ðŸ˜©',\n",
       "        'id': '3355912958001739'},\n",
       "       {'created_time': '2023-02-28T06:23:08+0000',\n",
       "        'message': 'Connie Kotevski I believe in you â¤ï¸ no matter how long it takes ðŸ™Œ',\n",
       "        'id': '3355943227998712'},\n",
       "       {'created_time': '2023-03-01T04:05:07+0000',\n",
       "        'message': 'Connie Kotevski thank you!',\n",
       "        'id': '3356561914603510'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUlVkZAmhvd1VvRXJ5czlKQjI1TnRKVWVneHRMTU91WmZABZAjN3NkVXRmhSOWZAiREtTLWFUQU9MbWtOQmxMNEF5OW92RmlTaHBxa0NNVjBhNTlwTzFzQ0ln',\n",
       "        'after': 'QVFIUkItXzZAWZAUl2VVdjUHhhVUFqQmFfYXdJZAWhHSHY4UWxBanFvZADRDZAHo2OHppcmh3V3c4YllqNXJtZA3ZANQ0dpeXdxUjZAIaHNnU0FNX2FoT0tLZAVgwN3ln'}}},\n",
       "     'id': '3354984584761243'},\n",
       "    {'created_time': '2023-02-26T22:02:42+0000',\n",
       "     'message': 'Well done Devani!!!!',\n",
       "     'comments': {'data': [{'created_time': '2023-02-28T04:45:32+0000',\n",
       "        'message': 'Teresa Madden youâ€™re bossing it too ðŸ’ª',\n",
       "        'id': '3355904931335875'}],\n",
       "      'paging': {'cursors': {'before': 'QVFIUndDemRKRnlEaUZA1SmdYUklfYW5Bbm5UeFR0SUdUSEZAlWVdsY2ZAVblZAiekxtTHFzM2FJaF8zSUk5b3dvMFpsOGdNNV9zYXgzb29KNWJ1MFNZAd3VtaFR3',\n",
       "        'after': 'QVFIUndDemRKRnlEaUZA1SmdYUklfYW5Bbm5UeFR0SUdUSEZAlWVdsY2ZAVblZAiekxtTHFzM2FJaF8zSUk5b3dvMFpsOGdNNV9zYXgzb29KNWJ1MFNZAd3VtaFR3'}}},\n",
       "     'id': '3355027294756972'}],\n",
       "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0xTkRrNE5EVTRORGMyTVRJME16b3hOamMzTkRReU9UTXkZD',\n",
       "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0xTlRBeU56STVORGMxTmprM01qb3hOamMzTkRRNE9UWXoZD'}}},\n",
       "  'id': '2139238999669147_3354957781430590'},\n",
       " {'id': '2139238999669147_3352826951643673'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_response['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>parent_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T20:45:46+0000</td>\n",
       "      <td>are protein bars bad for you as they are so pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T21:25:54+0000</td>\n",
       "      <td>Is protein really important ... should do we n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T23:31:32+0000</td>\n",
       "      <td>For those of us entering perimenopause, what s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T03:42:17+0000</td>\n",
       "      <td>What snacks should we lean more towards when s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T04:33:53+0000</td>\n",
       "      <td>These are bloody fantastic questions! I will c...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T04:34:42+0000</td>\n",
       "      <td>@everyone \\n7am Sydney Time Thursday \\n8pm Iri...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3370610399865328</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2139238999669147_3369703796622655</td>\n",
       "      <td>2023-03-21T04:42:48+0000</td>\n",
       "      <td>Set my alarm for 5am today to walk Eddie and b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3369948876598147</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>2023-03-15T13:38:20+0000</td>\n",
       "      <td>Thank you for the info Amanda.  I'm struggling...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3366487800277588</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>2023-03-15T07:39:21+0000</td>\n",
       "      <td>Thank you x</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3366074393652262</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_id              created_time  \\\n",
       "0  2139238999669147_3370347119891656  2023-03-21T20:45:46+0000   \n",
       "1  2139238999669147_3370347119891656  2023-03-21T21:25:54+0000   \n",
       "2  2139238999669147_3370347119891656  2023-03-21T23:31:32+0000   \n",
       "3  2139238999669147_3370347119891656  2023-03-22T03:42:17+0000   \n",
       "4  2139238999669147_3370347119891656  2023-03-22T04:33:53+0000   \n",
       "5  2139238999669147_3370347119891656  2023-03-22T04:34:42+0000   \n",
       "6  2139238999669147_3370342969892071  2023-03-22T05:39:10+0000   \n",
       "7  2139238999669147_3369703796622655  2023-03-21T04:42:48+0000   \n",
       "8  2139238999669147_3366060270320341  2023-03-15T13:38:20+0000   \n",
       "9  2139238999669147_3366060270320341  2023-03-15T07:39:21+0000   \n",
       "\n",
       "                                             message author_id author_name  \\\n",
       "0  are protein bars bad for you as they are so pr...      None        None   \n",
       "1  Is protein really important ... should do we n...      None        None   \n",
       "2  For those of us entering perimenopause, what s...      None        None   \n",
       "3  What snacks should we lean more towards when s...      None        None   \n",
       "4  These are bloody fantastic questions! I will c...      None        None   \n",
       "5  @everyone \\n7am Sydney Time Thursday \\n8pm Iri...      None        None   \n",
       "6                                          Ree Waugh      None        None   \n",
       "7  Set my alarm for 5am today to walk Eddie and b...      None        None   \n",
       "8  Thank you for the info Amanda.  I'm struggling...      None        None   \n",
       "9                                        Thank you x      None        None   \n",
       "\n",
       "          parent_id parent_name  \n",
       "0              None        None  \n",
       "1              None        None  \n",
       "2              None        None  \n",
       "3              None        None  \n",
       "4              None        None  \n",
       "5              None        None  \n",
       "6  3370610399865328        None  \n",
       "7  3369948876598147        None  \n",
       "8  3366487800277588        None  \n",
       "9  3366074393652262        None  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(comments_df.shape)\n",
    "comments_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_id', 'created_time', 'message', 'author_id', 'author_name',\n",
       "       'parent_id', 'parent_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_id', 'created_time', 'message', 'comments_count', 'like_count',\n",
       "       'love_count', 'wow_count', 'haha_count', 'sad_count', 'angry_count',\n",
       "       'permalink_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 3.3: Merge comments and posts into a single dataframe\n",
    "I have two dataframes:\n",
    "1. The comments_df table has the following columns: ['post_id', 'created_time', 'message', 'author_id', 'author_name',\n",
    "       'parent_id', 'parent_name']\n",
    "2. The posts_df table has the following columns: ['post_id', 'created_time', 'message', 'comments_count', 'like_count',\n",
    "       'love_count', 'wow_count', 'haha_count', 'sad_count', 'angry_count',\n",
    "       'permalink_url']\n",
    "\n",
    "Use Python to generate code to merge the two dataframes to create a table with the following columns:\n",
    "post_id, \n",
    "post_message, \n",
    "post_created_time, \n",
    "comment_created_time, \n",
    "comment_message, \n",
    "parent_id, \n",
    "parent_name\n",
    "\n",
    "The table should include all the comments. This means that rows from posts_df may be duplicated.\n",
    "\n",
    "### Response\n",
    "You can merge the two dataframes using the merge() method of pandas. You will need to merge on the post_id column, which is common to both dataframes. To include all comments, even those without a parent comment, use a left join so that all rows from the comments_df table are included. Here's the code:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# read in the dataframes\n",
    "comments_df = pd.read_csv('comments.csv')\n",
    "posts_df = pd.read_csv('posts.csv')\n",
    "\n",
    "# merge the dataframes\n",
    "merged_df = pd.merge(comments_df, posts_df, on='post_id', how='left')\n",
    "\n",
    "# select the desired columns\n",
    "merged_df = merged_df[['post_id', 'message_y', 'created_time_y', 'created_time_x', 'message_x', 'parent_id', 'parent_name']]\n",
    "\n",
    "# rename the columns\n",
    "merged_df.columns = ['post_id', 'post_message', 'post_created_time', 'comment_created_time', 'comment_message', 'parent_id', 'parent_name']\n",
    "\n",
    "# save the merged dataframe to a csv file\n",
    "merged_df.to_csv('merged.csv', index=False)\n",
    "```\n",
    "Here, the merge() method is used to join the two dataframes on the post_id column with a left join. The resulting dataframe includes all comments and may contain duplicated rows from the posts_df. Then, the desired columns are selected and the column names are renamed to match the desired output. Finally, the merged dataframe is saved to a csv file called merged.csv with the to_csv() method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_message</th>\n",
       "      <th>post_created_time</th>\n",
       "      <th>comment_created_time</th>\n",
       "      <th>comment_message</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>parent_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-21T20:45:46+0000</td>\n",
       "      <td>are protein bars bad for you as they are so pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-21T21:25:54+0000</td>\n",
       "      <td>Is protein really important ... should do we n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-21T23:31:32+0000</td>\n",
       "      <td>For those of us entering perimenopause, what s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T03:42:17+0000</td>\n",
       "      <td>What snacks should we lean more towards when s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T04:33:53+0000</td>\n",
       "      <td>These are bloody fantastic questions! I will c...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T04:34:42+0000</td>\n",
       "      <td>@everyone \\n7am Sydney Time Thursday \\n8pm Iri...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370610399865328</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2139238999669147_3369703796622655</td>\n",
       "      <td>Why your morning routine may actually be NEGAT...</td>\n",
       "      <td>2023-03-20T18:56:34+0000</td>\n",
       "      <td>2023-03-21T04:42:48+0000</td>\n",
       "      <td>Set my alarm for 5am today to walk Eddie and b...</td>\n",
       "      <td>3369948876598147</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>2023-03-15T13:38:20+0000</td>\n",
       "      <td>Thank you for the info Amanda.  I'm struggling...</td>\n",
       "      <td>3366487800277588</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>2023-03-15T07:39:21+0000</td>\n",
       "      <td>Thank you x</td>\n",
       "      <td>3366074393652262</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-14T20:28:40+0000</td>\n",
       "      <td>ðŸ‘ðŸ™ŒðŸ‘ðŸ™Œ</td>\n",
       "      <td>3365816430344725</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-14T20:43:52+0000</td>\n",
       "      <td>Fantastic!!!!</td>\n",
       "      <td>3365816490344719</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-14T20:50:22+0000</td>\n",
       "      <td>wow amazing mama Gillian NÃ­ HEachthairn! ðŸ’ª</td>\n",
       "      <td>3365819093677792</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-14T23:38:14+0000</td>\n",
       "      <td>Thanks everyone xx</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-15T02:06:26+0000</td>\n",
       "      <td>Amazing results!</td>\n",
       "      <td>3365955733664128</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2139238999669147_3364783420448026</td>\n",
       "      <td>@everyone would love your help with the live t...</td>\n",
       "      <td>2023-03-13T07:29:09+0000</td>\n",
       "      <td>2023-03-13T07:55:08+0000</td>\n",
       "      <td>Maybe something about how to adjust if u go up...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2139238999669147_3364475920478776</td>\n",
       "      <td>Have your ever tried on a pair of shorts - jus...</td>\n",
       "      <td>2023-03-12T18:50:47+0000</td>\n",
       "      <td>2023-03-13T08:16:03+0000</td>\n",
       "      <td>Love this!</td>\n",
       "      <td>3364807133778988</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-10T00:20:34+0000</td>\n",
       "      <td>@everyone should have a listen to this one! It...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-10T01:57:44+0000</td>\n",
       "      <td>Without a doubt, when Iâ€™m believe in and am pr...</td>\n",
       "      <td>3362610037332031</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-09T23:09:54+0000</td>\n",
       "      <td>ðŸ’¯ agree with how you feel about yourself effec...</td>\n",
       "      <td>3362550477337987</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-10T09:33:47+0000</td>\n",
       "      <td>â¤ï¸</td>\n",
       "      <td>3363181773941524</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2139238999669147_3361852350741133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-09T08:14:04+0000</td>\n",
       "      <td>Would love to do this but can't make that date...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2139238999669147_3360256357567399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-07T10:53:51+0000</td>\n",
       "      <td>Do you bulk up when you lift weights?</td>\n",
       "      <td>3360961760830192</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2139238999669147_3357641944495507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-02T21:03:53+0000</td>\n",
       "      <td>Brilliant. Thank you!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2139238999669147_3357641944495507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-05T21:07:12+0000</td>\n",
       "      <td>Thank you Amanda Mc Loone</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2139238999669147_3356343101292058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-28T19:26:21+0000</td>\n",
       "      <td>How can I eat foods and drinks I enjoy but sti...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2139238999669147_3356343101292058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-28T21:28:47+0000</td>\n",
       "      <td>Looking forward to it!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2139238999669147_3355663884693313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-28T04:20:50+0000</td>\n",
       "      <td>So much appreciate the honesty to help all of us.</td>\n",
       "      <td>3355943114665390</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2139238999669147_3354957781430590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-26T20:22:12+0000</td>\n",
       "      <td>Go Devani ðŸ‘</td>\n",
       "      <td>3355904748002560</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2139238999669147_3354957781430590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-26T22:02:42+0000</td>\n",
       "      <td>Well done Devani!!!!</td>\n",
       "      <td>3355904931335875</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              post_id  \\\n",
       "0   2139238999669147_3370347119891656   \n",
       "1   2139238999669147_3370347119891656   \n",
       "2   2139238999669147_3370347119891656   \n",
       "3   2139238999669147_3370347119891656   \n",
       "4   2139238999669147_3370347119891656   \n",
       "5   2139238999669147_3370347119891656   \n",
       "6   2139238999669147_3370342969892071   \n",
       "7   2139238999669147_3369703796622655   \n",
       "8   2139238999669147_3366060270320341   \n",
       "9   2139238999669147_3366060270320341   \n",
       "10  2139238999669147_3365771280349240   \n",
       "11  2139238999669147_3365771280349240   \n",
       "12  2139238999669147_3365771280349240   \n",
       "13  2139238999669147_3365771280349240   \n",
       "14  2139238999669147_3365771280349240   \n",
       "15  2139238999669147_3364783420448026   \n",
       "16  2139238999669147_3364475920478776   \n",
       "17  2139238999669147_3362414344018267   \n",
       "18  2139238999669147_3362414344018267   \n",
       "19  2139238999669147_3362414344018267   \n",
       "20  2139238999669147_3362414344018267   \n",
       "21  2139238999669147_3361852350741133   \n",
       "22  2139238999669147_3360256357567399   \n",
       "23  2139238999669147_3357641944495507   \n",
       "24  2139238999669147_3357641944495507   \n",
       "25  2139238999669147_3356343101292058   \n",
       "26  2139238999669147_3356343101292058   \n",
       "27  2139238999669147_3355663884693313   \n",
       "28  2139238999669147_3354957781430590   \n",
       "29  2139238999669147_3354957781430590   \n",
       "\n",
       "                                         post_message  \\\n",
       "0   @everyone for team training this week. A vast ...   \n",
       "1   @everyone for team training this week. A vast ...   \n",
       "2   @everyone for team training this week. A vast ...   \n",
       "3   @everyone for team training this week. A vast ...   \n",
       "4   @everyone for team training this week. A vast ...   \n",
       "5   @everyone for team training this week. A vast ...   \n",
       "6   How shocked would you be if I told you - there...   \n",
       "7   Why your morning routine may actually be NEGAT...   \n",
       "8   Calories in versus calories out (how do I over...   \n",
       "9   Calories in versus calories out (how do I over...   \n",
       "10  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "11  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "12  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "13  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "14  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "15  @everyone would love your help with the live t...   \n",
       "16  Have your ever tried on a pair of shorts - jus...   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "\n",
       "           post_created_time      comment_created_time  \\\n",
       "0   2023-03-21T19:11:52+0000  2023-03-21T20:45:46+0000   \n",
       "1   2023-03-21T19:11:52+0000  2023-03-21T21:25:54+0000   \n",
       "2   2023-03-21T19:11:52+0000  2023-03-21T23:31:32+0000   \n",
       "3   2023-03-21T19:11:52+0000  2023-03-22T03:42:17+0000   \n",
       "4   2023-03-21T19:11:52+0000  2023-03-22T04:33:53+0000   \n",
       "5   2023-03-21T19:11:52+0000  2023-03-22T04:34:42+0000   \n",
       "6   2023-03-21T19:02:42+0000  2023-03-22T05:39:10+0000   \n",
       "7   2023-03-20T18:56:34+0000  2023-03-21T04:42:48+0000   \n",
       "8   2023-03-15T07:02:37+0000  2023-03-15T13:38:20+0000   \n",
       "9   2023-03-15T07:02:37+0000  2023-03-15T07:39:21+0000   \n",
       "10  2023-03-14T19:04:59+0000  2023-03-14T20:28:40+0000   \n",
       "11  2023-03-14T19:04:59+0000  2023-03-14T20:43:52+0000   \n",
       "12  2023-03-14T19:04:59+0000  2023-03-14T20:50:22+0000   \n",
       "13  2023-03-14T19:04:59+0000  2023-03-14T23:38:14+0000   \n",
       "14  2023-03-14T19:04:59+0000  2023-03-15T02:06:26+0000   \n",
       "15  2023-03-13T07:29:09+0000  2023-03-13T07:55:08+0000   \n",
       "16  2023-03-12T18:50:47+0000  2023-03-13T08:16:03+0000   \n",
       "17                       NaN  2023-03-10T00:20:34+0000   \n",
       "18                       NaN  2023-03-10T01:57:44+0000   \n",
       "19                       NaN  2023-03-09T23:09:54+0000   \n",
       "20                       NaN  2023-03-10T09:33:47+0000   \n",
       "21                       NaN  2023-03-09T08:14:04+0000   \n",
       "22                       NaN  2023-03-07T10:53:51+0000   \n",
       "23                       NaN  2023-03-02T21:03:53+0000   \n",
       "24                       NaN  2023-03-05T21:07:12+0000   \n",
       "25                       NaN  2023-02-28T19:26:21+0000   \n",
       "26                       NaN  2023-02-28T21:28:47+0000   \n",
       "27                       NaN  2023-02-28T04:20:50+0000   \n",
       "28                       NaN  2023-02-26T20:22:12+0000   \n",
       "29                       NaN  2023-02-26T22:02:42+0000   \n",
       "\n",
       "                                      comment_message         parent_id  \\\n",
       "0   are protein bars bad for you as they are so pr...              None   \n",
       "1   Is protein really important ... should do we n...              None   \n",
       "2   For those of us entering perimenopause, what s...              None   \n",
       "3   What snacks should we lean more towards when s...              None   \n",
       "4   These are bloody fantastic questions! I will c...              None   \n",
       "5   @everyone \\n7am Sydney Time Thursday \\n8pm Iri...              None   \n",
       "6                                           Ree Waugh  3370610399865328   \n",
       "7   Set my alarm for 5am today to walk Eddie and b...  3369948876598147   \n",
       "8   Thank you for the info Amanda.  I'm struggling...  3366487800277588   \n",
       "9                                         Thank you x  3366074393652262   \n",
       "10                                               ðŸ‘ðŸ™ŒðŸ‘ðŸ™Œ  3365816430344725   \n",
       "11                                      Fantastic!!!!  3365816490344719   \n",
       "12         wow amazing mama Gillian NÃ­ HEachthairn! ðŸ’ª  3365819093677792   \n",
       "13                                 Thanks everyone xx              None   \n",
       "14                                   Amazing results!  3365955733664128   \n",
       "15  Maybe something about how to adjust if u go up...              None   \n",
       "16                                         Love this!  3364807133778988   \n",
       "17  @everyone should have a listen to this one! It...              None   \n",
       "18  Without a doubt, when Iâ€™m believe in and am pr...  3362610037332031   \n",
       "19  ðŸ’¯ agree with how you feel about yourself effec...  3362550477337987   \n",
       "20                                                 â¤ï¸  3363181773941524   \n",
       "21  Would love to do this but can't make that date...              None   \n",
       "22              Do you bulk up when you lift weights?  3360961760830192   \n",
       "23                              Brilliant. Thank you!              None   \n",
       "24                          Thank you Amanda Mc Loone              None   \n",
       "25  How can I eat foods and drinks I enjoy but sti...              None   \n",
       "26                             Looking forward to it!              None   \n",
       "27  So much appreciate the honesty to help all of us.  3355943114665390   \n",
       "28                                        Go Devani ðŸ‘  3355904748002560   \n",
       "29                               Well done Devani!!!!  3355904931335875   \n",
       "\n",
       "   parent_name  \n",
       "0         None  \n",
       "1         None  \n",
       "2         None  \n",
       "3         None  \n",
       "4         None  \n",
       "5         None  \n",
       "6         None  \n",
       "7         None  \n",
       "8         None  \n",
       "9         None  \n",
       "10        None  \n",
       "11        None  \n",
       "12        None  \n",
       "13        None  \n",
       "14        None  \n",
       "15        None  \n",
       "16        None  \n",
       "17        None  \n",
       "18        None  \n",
       "19        None  \n",
       "20        None  \n",
       "21        None  \n",
       "22        None  \n",
       "23        None  \n",
       "24        None  \n",
       "25        None  \n",
       "26        None  \n",
       "27        None  \n",
       "28        None  \n",
       "29        None  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# merge the dataframes\n",
    "merged_df = pd.merge(comments_df, posts_df, on='post_id', how='left')\n",
    "\n",
    "# select the desired columns\n",
    "merged_df = merged_df[['post_id', 'message_y', 'created_time_y', 'created_time_x', 'message_x', 'parent_id', 'parent_name']]\n",
    "\n",
    "# rename the columns\n",
    "merged_df.columns = ['post_id', 'post_message', 'post_created_time', 'comment_created_time', 'comment_message', 'parent_id', 'parent_name']\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 3.4: Pulling comment replies\n",
    "I have a Python json object in the following format:\n",
    "[{'comments': {'data': [{'created_time': '2023-03-21T20:45:46+0000',\n",
    "     'message': 'are protein bars bad for you as they are so processed',\n",
    "     'id': '3370383936554641'},\n",
    "    {'created_time': '2023-03-21T21:25:54+0000',\n",
    "     'message': 'Is protein really important ... should do we need to take protein supplements or powder...\\nOr',\n",
    "     'id': '3370399599886408'},\n",
    "    {'created_time': '2023-03-22T04:34:42+0000',\n",
    "     'message': '@everyone \\n7am Sydney Time Thursday \\n8pm Irish time \\n\\nKeep your eyes peeled!',\n",
    "     'id': '3370569076536127'}],\n",
    "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURNNE16a3pOalUxTkRZAME1Ub3hOamM1TkRNeE5UUTMZD',\n",
    "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVMk9UQTNOalV6TmpFeU56b3hOamM1TkRVNU5qZA3oZD'}}},\n",
    "  'id': '2139238999669147_3370347119891656'},\n",
    " {'comments': {'data': [{'created_time': '2023-03-22T05:39:10+0000',\n",
    "     'message': 'Ree Waugh',\n",
    "     'comments': {'data': [{'created_time': '2023-03-22T06:20:38+0000',\n",
    "        'message': 'Zoe Leah itâ€™s good to see isnâ€™t it?',\n",
    "        'id': '3370610399865328'},\n",
    "       {'created_time': '2023-03-22T08:25:20+0000',\n",
    "        'message': 'Amanda Mc Loone Definitely!',\n",
    "        'id': '3370661996526835'}],\n",
    "      'paging': {'cursors': {'before': 'QVFIUld1S1ZAGTUNFM0VJOXpfSTRiU19BRGZAPWE1qTk5OcnhOeGtzeHhUUTM0Y0VKNmxmSEJ0R0tsUVRLbEJZAZAjR5djJNWmdLNUgyX3NBRjNXYzdiS0h5S1p3',\n",
    "        'after': 'QVFIUkFhU28wSW5hY1lkbTZATSEo5cjFSMWhBamVxTGVKYkxUcWRrVmxDZAmJqRFE4bWZADbnVPWlNvQUlZAdnhFdUdPdmlkVG84a0V1X0NaQ3QtRkJkMmlRQmpR'}}},\n",
    "     'id': '3370594463200255'}],\n",
    "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVNU5EUTJNekl3TURJMU5Ub3hOamM1TkRZAek5UVXgZD',\n",
    "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVNU5EUTJNekl3TURJMU5Ub3hOamM1TkRZAek5UVXgZD'}}},\n",
    "  'id': '2139238999669147_3370342969892071'},\n",
    "...\n",
    "]\n",
    "\n",
    "Write a Python function that uses this data to create a dataframe that contains only the replies to the comments.\n",
    "The dataframe should have these columns: post_id, parent_comment_message, comment_id, reply_comment_message, reply_created_time, reply_id.\n",
    "\n",
    "### Response\n",
    "Here's a Python function that takes in the json object and creates a pandas dataframe with the desired columns:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def create_reply_dataframe(json_object):\n",
    "    # Initialize empty lists to store data\n",
    "    post_id_list = []\n",
    "    parent_comment_message_list = []\n",
    "    comment_id_list = []\n",
    "    reply_comment_message_list = []\n",
    "    reply_created_time_list = []\n",
    "    reply_id_list = []\n",
    "    \n",
    "    # Loop through each post in the json object\n",
    "    for post in json_object:\n",
    "        # Get the post ID\n",
    "        post_id = post['id']\n",
    "        \n",
    "        # Loop through each comment in the post\n",
    "        for comment in post['comments']['data']:\n",
    "            # Get the comment ID and message\n",
    "            comment_id = comment['id']\n",
    "            parent_comment_message = comment['message']\n",
    "            \n",
    "            # Check if the comment has any replies\n",
    "            if 'comments' in comment:\n",
    "                # Loop through each reply to the comment\n",
    "                for reply in comment['comments']['data']:\n",
    "                    # Get the reply ID, message, and creation time\n",
    "                    reply_id = reply['id']\n",
    "                    reply_comment_message = reply['message']\n",
    "                    reply_created_time = reply['created_time']\n",
    "                    \n",
    "                    # Add the data to the lists\n",
    "                    post_id_list.append(post_id)\n",
    "                    parent_comment_message_list.append(parent_comment_message)\n",
    "                    comment_id_list.append(comment_id)\n",
    "                    reply_comment_message_list.append(reply_comment_message)\n",
    "                    reply_created_time_list.append(reply_created_time)\n",
    "                    reply_id_list.append(reply_id)\n",
    "    \n",
    "    # Create a dataframe from the lists\n",
    "    df = pd.DataFrame({\n",
    "        'post_id': post_id_list,\n",
    "        'parent_comment_message': parent_comment_message_list,\n",
    "        'comment_id': comment_id_list,\n",
    "        'reply_comment_message': reply_comment_message_list,\n",
    "        'reply_created_time': reply_created_time_list,\n",
    "        'reply_id': reply_id_list\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "```\n",
    "You can use this function like this:\n",
    "```python\n",
    "json_object = [{'comments': {'data': [{'created_time': '2023-03-21T20:45:46+0000',\n",
    "     'message': 'are protein bars bad for you as they are so processed',\n",
    "     'id': '3370383936554641'},\n",
    "    {'created_time': '2023-03-21T21:25:54+0000',\n",
    "     'message': 'Is protein really important ... should do we need to take protein supplements or powder...\\nOr',\n",
    "     'id': '3370399599886408'},\n",
    "    {'created_time': '2023-03-22T04:34:42+0000',\n",
    "     'message': '@everyone \\n7am Sydney Time Thursday \\n8pm Irish time \\n\\nKeep your eyes peeled!',\n",
    "     'id': '3370569076536127'}],\n",
    "   'paging': {'cursors': {'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURNNE16a3pOalUxTkRZAME1Ub3hOamM1TkRNeE5UUTMZD',\n",
    "     'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZANek0zTURVMk9UQTNOalV6TmpFeU56b3hOamM1TkRVNU5qZA3oZD'}}},\n",
    "  'id': '2139238999669147_3370347119891656'},\n",
    " {'comments': {'data': [{'created_time': '2023-03-22T05:39:10+0000',\n",
    "     'message\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\notebooks\\2023-03-22 ChatGPT GUI FB group.ipynb Cell 58\u001b[0m in \u001b[0;36m5\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mpost_id\u001b[39m\u001b[39m'\u001b[39m: post_id_list,\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mparent_comment_message\u001b[39m\u001b[39m'\u001b[39m: parent_comment_message_list,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mreply_id\u001b[39m\u001b[39m'\u001b[39m: reply_id_list\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     })\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m replies \u001b[39m=\u001b[39m create_reply_dataframe(comments_response)\n",
      "\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\notebooks\\2023-03-22 ChatGPT GUI FB group.ipynb Cell 58\u001b[0m in \u001b[0;36m1\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Loop through each post in the json object\u001b[39;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m post \u001b[39min\u001b[39;00m json_object:\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# Get the post ID\u001b[39;00m\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     post_id \u001b[39m=\u001b[39m post[\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Loop through each comment in the post\u001b[39;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mfor\u001b[39;00m comment \u001b[39min\u001b[39;00m post[\u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y101sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39m# Get the comment ID and message\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_reply_dataframe(json_object):\n",
    "    # Initialize empty lists to store data\n",
    "    post_id_list = []\n",
    "    parent_comment_message_list = []\n",
    "    comment_id_list = []\n",
    "    reply_comment_message_list = []\n",
    "    reply_created_time_list = []\n",
    "    reply_id_list = []\n",
    "    \n",
    "    # Loop through each post in the json object\n",
    "    for post in json_object:\n",
    "        # Get the post ID\n",
    "        post_id = post['id']\n",
    "        \n",
    "        # Loop through each comment in the post\n",
    "        for comment in post['comments']['data']:\n",
    "            # Get the comment ID and message\n",
    "            comment_id = comment['id']\n",
    "            parent_comment_message = comment['message']\n",
    "            \n",
    "            # Check if the comment has any replies\n",
    "            if 'comments' in comment:\n",
    "                # Loop through each reply to the comment\n",
    "                for reply in comment['comments']['data']:\n",
    "                    # Get the reply ID, message, and creation time\n",
    "                    reply_id = reply['id']\n",
    "                    reply_comment_message = reply['message']\n",
    "                    reply_created_time = reply['created_time']\n",
    "                    \n",
    "                    # Add the data to the lists\n",
    "                    post_id_list.append(post_id)\n",
    "                    parent_comment_message_list.append(parent_comment_message)\n",
    "                    comment_id_list.append(comment_id)\n",
    "                    reply_comment_message_list.append(reply_comment_message)\n",
    "                    reply_created_time_list.append(reply_created_time)\n",
    "                    reply_id_list.append(reply_id)\n",
    "    \n",
    "    # Create a dataframe from the lists\n",
    "    df = pd.DataFrame({\n",
    "        'post_id': post_id_list,\n",
    "        'parent_comment_message': parent_comment_message_list,\n",
    "        'comment_id': comment_id_list,\n",
    "        'reply_comment_message': reply_comment_message_list,\n",
    "        'reply_created_time': reply_created_time_list,\n",
    "        'reply_id': reply_id_list\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "replies = create_reply_dataframe(comments_response['data'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the code\n",
    "ChatGPT's code resulted in error messages. Upon examination, it's because not all comments have replies. I added the `try` and `except` statements and that fixed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_reply_dataframe(json_object):\n",
    "    # Initialize empty lists to store data\n",
    "    post_id_list = []\n",
    "    parent_comment_message_list = []\n",
    "    comment_id_list = []\n",
    "    reply_comment_message_list = []\n",
    "    reply_created_time_list = []\n",
    "    reply_id_list = []\n",
    "    \n",
    "    # Loop through each post in the json object\n",
    "    for post in json_object:\n",
    "        # Get the post ID\n",
    "        post_id = post['id']\n",
    "        \n",
    "        try: # SH 2023-03-22 10:50 Added this \n",
    "            # Loop through each comment in the post\n",
    "            for comment in post['comments']['data']:\n",
    "                # Get the comment ID and message\n",
    "                comment_id = comment['id']\n",
    "                parent_comment_message = comment['message']\n",
    "                \n",
    "                # Check if the comment has any replies\n",
    "                # if 'comments' in comment:\n",
    "                if 'comments' in comment:\n",
    "                    # Loop through each reply to the comment\n",
    "                    for reply in comment['comments']['data']:\n",
    "                        # Get the reply ID, message, and creation time\n",
    "                        reply_id = reply['id']\n",
    "                        reply_comment_message = reply['message']\n",
    "                        reply_created_time = reply['created_time']\n",
    "                        \n",
    "                        # Add the data to the lists\n",
    "                        post_id_list.append(post_id)\n",
    "                        parent_comment_message_list.append(parent_comment_message)\n",
    "                        comment_id_list.append(comment_id)\n",
    "                        reply_comment_message_list.append(reply_comment_message)\n",
    "                        reply_created_time_list.append(reply_created_time)\n",
    "                        reply_id_list.append(reply_id)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Create a dataframe from the lists\n",
    "    df = pd.DataFrame({\n",
    "        'post_id': post_id_list,\n",
    "        'parent_comment_message': parent_comment_message_list,\n",
    "        'comment_id': comment_id_list,\n",
    "        'reply_comment_message': reply_comment_message_list,\n",
    "        'reply_created_time': reply_created_time_list,\n",
    "        'reply_id': reply_id_list\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "replies = create_reply_dataframe(comments_response['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_comment_message</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>reply_comment_message</th>\n",
       "      <th>reply_created_time</th>\n",
       "      <th>reply_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Zoe Leah itâ€™s good to see isnâ€™t it?</td>\n",
       "      <td>2023-03-22T06:20:38+0000</td>\n",
       "      <td>3370610399865328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone yes, very much so ðŸ¤</td>\n",
       "      <td>2023-03-22T06:21:05+0000</td>\n",
       "      <td>3370610566531978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone this is so interesting to know...</td>\n",
       "      <td>2023-03-22T06:29:21+0000</td>\n",
       "      <td>3370613349865033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>K Bev Nyirenda scales donâ€™t always show body c...</td>\n",
       "      <td>2023-03-22T07:34:23+0000</td>\n",
       "      <td>3370641649862203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone Definitely!</td>\n",
       "      <td>2023-03-22T08:25:20+0000</td>\n",
       "      <td>3370661996526835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_id parent_comment_message        comment_id  \\\n",
       "0  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "1  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "2  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "3  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "4  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "\n",
       "                               reply_comment_message  \\\n",
       "0                Zoe Leah itâ€™s good to see isnâ€™t it?   \n",
       "1                Amanda Mc Loone yes, very much so ðŸ¤   \n",
       "2  Amanda Mc Loone this is so interesting to know...   \n",
       "3  K Bev Nyirenda scales donâ€™t always show body c...   \n",
       "4                        Amanda Mc Loone Definitely!   \n",
       "\n",
       "         reply_created_time          reply_id  \n",
       "0  2023-03-22T06:20:38+0000  3370610399865328  \n",
       "1  2023-03-22T06:21:05+0000  3370610566531978  \n",
       "2  2023-03-22T06:29:21+0000  3370613349865033  \n",
       "3  2023-03-22T07:34:23+0000  3370641649862203  \n",
       "4  2023-03-22T08:25:20+0000  3370661996526835  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 3.5 Merge posts, comments, and replies\n",
    "\n",
    "I have 3 dataframes:\n",
    "1. The comments_df dataframe has the following columns: ['post_id', 'created_time', 'message', 'author_id', 'author_name',\n",
    "       'parent_id', 'parent_name']\n",
    "2. The posts_df dataframe has the following columns: ['post_id', 'created_time', 'message', 'comments_count', 'like_count',\n",
    "       'love_count', 'wow_count', 'haha_count', 'sad_count', 'angry_count',\n",
    "       'permalink_url']\n",
    "3. The replies dataframe has the following columns: ['post_id', 'parent_comment_message', 'comment_id',\n",
    "       'reply_comment_message', 'reply_created_time', 'reply_id']\n",
    "\n",
    "Write a python function to merge the dataframes to create a table with the following columns:\n",
    "post_id, \n",
    "post_message, \n",
    "post_created_time, \n",
    "comment_created_time, \n",
    "comment_message, \n",
    "parent_id, \n",
    "parent_name,\n",
    "reply_comment_message, \n",
    "reply_created_time, \n",
    "reply_id\n",
    "\n",
    "The table should include all the comments and replies. This means that rows from posts_df and comments_df may be duplicated.\n",
    "\n",
    "### Response\n",
    "Here is the Python function to merge the dataframes:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def merge_dataframes(comments_df, posts_df, replies_df):\n",
    "    # merge comments and posts dataframes on post_id\n",
    "    merged_df = pd.merge(comments_df, posts_df, on='post_id', how='outer')\n",
    "    # merge replies dataframe on comment_id\n",
    "    merged_df = pd.merge(merged_df, replies_df, left_on='parent_id', right_on='comment_id', how='left')\n",
    "    # rename columns\n",
    "    merged_df = merged_df.rename(columns={\n",
    "        'created_time_x': 'comment_created_time',\n",
    "        'created_time_y': 'post_created_time',\n",
    "        'message_x': 'comment_message',\n",
    "        'message_y': 'post_message',\n",
    "        'parent_name_x': 'parent_name',\n",
    "        'reply_comment_message': 'reply_message',\n",
    "        'reply_created_time': 'reply_created_time',\n",
    "        'reply_id': 'reply_id'\n",
    "    })\n",
    "    # drop unnecessary columns\n",
    "    merged_df = merged_df.drop(columns=['parent_id', 'parent_name_y', 'comment_id'])\n",
    "    # reorder columns\n",
    "    merged_df = merged_df[['post_id', 'post_message', 'post_created_time', 'comment_created_time', 'comment_message',\n",
    "                           'parent_id', 'parent_name', 'reply_message', 'reply_created_time', 'reply_id']]\n",
    "    return merged_df\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['parent_name_y'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\notebooks\\2023-03-22 ChatGPT GUI FB group.ipynb Cell 64\u001b[0m in \u001b[0;36m1\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m merged \u001b[39m=\u001b[39m merge_dataframes(comments_df, posts_df, replies)\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m merged\u001b[39m.\u001b[39mhead()\n",
      "\n",
      "\u001b[1;32mc:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\notebooks\\2023-03-22 ChatGPT GUI FB group.ipynb Cell 64\u001b[0m in \u001b[0;36m1\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m merged_df \u001b[39m=\u001b[39m merged_df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcreated_time_x\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mcomment_created_time\u001b[39m\u001b[39m'\u001b[39m,\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcreated_time_y\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mpost_created_time\u001b[39m\u001b[39m'\u001b[39m,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mreply_id\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mreply_id\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m })\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m \u001b[39m# drop unnecessary columns\u001b[39;00m\n",
      "\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m merged_df \u001b[39m=\u001b[39m merged_df\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mparent_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mparent_name_y\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcomment_id\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m \u001b[39m# reorder columns\u001b[39;00m\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m merged_df \u001b[39m=\u001b[39m merged_df[[\u001b[39m'\u001b[39m\u001b[39mpost_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpost_message\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpost_created_time\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomment_created_time\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcomment_message\u001b[39m\u001b[39m'\u001b[39m,\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/notebooks/2023-03-22%20ChatGPT%20GUI%20FB%20group.ipynb#Y136sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mparent_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mparent_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreply_message\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreply_created_time\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreply_id\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n",
      "\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n",
      "\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n",
      "\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n",
      "\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n",
      "\u001b[0;32m    316\u001b[0m     )\n",
      "\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:5391\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n",
      "\u001b[0;32m   5243\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;32m   5244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n",
      "\u001b[0;32m   5245\u001b[0m     \u001b[39mself\u001b[39m,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   5252\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n",
      "\u001b[0;32m   5253\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;32m   5254\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m   5255\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n",
      "\u001b[0;32m   5256\u001b[0m \n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   5389\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n",
      "\u001b[0;32m   5390\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 5391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n",
      "\u001b[0;32m   5392\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n",
      "\u001b[0;32m   5393\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n",
      "\u001b[0;32m   5394\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n",
      "\u001b[0;32m   5395\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n",
      "\u001b[0;32m   5396\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n",
      "\u001b[0;32m   5397\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n",
      "\u001b[0;32m   5398\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n",
      "\u001b[0;32m   5399\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n",
      "\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n",
      "\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n",
      "\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n",
      "\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n",
      "\u001b[0;32m    316\u001b[0m     )\n",
      "\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:4510\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n",
      "\u001b[0;32m   4508\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n",
      "\u001b[0;32m   4509\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m-> 4510\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n",
      "\u001b[0;32m   4512\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n",
      "\u001b[0;32m   4513\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:4551\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n",
      "\u001b[0;32m   4549\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n",
      "\u001b[0;32m   4550\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 4551\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n",
      "\u001b[0;32m   4552\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n",
      "\u001b[0;32m   4554\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n",
      "\u001b[0;32m   4555\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:6972\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n",
      "\u001b[0;32m   6970\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n",
      "\u001b[0;32m   6971\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;32m-> 6972\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;32m   6973\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n",
      "\u001b[0;32m   6974\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['parent_name_y'] not found in axis\""
     ]
    }
   ],
   "source": [
    "merged = merge_dataframes(comments_df, posts_df, replies)\n",
    "merged.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the code\n",
    "#### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['post_id', 'created_time_x', 'message_x', 'author_id', 'author_name',\n",
      "       'parent_id', 'parent_name', 'created_time_y', 'message_y',\n",
      "       'comments_count', 'like_count', 'love_count', 'wow_count', 'haha_count',\n",
      "       'sad_count', 'angry_count', 'permalink_url'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>created_time_x</th>\n",
       "      <th>message_x</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>parent_name</th>\n",
       "      <th>created_time_y</th>\n",
       "      <th>message_y</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>love_count</th>\n",
       "      <th>wow_count</th>\n",
       "      <th>haha_count</th>\n",
       "      <th>sad_count</th>\n",
       "      <th>angry_count</th>\n",
       "      <th>permalink_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T20:45:46+0000</td>\n",
       "      <td>are protein bars bad for you as they are so pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T21:25:54+0000</td>\n",
       "      <td>Is protein really important ... should do we n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T23:31:32+0000</td>\n",
       "      <td>For those of us entering perimenopause, what s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T03:42:17+0000</td>\n",
       "      <td>What snacks should we lean more towards when s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T04:33:53+0000</td>\n",
       "      <td>These are bloody fantastic questions! I will c...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_id            created_time_x  \\\n",
       "0  2139238999669147_3370347119891656  2023-03-21T20:45:46+0000   \n",
       "1  2139238999669147_3370347119891656  2023-03-21T21:25:54+0000   \n",
       "2  2139238999669147_3370347119891656  2023-03-21T23:31:32+0000   \n",
       "3  2139238999669147_3370347119891656  2023-03-22T03:42:17+0000   \n",
       "4  2139238999669147_3370347119891656  2023-03-22T04:33:53+0000   \n",
       "\n",
       "                                           message_x author_id author_name  \\\n",
       "0  are protein bars bad for you as they are so pr...      None        None   \n",
       "1  Is protein really important ... should do we n...      None        None   \n",
       "2  For those of us entering perimenopause, what s...      None        None   \n",
       "3  What snacks should we lean more towards when s...      None        None   \n",
       "4  These are bloody fantastic questions! I will c...      None        None   \n",
       "\n",
       "  parent_id parent_name            created_time_y  \\\n",
       "0      None        None  2023-03-21T19:11:52+0000   \n",
       "1      None        None  2023-03-21T19:11:52+0000   \n",
       "2      None        None  2023-03-21T19:11:52+0000   \n",
       "3      None        None  2023-03-21T19:11:52+0000   \n",
       "4      None        None  2023-03-21T19:11:52+0000   \n",
       "\n",
       "                                           message_y  comments_count  \\\n",
       "0  @everyone for team training this week. A vast ...               7   \n",
       "1  @everyone for team training this week. A vast ...               7   \n",
       "2  @everyone for team training this week. A vast ...               7   \n",
       "3  @everyone for team training this week. A vast ...               7   \n",
       "4  @everyone for team training this week. A vast ...               7   \n",
       "\n",
       "   like_count  love_count  wow_count  haha_count  sad_count  angry_count  \\\n",
       "0           2           0          0           0          0            0   \n",
       "1           2           0          0           0          0            0   \n",
       "2           2           0          0           0          0            0   \n",
       "3           2           0          0           0          0            0   \n",
       "4           2           0          0           0          0            0   \n",
       "\n",
       "                                       permalink_url  \n",
       "0  https://www.facebook.com/groups/strongandsassy...  \n",
       "1  https://www.facebook.com/groups/strongandsassy...  \n",
       "2  https://www.facebook.com/groups/strongandsassy...  \n",
       "3  https://www.facebook.com/groups/strongandsassy...  \n",
       "4  https://www.facebook.com/groups/strongandsassy...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def merge_dataframes(comments_df, posts_df, replies_df):\n",
    "    # merge comments and posts dataframes on post_id\n",
    "    merged_df = pd.merge(comments_df, posts_df, on='post_id', how='outer')\n",
    "    # merge replies dataframe on comment_id\n",
    "    merged_df2 = pd.merge(merged_df, replies_df, left_on='parent_id', right_on='comment_id', how='left')\n",
    "    # rename columns\n",
    "    # merged_df2 = merged_df.rename(columns={\n",
    "    #     'post_id_x': 'post_id',\n",
    "    #     'created_time_x': 'comment_created_time',\n",
    "    #     'created_time_y': 'post_created_time',\n",
    "    #     'message_x': 'comment_message',\n",
    "    #     'message_y': 'post_message',\n",
    "    #     'parent_name_x': 'parent_name',\n",
    "    #     'reply_comment_message': 'reply_message',\n",
    "    #     'reply_created_time': 'reply_created_time',\n",
    "    #     'reply_id': 'reply_id'\n",
    "    # })\n",
    "    # drop unnecessary columns\n",
    "    # merged_df2 = merged_df.drop(columns=['parent_id', 'parent_name', 'comment_id'])\n",
    "    # # reorder columns\n",
    "    # merged_df = merged_df[['post_id', 'post_message', 'post_created_time', 'comment_created_time', 'parent_comment_message',\n",
    "    #                        'parent_id', 'parent_name', 'reply_message', 'reply_created_time', 'reply_id']]\n",
    "    return merged_df, merged_df2\n",
    "\n",
    "merged, merged2 = merge_dataframes(comments_df, posts_df, replies)\n",
    "print(merged.columns)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['post_id_x', 'created_time_x', 'message_x', 'author_id', 'author_name',\n",
      "       'parent_id', 'parent_name', 'created_time_y', 'message_y',\n",
      "       'comments_count', 'like_count', 'love_count', 'wow_count', 'haha_count',\n",
      "       'sad_count', 'angry_count', 'permalink_url', 'post_id_y',\n",
      "       'parent_comment_message', 'comment_id', 'reply_comment_message',\n",
      "       'reply_created_time', 'reply_id'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "5     NaN\n",
       "6     NaN\n",
       "7     NaN\n",
       "8     NaN\n",
       "9     NaN\n",
       "10    NaN\n",
       "11    NaN\n",
       "12    NaN\n",
       "13    NaN\n",
       "14    NaN\n",
       "15    NaN\n",
       "16    NaN\n",
       "17    NaN\n",
       "18    NaN\n",
       "19    NaN\n",
       "20    NaN\n",
       "21    NaN\n",
       "22    NaN\n",
       "23    NaN\n",
       "24    NaN\n",
       "25    NaN\n",
       "26    NaN\n",
       "27    NaN\n",
       "28    NaN\n",
       "29    NaN\n",
       "30    NaN\n",
       "31    NaN\n",
       "32    NaN\n",
       "33    NaN\n",
       "34    NaN\n",
       "35    NaN\n",
       "36    NaN\n",
       "37    NaN\n",
       "38    NaN\n",
       "39    NaN\n",
       "40    NaN\n",
       "Name: comment_id, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(merged2.columns)\n",
    "merged2['comment_id']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 2\n",
    "I looked closely at the resulting output and did debugging. I found that:\n",
    "* There were some mistakes when renaming and dropping columns.\n",
    "* The merge did not join the dataframes correctly due to the id numbers not corresponding between the comments and replies.\n",
    "\n",
    "The modified version below fixes these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['post_id', 'post_message', 'post_created_time', 'comment_created_time',\n",
      "       'parent_comment_message', 'comment_id', 'reply_message',\n",
      "       'reply_created_time', 'reply_id'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_message</th>\n",
       "      <th>post_created_time</th>\n",
       "      <th>comment_created_time</th>\n",
       "      <th>parent_comment_message</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>reply_message</th>\n",
       "      <th>reply_created_time</th>\n",
       "      <th>reply_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-21T20:45:46+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-21T21:25:54+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-21T23:31:32+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T03:42:17+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T04:33:53+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T04:34:42+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T18:53:06+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Zoe Leah itâ€™s good to see isnâ€™t it?</td>\n",
       "      <td>2023-03-22T06:20:38+0000</td>\n",
       "      <td>3370610399865328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone yes, very much so ðŸ¤</td>\n",
       "      <td>2023-03-22T06:21:05+0000</td>\n",
       "      <td>3370610566531978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone this is so interesting to know...</td>\n",
       "      <td>2023-03-22T06:29:21+0000</td>\n",
       "      <td>3370613349865033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_id  \\\n",
       "0  2139238999669147_3370347119891656   \n",
       "1  2139238999669147_3370347119891656   \n",
       "2  2139238999669147_3370347119891656   \n",
       "3  2139238999669147_3370347119891656   \n",
       "4  2139238999669147_3370347119891656   \n",
       "5  2139238999669147_3370347119891656   \n",
       "6  2139238999669147_3370347119891656   \n",
       "7  2139238999669147_3370342969892071   \n",
       "8  2139238999669147_3370342969892071   \n",
       "9  2139238999669147_3370342969892071   \n",
       "\n",
       "                                        post_message  \\\n",
       "0  @everyone for team training this week. A vast ...   \n",
       "1  @everyone for team training this week. A vast ...   \n",
       "2  @everyone for team training this week. A vast ...   \n",
       "3  @everyone for team training this week. A vast ...   \n",
       "4  @everyone for team training this week. A vast ...   \n",
       "5  @everyone for team training this week. A vast ...   \n",
       "6  @everyone for team training this week. A vast ...   \n",
       "7  How shocked would you be if I told you - there...   \n",
       "8  How shocked would you be if I told you - there...   \n",
       "9  How shocked would you be if I told you - there...   \n",
       "\n",
       "          post_created_time      comment_created_time parent_comment_message  \\\n",
       "0  2023-03-21T19:11:52+0000  2023-03-21T20:45:46+0000                    NaN   \n",
       "1  2023-03-21T19:11:52+0000  2023-03-21T21:25:54+0000                    NaN   \n",
       "2  2023-03-21T19:11:52+0000  2023-03-21T23:31:32+0000                    NaN   \n",
       "3  2023-03-21T19:11:52+0000  2023-03-22T03:42:17+0000                    NaN   \n",
       "4  2023-03-21T19:11:52+0000  2023-03-22T04:33:53+0000                    NaN   \n",
       "5  2023-03-21T19:11:52+0000  2023-03-22T04:34:42+0000                    NaN   \n",
       "6  2023-03-21T19:11:52+0000  2023-03-22T18:53:06+0000                    NaN   \n",
       "7  2023-03-21T19:02:42+0000  2023-03-22T05:39:10+0000              Ree Waugh   \n",
       "8  2023-03-21T19:02:42+0000  2023-03-22T05:39:10+0000              Ree Waugh   \n",
       "9  2023-03-21T19:02:42+0000  2023-03-22T05:39:10+0000              Ree Waugh   \n",
       "\n",
       "         comment_id                                      reply_message  \\\n",
       "0               NaN                                                NaN   \n",
       "1               NaN                                                NaN   \n",
       "2               NaN                                                NaN   \n",
       "3               NaN                                                NaN   \n",
       "4               NaN                                                NaN   \n",
       "5               NaN                                                NaN   \n",
       "6               NaN                                                NaN   \n",
       "7  3370594463200255                Zoe Leah itâ€™s good to see isnâ€™t it?   \n",
       "8  3370594463200255                Amanda Mc Loone yes, very much so ðŸ¤   \n",
       "9  3370594463200255  Amanda Mc Loone this is so interesting to know...   \n",
       "\n",
       "         reply_created_time          reply_id  \n",
       "0                       NaN               NaN  \n",
       "1                       NaN               NaN  \n",
       "2                       NaN               NaN  \n",
       "3                       NaN               NaN  \n",
       "4                       NaN               NaN  \n",
       "5                       NaN               NaN  \n",
       "6                       NaN               NaN  \n",
       "7  2023-03-22T06:20:38+0000  3370610399865328  \n",
       "8  2023-03-22T06:21:05+0000  3370610566531978  \n",
       "9  2023-03-22T06:29:21+0000  3370613349865033  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will make up the final script for the task \n",
    "def merge_dataframes(comments_df, posts_df, replies_df):\n",
    "    # merge comments and posts dataframes on post_id\n",
    "    merged_df = pd.merge(comments_df, posts_df, on='post_id', how='outer')\n",
    "    # merge replies dataframe on comment_id\n",
    "    merged_df = pd.merge(merged_df, replies_df, left_on='message_x', right_on='parent_comment_message', how='left')\n",
    "    # rename columns\n",
    "    merged_df = merged_df.rename(columns={\n",
    "        'post_id_x': 'post_id',\n",
    "        'created_time_x': 'comment_created_time',\n",
    "        'created_time_y': 'post_created_time',\n",
    "        'message_x': 'comment_message',\n",
    "        'message_y': 'post_message',\n",
    "        'parent_name_x': 'parent_name',\n",
    "        'reply_comment_message': 'reply_message',\n",
    "        'reply_created_time': 'reply_created_time',\n",
    "        'reply_id': 'reply_id'\n",
    "    })\n",
    "    # drop unnecessary columns\n",
    "    merged_df = merged_df.drop(columns=['parent_name', 'parent_id'])\n",
    "    # reorder columns\n",
    "    merged_df = merged_df[['post_id', 'post_message', 'post_created_time', 'comment_created_time', 'parent_comment_message',\n",
    "                           'comment_id', 'reply_message', 'reply_created_time', 'reply_id']]\n",
    "    return merged_df\n",
    "\n",
    "merged = merge_dataframes(comments_df, posts_df, replies)\n",
    "print(merged.columns)\n",
    "merged.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I will use this as part of the final code for the task\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_facebook_posts(group_id, access_token, limit=25):\n",
    "    \"\"\"\n",
    "    Makes a GET request to pull posts from a Facebook group using the Facebook API.\n",
    "    Outputs the results into a DataFrame so that each post is a row along with its time stamp, message,\n",
    "    permalink, comments count, reactions, and post ID.\n",
    "    Also outputs the response.json().\n",
    "\n",
    "    Parameters:\n",
    "        group_id (str): The ID of the Facebook group to pull posts from.\n",
    "        access_token (str): An access token with the appropriate permissions to access the group's content.\n",
    "        limit (int): The number of posts to retrieve (default is 100).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the posts and their associated data.\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "\n",
    "    params = {\n",
    "        \"access_token\": access_token,\n",
    "        \"fields\": \"created_time,message,permalink_url,comments.limit(10).summary(true),reactions.limit(500).summary(true).type(LIKE).as(like),reactions.limit(500).summary(true).type(LOVE).as(love),reactions.limit(500).summary(true).type(WOW).as(wow),reactions.limit(500).summary(true).type(HAHA).as(haha),reactions.limit(500).summary(true).type(SAD).as(sad),reactions.limit(500).summary(true).type(ANGRY).as(angry)\",\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    status_code = response.status_code\n",
    "    print(\"Response Status Code:\", status_code)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "## I will use this as part of the final code for the task\n",
    "def process_response(data):\n",
    "    posts = []\n",
    "    comments = []\n",
    "    for post in data[\"data\"]:\n",
    "        created_time = post.get(\"created_time\")\n",
    "        message = post.get(\"message\")\n",
    "        permalink_url = post.get(\"permalink_url\")\n",
    "        comments_count = post.get(\"comments\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        reactions = post.get(\"like\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"love\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"wow\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"haha\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"sad\", {}).get(\"summary\", {}).get(\"total_count\", 0), post.get(\"angry\", {}).get(\"summary\", {}).get(\"total_count\", 0)\n",
    "        post_id = post.get(\"id\")\n",
    "        posts.append({\n",
    "            \"post_id\": post_id,\n",
    "            \"created_time\": created_time,\n",
    "            \"message\": message,\n",
    "            \"comments_count\": comments_count,\n",
    "            \"like_count\": reactions[0],\n",
    "            \"love_count\": reactions[1],\n",
    "            \"wow_count\": reactions[2],\n",
    "            \"haha_count\": reactions[3],\n",
    "            \"sad_count\": reactions[4],\n",
    "            \"angry_count\": reactions[5],\n",
    "            \"permalink_url\": permalink_url,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(posts)\n",
    "    # Reorder columns\n",
    "    df = df[[\"post_id\", \"created_time\", \"message\", \"comments_count\", \"like_count\", \"love_count\", \"wow_count\", \"haha_count\", \"sad_count\", \"angry_count\", \"permalink_url\"]]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_fb_comments(group_id, access_token, limit=25):\n",
    "    \"\"\"\n",
    "    Pulls comments from a Facebook group using the Facebook API and outputs the results into a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    group_id (str): The ID of the Facebook group to pull comments from.\n",
    "    access_token (str): A Facebook access token with the necessary permissions to access the group.\n",
    "    \n",
    "    Returns:\n",
    "    Tuple(pandas.DataFrame, dict): A tuple containing a DataFrame with each comment as a row along with its details and replies,\n",
    "    and the full JSON response from the API.\n",
    "    \"\"\"\n",
    "    # Set up the API endpoint and parameters\n",
    "    url = f\"https://graph.facebook.com/{group_id}/feed\"\n",
    "    params = {\n",
    "        \"fields\": \"comments{created_time,message,from,comments{created_time,message,from}}\",\n",
    "        \"access_token\": access_token,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Convert the response to a DataFrame\n",
    "    comments = []\n",
    "    for post in response.json()[\"data\"]:\n",
    "        post_comments = post.get(\"comments\", {}).get(\"data\", [])\n",
    "        for comment in post_comments:\n",
    "            comment_dict = {\n",
    "                \"post_id\": post.get(\"id\"),\n",
    "                \"created_time\": comment.get(\"created_time\"),\n",
    "                \"message\": comment.get(\"message\"),\n",
    "                \"author_id\": comment.get(\"from\", {}).get(\"id\"),\n",
    "                \"author_name\": comment.get(\"from\", {}).get(\"name\"),\n",
    "                \"parent_id\": None,\n",
    "                \"parent_name\": None,\n",
    "            }\n",
    "            parent_comment = comment.get(\"comments\", {}).get(\"data\", [])\n",
    "            if parent_comment:\n",
    "                parent_comment = parent_comment[0]\n",
    "                comment_dict[\"parent_id\"] = parent_comment.get(\"id\")\n",
    "                comment_dict[\"parent_name\"] = parent_comment.get(\"from\", {}).get(\"name\")\n",
    "            comments.append(comment_dict)\n",
    "    df = pd.DataFrame(comments)\n",
    "    return df, response.json()\n",
    "\n",
    "def create_reply_dataframe(json_object):\n",
    "    # Initialize empty lists to store data\n",
    "    post_id_list = []\n",
    "    parent_comment_message_list = []\n",
    "    comment_id_list = []\n",
    "    reply_comment_message_list = []\n",
    "    reply_created_time_list = []\n",
    "    reply_id_list = []\n",
    "    \n",
    "    # Loop through each post in the json object\n",
    "    for post in json_object:\n",
    "        # Get the post ID\n",
    "        post_id = post['id']\n",
    "        \n",
    "        try: # SH 2023-03-22 10:50 Added this \n",
    "            # Loop through each comment in the post\n",
    "            for comment in post['comments']['data']:\n",
    "                # Get the comment ID and message\n",
    "                comment_id = comment['id']\n",
    "                parent_comment_message = comment['message']\n",
    "                \n",
    "                # Check if the comment has any replies\n",
    "                # if 'comments' in comment:\n",
    "                if 'comments' in comment:\n",
    "                    # Loop through each reply to the comment\n",
    "                    for reply in comment['comments']['data']:\n",
    "                        # Get the reply ID, message, and creation time\n",
    "                        reply_id = reply['id']\n",
    "                        reply_comment_message = reply['message']\n",
    "                        reply_created_time = reply['created_time']\n",
    "                        \n",
    "                        # Add the data to the lists\n",
    "                        post_id_list.append(post_id)\n",
    "                        parent_comment_message_list.append(parent_comment_message)\n",
    "                        comment_id_list.append(comment_id)\n",
    "                        reply_comment_message_list.append(reply_comment_message)\n",
    "                        reply_created_time_list.append(reply_created_time)\n",
    "                        reply_id_list.append(reply_id)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Create a dataframe from the lists\n",
    "    df = pd.DataFrame({\n",
    "        'post_id': post_id_list,\n",
    "        'parent_comment_message': parent_comment_message_list,\n",
    "        'comment_id': comment_id_list,\n",
    "        'reply_comment_message': reply_comment_message_list,\n",
    "        'reply_created_time': reply_created_time_list,\n",
    "        'reply_id': reply_id_list\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def merge_dataframes(comments_df, posts_df, replies_df):\n",
    "    # merge comments and posts dataframes on post_id\n",
    "    merged_df = pd.merge(comments_df, posts_df, on='post_id', how='outer')\n",
    "    # merge replies dataframe on comment_id\n",
    "    merged_df = pd.merge(merged_df, replies_df, left_on='message_x', right_on='parent_comment_message', how='left')\n",
    "    # rename columns\n",
    "    merged_df = merged_df.rename(columns={\n",
    "        'post_id_x': 'post_id',\n",
    "        'created_time_x': 'comment_created_time',\n",
    "        'created_time_y': 'post_created_time',\n",
    "        'message_x': 'comment_message',\n",
    "        'message_y': 'post_message',\n",
    "        'parent_name_x': 'parent_name',\n",
    "        'reply_comment_message': 'reply_message',\n",
    "        'reply_created_time': 'reply_created_time',\n",
    "        'reply_id': 'reply_id'\n",
    "    })\n",
    "    # drop unnecessary columns\n",
    "    merged_df = merged_df.drop(columns=['parent_name', 'parent_id'])\n",
    "    # reorder columns\n",
    "    merged_df = merged_df[['post_id', 'post_message', 'post_created_time', 'comment_created_time', 'parent_comment_message',\n",
    "                           'comment_id', 'reply_message', 'reply_created_time', 'reply_id']]\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>love_count</th>\n",
       "      <th>wow_count</th>\n",
       "      <th>haha_count</th>\n",
       "      <th>sad_count</th>\n",
       "      <th>angry_count</th>\n",
       "      <th>permalink_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370989849827383</td>\n",
       "      <td>2023-03-22T20:00:34+0000</td>\n",
       "      <td>Q&amp;A - protein, protein bars, does training aff...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370971416495893</td>\n",
       "      <td>2023-03-22T19:16:23+0000</td>\n",
       "      <td>Almost half of the world's population are not ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3369703796622655</td>\n",
       "      <td>2023-03-20T18:56:34+0000</td>\n",
       "      <td>Why your morning routine may actually be NEGAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2139238999669147_3367071606885874</td>\n",
       "      <td>2023-03-16T18:50:55+0000</td>\n",
       "      <td>If youâ€™re constantly worried about calories an...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2139238999669147_3366477613611940</td>\n",
       "      <td>2023-03-15T20:56:22+0000</td>\n",
       "      <td>Youâ€™ve heard the saying â€˜a dog is for life - n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2139238999669147_3365106907082344</td>\n",
       "      <td>2023-03-13T18:45:59+0000</td>\n",
       "      <td>It would actually break your heart to read my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/groups/strongandsassy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_id              created_time  \\\n",
       "0  2139238999669147_3370989849827383  2023-03-22T20:00:34+0000   \n",
       "1  2139238999669147_3370971416495893  2023-03-22T19:16:23+0000   \n",
       "2  2139238999669147_3370347119891656  2023-03-21T19:11:52+0000   \n",
       "3  2139238999669147_3370342969892071  2023-03-21T19:02:42+0000   \n",
       "4  2139238999669147_3369703796622655  2023-03-20T18:56:34+0000   \n",
       "5  2139238999669147_3367071606885874  2023-03-16T18:50:55+0000   \n",
       "6  2139238999669147_3366477613611940  2023-03-15T20:56:22+0000   \n",
       "7  2139238999669147_3366060270320341  2023-03-15T07:02:37+0000   \n",
       "8  2139238999669147_3365771280349240  2023-03-14T19:04:59+0000   \n",
       "9  2139238999669147_3365106907082344  2023-03-13T18:45:59+0000   \n",
       "\n",
       "                                             message  comments_count  \\\n",
       "0  Q&A - protein, protein bars, does training aff...               0   \n",
       "1  Almost half of the world's population are not ...               0   \n",
       "2  @everyone for team training this week. A vast ...               7   \n",
       "3  How shocked would you be if I told you - there...               1   \n",
       "4  Why your morning routine may actually be NEGAT...               1   \n",
       "5  If youâ€™re constantly worried about calories an...               0   \n",
       "6  Youâ€™ve heard the saying â€˜a dog is for life - n...               0   \n",
       "7  Calories in versus calories out (how do I over...               2   \n",
       "8  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...               6   \n",
       "9  It would actually break your heart to read my ...               0   \n",
       "\n",
       "   like_count  love_count  wow_count  haha_count  sad_count  angry_count  \\\n",
       "0           4           1          0           0          0            0   \n",
       "1           3           0          0           0          0            0   \n",
       "2           2           0          0           0          0            0   \n",
       "3           3           6          3           0          0            0   \n",
       "4           5           0          0           0          0            0   \n",
       "5           4           1          0           0          0            0   \n",
       "6           1           4          0           0          0            0   \n",
       "7           5           3          0           0          0            0   \n",
       "8          15           6          0           0          0            0   \n",
       "9           3           0          0           0          0            0   \n",
       "\n",
       "                                       permalink_url  \n",
       "0  https://www.facebook.com/groups/strongandsassy...  \n",
       "1  https://www.facebook.com/groups/strongandsassy...  \n",
       "2  https://www.facebook.com/groups/strongandsassy...  \n",
       "3  https://www.facebook.com/groups/strongandsassy...  \n",
       "4  https://www.facebook.com/groups/strongandsassy...  \n",
       "5  https://www.facebook.com/groups/strongandsassy...  \n",
       "6  https://www.facebook.com/groups/strongandsassy...  \n",
       "7  https://www.facebook.com/groups/strongandsassy...  \n",
       "8  https://www.facebook.com/groups/strongandsassy...  \n",
       "9  https://www.facebook.com/groups/strongandsassy...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Facebook group posts\n",
    "posts_data = get_facebook_posts(group_id, access_token)\n",
    "posts_df = process_response(posts_data)\n",
    "posts_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>parent_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T20:45:46+0000</td>\n",
       "      <td>are protein bars bad for you as they are so pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T21:25:54+0000</td>\n",
       "      <td>Is protein really important ... should do we n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-21T23:31:32+0000</td>\n",
       "      <td>For those of us entering perimenopause, what s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T03:42:17+0000</td>\n",
       "      <td>What snacks should we lean more towards when s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T04:33:53+0000</td>\n",
       "      <td>These are bloody fantastic questions! I will c...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T04:34:42+0000</td>\n",
       "      <td>@everyone \\n7am Sydney Time Thursday \\n8pm Iri...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>2023-03-22T18:53:06+0000</td>\n",
       "      <td>Any snack/food ideas for when your out all day...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3370610399865328</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2139238999669147_3369703796622655</td>\n",
       "      <td>2023-03-21T04:42:48+0000</td>\n",
       "      <td>Set my alarm for 5am today to walk Eddie and b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3369948876598147</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>2023-03-15T13:38:20+0000</td>\n",
       "      <td>Thank you for the info Amanda.  I'm struggling...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3366487800277588</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_id              created_time  \\\n",
       "0  2139238999669147_3370347119891656  2023-03-21T20:45:46+0000   \n",
       "1  2139238999669147_3370347119891656  2023-03-21T21:25:54+0000   \n",
       "2  2139238999669147_3370347119891656  2023-03-21T23:31:32+0000   \n",
       "3  2139238999669147_3370347119891656  2023-03-22T03:42:17+0000   \n",
       "4  2139238999669147_3370347119891656  2023-03-22T04:33:53+0000   \n",
       "5  2139238999669147_3370347119891656  2023-03-22T04:34:42+0000   \n",
       "6  2139238999669147_3370347119891656  2023-03-22T18:53:06+0000   \n",
       "7  2139238999669147_3370342969892071  2023-03-22T05:39:10+0000   \n",
       "8  2139238999669147_3369703796622655  2023-03-21T04:42:48+0000   \n",
       "9  2139238999669147_3366060270320341  2023-03-15T13:38:20+0000   \n",
       "\n",
       "                                             message author_id author_name  \\\n",
       "0  are protein bars bad for you as they are so pr...      None        None   \n",
       "1  Is protein really important ... should do we n...      None        None   \n",
       "2  For those of us entering perimenopause, what s...      None        None   \n",
       "3  What snacks should we lean more towards when s...      None        None   \n",
       "4  These are bloody fantastic questions! I will c...      None        None   \n",
       "5  @everyone \\n7am Sydney Time Thursday \\n8pm Iri...      None        None   \n",
       "6  Any snack/food ideas for when your out all day...      None        None   \n",
       "7                                          Ree Waugh      None        None   \n",
       "8  Set my alarm for 5am today to walk Eddie and b...      None        None   \n",
       "9  Thank you for the info Amanda.  I'm struggling...      None        None   \n",
       "\n",
       "          parent_id parent_name  \n",
       "0              None        None  \n",
       "1              None        None  \n",
       "2              None        None  \n",
       "3              None        None  \n",
       "4              None        None  \n",
       "5              None        None  \n",
       "6              None        None  \n",
       "7  3370610399865328        None  \n",
       "8  3369948876598147        None  \n",
       "9  3366487800277588        None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df, comments_response = get_fb_comments(group_id, access_token)\n",
    "comments_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_comment_message</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>reply_comment_message</th>\n",
       "      <th>reply_created_time</th>\n",
       "      <th>reply_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Zoe Leah itâ€™s good to see isnâ€™t it?</td>\n",
       "      <td>2023-03-22T06:20:38+0000</td>\n",
       "      <td>3370610399865328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone yes, very much so ðŸ¤</td>\n",
       "      <td>2023-03-22T06:21:05+0000</td>\n",
       "      <td>3370610566531978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone this is so interesting to know...</td>\n",
       "      <td>2023-03-22T06:29:21+0000</td>\n",
       "      <td>3370613349865033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>K Bev Nyirenda scales donâ€™t always show body c...</td>\n",
       "      <td>2023-03-22T07:34:23+0000</td>\n",
       "      <td>3370641649862203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone Definitely!</td>\n",
       "      <td>2023-03-22T08:25:20+0000</td>\n",
       "      <td>3370661996526835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_id parent_comment_message        comment_id  \\\n",
       "0  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "1  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "2  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "3  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "4  2139238999669147_3370342969892071              Ree Waugh  3370594463200255   \n",
       "\n",
       "                               reply_comment_message  \\\n",
       "0                Zoe Leah itâ€™s good to see isnâ€™t it?   \n",
       "1                Amanda Mc Loone yes, very much so ðŸ¤   \n",
       "2  Amanda Mc Loone this is so interesting to know...   \n",
       "3  K Bev Nyirenda scales donâ€™t always show body c...   \n",
       "4                        Amanda Mc Loone Definitely!   \n",
       "\n",
       "         reply_created_time          reply_id  \n",
       "0  2023-03-22T06:20:38+0000  3370610399865328  \n",
       "1  2023-03-22T06:21:05+0000  3370610566531978  \n",
       "2  2023-03-22T06:29:21+0000  3370613349865033  \n",
       "3  2023-03-22T07:34:23+0000  3370641649862203  \n",
       "4  2023-03-22T08:25:20+0000  3370661996526835  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies = create_reply_dataframe(comments_response['data'])\n",
    "replies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_message</th>\n",
       "      <th>post_created_time</th>\n",
       "      <th>comment_created_time</th>\n",
       "      <th>parent_comment_message</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>reply_message</th>\n",
       "      <th>reply_created_time</th>\n",
       "      <th>reply_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-21T20:45:46+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-21T21:25:54+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-21T23:31:32+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T03:42:17+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T04:33:53+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T04:34:42+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2139238999669147_3370347119891656</td>\n",
       "      <td>@everyone for team training this week. A vast ...</td>\n",
       "      <td>2023-03-21T19:11:52+0000</td>\n",
       "      <td>2023-03-22T18:53:06+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Zoe Leah itâ€™s good to see isnâ€™t it?</td>\n",
       "      <td>2023-03-22T06:20:38+0000</td>\n",
       "      <td>3370610399865328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone yes, very much so ðŸ¤</td>\n",
       "      <td>2023-03-22T06:21:05+0000</td>\n",
       "      <td>3370610566531978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone this is so interesting to know...</td>\n",
       "      <td>2023-03-22T06:29:21+0000</td>\n",
       "      <td>3370613349865033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>K Bev Nyirenda scales donâ€™t always show body c...</td>\n",
       "      <td>2023-03-22T07:34:23+0000</td>\n",
       "      <td>3370641649862203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2139238999669147_3370342969892071</td>\n",
       "      <td>How shocked would you be if I told you - there...</td>\n",
       "      <td>2023-03-21T19:02:42+0000</td>\n",
       "      <td>2023-03-22T05:39:10+0000</td>\n",
       "      <td>Ree Waugh</td>\n",
       "      <td>3370594463200255</td>\n",
       "      <td>Amanda Mc Loone Definitely!</td>\n",
       "      <td>2023-03-22T08:25:20+0000</td>\n",
       "      <td>3370661996526835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2139238999669147_3369703796622655</td>\n",
       "      <td>Why your morning routine may actually be NEGAT...</td>\n",
       "      <td>2023-03-20T18:56:34+0000</td>\n",
       "      <td>2023-03-21T04:42:48+0000</td>\n",
       "      <td>Set my alarm for 5am today to walk Eddie and b...</td>\n",
       "      <td>3369936533266048</td>\n",
       "      <td>Lisa Calvert but you obvs needed the sleep ðŸ™Œ a...</td>\n",
       "      <td>2023-03-21T05:17:56+0000</td>\n",
       "      <td>3369948876598147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2139238999669147_3369703796622655</td>\n",
       "      <td>Why your morning routine may actually be NEGAT...</td>\n",
       "      <td>2023-03-20T18:56:34+0000</td>\n",
       "      <td>2023-03-21T04:42:48+0000</td>\n",
       "      <td>Set my alarm for 5am today to walk Eddie and b...</td>\n",
       "      <td>3369936533266048</td>\n",
       "      <td>Amanda Mc Loone I've asked politely a few time...</td>\n",
       "      <td>2023-03-21T05:31:10+0000</td>\n",
       "      <td>3369953436597691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2139238999669147_3369703796622655</td>\n",
       "      <td>Why your morning routine may actually be NEGAT...</td>\n",
       "      <td>2023-03-20T18:56:34+0000</td>\n",
       "      <td>2023-03-21T04:42:48+0000</td>\n",
       "      <td>Set my alarm for 5am today to walk Eddie and b...</td>\n",
       "      <td>3369936533266048</td>\n",
       "      <td>Lisa Calvert nightmare!</td>\n",
       "      <td>2023-03-21T05:32:01+0000</td>\n",
       "      <td>3369953749930993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>2023-03-15T13:38:20+0000</td>\n",
       "      <td>Thank you for the info Amanda.  I'm struggling...</td>\n",
       "      <td>3366252306967804</td>\n",
       "      <td>Lorraine Wilmot Iâ€™m going to message you!</td>\n",
       "      <td>2023-03-15T21:19:52+0000</td>\n",
       "      <td>3366487800277588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>2023-03-15T07:39:21+0000</td>\n",
       "      <td>Thank you x</td>\n",
       "      <td>3366072910319077</td>\n",
       "      <td>Jessica Protopapas did you enjoy this?</td>\n",
       "      <td>2023-03-15T07:42:57+0000</td>\n",
       "      <td>3366074393652262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>2023-03-15T07:39:21+0000</td>\n",
       "      <td>Thank you x</td>\n",
       "      <td>3366072910319077</td>\n",
       "      <td>Amanda Mc Loone you always give great content....</td>\n",
       "      <td>2023-03-15T08:06:22+0000</td>\n",
       "      <td>3366092883650413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>2023-03-15T07:39:21+0000</td>\n",
       "      <td>Thank you x</td>\n",
       "      <td>3366072910319077</td>\n",
       "      <td>Jessica Protopapas honestly bulking is SO HARD...</td>\n",
       "      <td>2023-03-15T21:19:32+0000</td>\n",
       "      <td>3366487480277620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>2023-03-15T07:39:21+0000</td>\n",
       "      <td>Thank you x</td>\n",
       "      <td>3366072910319077</td>\n",
       "      <td>Amanda Mc Loone excellent.  My fitness pal foo...</td>\n",
       "      <td>2023-03-15T21:21:27+0000</td>\n",
       "      <td>3366488646944170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2139238999669147_3366060270320341</td>\n",
       "      <td>Calories in versus calories out (how do I over...</td>\n",
       "      <td>2023-03-15T07:02:37+0000</td>\n",
       "      <td>2023-03-15T07:39:21+0000</td>\n",
       "      <td>Thank you x</td>\n",
       "      <td>3366072910319077</td>\n",
       "      <td>Jessica Protopapas sounds like youâ€™re on track...</td>\n",
       "      <td>2023-03-16T00:52:38+0000</td>\n",
       "      <td>3366569473602754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-14T20:28:40+0000</td>\n",
       "      <td>ðŸ‘ðŸ™ŒðŸ‘ðŸ™Œ</td>\n",
       "      <td>3365809060345462</td>\n",
       "      <td>Emily Davy the best supportive crew â™¥ï¸</td>\n",
       "      <td>2023-03-14T20:46:02+0000</td>\n",
       "      <td>3365816430344725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-14T20:43:52+0000</td>\n",
       "      <td>Fantastic!!!!</td>\n",
       "      <td>3365815597011475</td>\n",
       "      <td>Teresa Madden love the support â™¥ï¸</td>\n",
       "      <td>2023-03-14T20:46:12+0000</td>\n",
       "      <td>3365816490344719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-14T20:50:22+0000</td>\n",
       "      <td>wow amazing mama Gillian NÃ­ HEachthairn! ðŸ’ª</td>\n",
       "      <td>3365817977011237</td>\n",
       "      <td>Melinda Quinlan mamas supporting mamas â™¥ï¸</td>\n",
       "      <td>2023-03-14T20:53:32+0000</td>\n",
       "      <td>3365819093677792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-14T23:38:14+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2139238999669147_3365771280349240</td>\n",
       "      <td>The humble back photo ðŸ”™\\n\\nIn my opinion, usua...</td>\n",
       "      <td>2023-03-14T19:04:59+0000</td>\n",
       "      <td>2023-03-15T02:06:26+0000</td>\n",
       "      <td>Amazing results!</td>\n",
       "      <td>3365939723665729</td>\n",
       "      <td>Devani John ðŸ™Œ</td>\n",
       "      <td>2023-03-15T02:45:53+0000</td>\n",
       "      <td>3365955733664128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2139238999669147_3364783420448026</td>\n",
       "      <td>@everyone would love your help with the live t...</td>\n",
       "      <td>2023-03-13T07:29:09+0000</td>\n",
       "      <td>2023-03-13T07:55:08+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2139238999669147_3364475920478776</td>\n",
       "      <td>Have your ever tried on a pair of shorts - jus...</td>\n",
       "      <td>2023-03-12T18:50:47+0000</td>\n",
       "      <td>2023-03-13T08:16:03+0000</td>\n",
       "      <td>Love this!</td>\n",
       "      <td>3364801680446200</td>\n",
       "      <td>Devani John love the support ðŸ™Œâ¤ï¸</td>\n",
       "      <td>2023-03-13T08:30:22+0000</td>\n",
       "      <td>3364807133778988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>Do you know your why?</td>\n",
       "      <td>2023-03-09T19:03:27+0000</td>\n",
       "      <td>2023-03-10T00:20:34+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>Do you know your why?</td>\n",
       "      <td>2023-03-09T19:03:27+0000</td>\n",
       "      <td>2023-03-10T01:57:44+0000</td>\n",
       "      <td>Without a doubt, when Iâ€™m believe in and am pr...</td>\n",
       "      <td>3362592534000448</td>\n",
       "      <td>Emily Davy proof is in the pudding â¤ï¸ðŸ’ª</td>\n",
       "      <td>2023-03-10T02:38:52+0000</td>\n",
       "      <td>3362610037332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>Do you know your why?</td>\n",
       "      <td>2023-03-09T19:03:27+0000</td>\n",
       "      <td>2023-03-09T23:09:54+0000</td>\n",
       "      <td>ðŸ’¯ agree with how you feel about yourself effec...</td>\n",
       "      <td>3362523780673990</td>\n",
       "      <td>Samantha Flanagan yes that is exactly what Iâ€™m...</td>\n",
       "      <td>2023-03-10T00:20:00+0000</td>\n",
       "      <td>3362550477337987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2139238999669147_3362414344018267</td>\n",
       "      <td>Do you know your why?</td>\n",
       "      <td>2023-03-09T19:03:27+0000</td>\n",
       "      <td>2023-03-10T09:33:47+0000</td>\n",
       "      <td>â¤ï¸</td>\n",
       "      <td>3362782370648131</td>\n",
       "      <td>Stacey MK did you relate?</td>\n",
       "      <td>2023-03-10T22:03:05+0000</td>\n",
       "      <td>3363181773941524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2139238999669147_3361852350741133</td>\n",
       "      <td>@everyone any Sydney Siders on here looking to...</td>\n",
       "      <td>2023-03-08T22:23:29+0000</td>\n",
       "      <td>2023-03-09T08:14:04+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2139238999669147_3360256357567399</td>\n",
       "      <td>Weights are king when it comes to body composi...</td>\n",
       "      <td>2023-03-06T18:49:47+0000</td>\n",
       "      <td>2023-03-07T10:53:51+0000</td>\n",
       "      <td>Do you bulk up when you lift weights?</td>\n",
       "      <td>3360641684195533</td>\n",
       "      <td>K Bev Nyirenda great question! This is VERY ra...</td>\n",
       "      <td>2023-03-07T18:47:13+0000</td>\n",
       "      <td>3360961760830192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2139238999669147_3360256357567399</td>\n",
       "      <td>Weights are king when it comes to body composi...</td>\n",
       "      <td>2023-03-06T18:49:47+0000</td>\n",
       "      <td>2023-03-07T10:53:51+0000</td>\n",
       "      <td>Do you bulk up when you lift weights?</td>\n",
       "      <td>3360641684195533</td>\n",
       "      <td>Yes it does, Thank you. For me l find out that...</td>\n",
       "      <td>2023-03-10T12:40:02+0000</td>\n",
       "      <td>3362882730638095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2139238999669147_3360256357567399</td>\n",
       "      <td>Weights are king when it comes to body composi...</td>\n",
       "      <td>2023-03-06T18:49:47+0000</td>\n",
       "      <td>2023-03-07T10:53:51+0000</td>\n",
       "      <td>Do you bulk up when you lift weights?</td>\n",
       "      <td>3360641684195533</td>\n",
       "      <td>K Bev Nyirenda ironically volume (ie lots of r...</td>\n",
       "      <td>2023-03-10T22:04:39+0000</td>\n",
       "      <td>3363182303941471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2139238999669147_3360256357567399</td>\n",
       "      <td>Weights are king when it comes to body composi...</td>\n",
       "      <td>2023-03-06T18:49:47+0000</td>\n",
       "      <td>2023-03-07T10:53:51+0000</td>\n",
       "      <td>Do you bulk up when you lift weights?</td>\n",
       "      <td>3360641684195533</td>\n",
       "      <td>Amanda Mc Loone nutrition is good.</td>\n",
       "      <td>2023-03-10T23:08:31+0000</td>\n",
       "      <td>3363207860605582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2139238999669147_3360256357567399</td>\n",
       "      <td>Weights are king when it comes to body composi...</td>\n",
       "      <td>2023-03-06T18:49:47+0000</td>\n",
       "      <td>2023-03-07T10:53:51+0000</td>\n",
       "      <td>Do you bulk up when you lift weights?</td>\n",
       "      <td>3360641684195533</td>\n",
       "      <td>K Bev Nyirenda also every individual is differ...</td>\n",
       "      <td>2023-03-11T00:25:57+0000</td>\n",
       "      <td>3363237553935946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2139238999669147_3357641944495507</td>\n",
       "      <td>How do I eat the foods I enjoy and STILL lose ...</td>\n",
       "      <td>2023-03-02T19:15:06+0000</td>\n",
       "      <td>2023-03-02T21:03:53+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2139238999669147_3357641944495507</td>\n",
       "      <td>How do I eat the foods I enjoy and STILL lose ...</td>\n",
       "      <td>2023-03-02T19:15:06+0000</td>\n",
       "      <td>2023-03-05T21:07:12+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2139238999669147_3356343101292058</td>\n",
       "      <td>@everyone Live training Friday morning - I wil...</td>\n",
       "      <td>2023-02-28T19:10:28+0000</td>\n",
       "      <td>2023-02-28T19:26:21+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2139238999669147_3356343101292058</td>\n",
       "      <td>@everyone Live training Friday morning - I wil...</td>\n",
       "      <td>2023-02-28T19:10:28+0000</td>\n",
       "      <td>2023-02-28T21:28:47+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2139238999669147_3355663884693313</td>\n",
       "      <td>Being self conscious almost ruined my relation...</td>\n",
       "      <td>2023-02-27T18:55:30+0000</td>\n",
       "      <td>2023-02-28T04:20:50+0000</td>\n",
       "      <td>So much appreciate the honesty to help all of us.</td>\n",
       "      <td>3355892908003744</td>\n",
       "      <td>Hazel O'leary ah Iâ€™m so glad it helps Hazel â™¥ï¸</td>\n",
       "      <td>2023-02-28T06:22:47+0000</td>\n",
       "      <td>3355943114665390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2139238999669147_3370989849827383</td>\n",
       "      <td>Q&amp;A - protein, protein bars, does training aff...</td>\n",
       "      <td>2023-03-22T20:00:34+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2139238999669147_3370971416495893</td>\n",
       "      <td>Almost half of the world's population are not ...</td>\n",
       "      <td>2023-03-22T19:16:23+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2139238999669147_3367071606885874</td>\n",
       "      <td>If youâ€™re constantly worried about calories an...</td>\n",
       "      <td>2023-03-16T18:50:55+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2139238999669147_3366477613611940</td>\n",
       "      <td>Youâ€™ve heard the saying â€˜a dog is for life - n...</td>\n",
       "      <td>2023-03-15T20:56:22+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2139238999669147_3365106907082344</td>\n",
       "      <td>It would actually break your heart to read my ...</td>\n",
       "      <td>2023-03-13T18:45:59+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2139238999669147_3362409990685369</td>\n",
       "      <td>Being organised is the key to success ðŸ”‘\\n\\nThi...</td>\n",
       "      <td>2023-03-09T18:57:15+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2139238999669147_3360960114163690</td>\n",
       "      <td>Have you been doing spin classes with no resul...</td>\n",
       "      <td>2023-03-07T18:44:52+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2139238999669147_3359640917628943</td>\n",
       "      <td>@everyone Iâ€™m curious when it comes to weight ...</td>\n",
       "      <td>2023-03-05T19:54:44+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2139238999669147_3359623880963980</td>\n",
       "      <td>Meet Caitrin ðŸ™Œ\\n\\nCaitrin is almost with me a ...</td>\n",
       "      <td>2023-03-05T19:14:57+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2139238999669147_3357632041163164</td>\n",
       "      <td>ððžð«ð¬ð¨ð§ðšð¥ ð“ð«ðšð¢ð§ð¢ð§ð  ð¨ð« ðŽð§ð¥ð¢ð§ðž ð‚ð¨ðšðœð¡ð¢ð§ð ?\\n.\\n.\\n(...</td>\n",
       "      <td>2023-03-02T18:51:21+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2139238999669147_3357043277888707</td>\n",
       "      <td>I know itâ€™s hard to believe the creator of the...</td>\n",
       "      <td>2023-03-01T21:25:04+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2139238999669147_3356342237958811</td>\n",
       "      <td>ðŸŽ¯ Nutrition - Hierarchy of Importance ðŸŽ¯\\n.\\n.\\...</td>\n",
       "      <td>2023-02-28T19:08:29+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              post_id  \\\n",
       "0   2139238999669147_3370347119891656   \n",
       "1   2139238999669147_3370347119891656   \n",
       "2   2139238999669147_3370347119891656   \n",
       "3   2139238999669147_3370347119891656   \n",
       "4   2139238999669147_3370347119891656   \n",
       "5   2139238999669147_3370347119891656   \n",
       "6   2139238999669147_3370347119891656   \n",
       "7   2139238999669147_3370342969892071   \n",
       "8   2139238999669147_3370342969892071   \n",
       "9   2139238999669147_3370342969892071   \n",
       "10  2139238999669147_3370342969892071   \n",
       "11  2139238999669147_3370342969892071   \n",
       "12  2139238999669147_3369703796622655   \n",
       "13  2139238999669147_3369703796622655   \n",
       "14  2139238999669147_3369703796622655   \n",
       "15  2139238999669147_3366060270320341   \n",
       "16  2139238999669147_3366060270320341   \n",
       "17  2139238999669147_3366060270320341   \n",
       "18  2139238999669147_3366060270320341   \n",
       "19  2139238999669147_3366060270320341   \n",
       "20  2139238999669147_3366060270320341   \n",
       "21  2139238999669147_3365771280349240   \n",
       "22  2139238999669147_3365771280349240   \n",
       "23  2139238999669147_3365771280349240   \n",
       "24  2139238999669147_3365771280349240   \n",
       "25  2139238999669147_3365771280349240   \n",
       "26  2139238999669147_3364783420448026   \n",
       "27  2139238999669147_3364475920478776   \n",
       "28  2139238999669147_3362414344018267   \n",
       "29  2139238999669147_3362414344018267   \n",
       "30  2139238999669147_3362414344018267   \n",
       "31  2139238999669147_3362414344018267   \n",
       "32  2139238999669147_3361852350741133   \n",
       "33  2139238999669147_3360256357567399   \n",
       "34  2139238999669147_3360256357567399   \n",
       "35  2139238999669147_3360256357567399   \n",
       "36  2139238999669147_3360256357567399   \n",
       "37  2139238999669147_3360256357567399   \n",
       "38  2139238999669147_3357641944495507   \n",
       "39  2139238999669147_3357641944495507   \n",
       "40  2139238999669147_3356343101292058   \n",
       "41  2139238999669147_3356343101292058   \n",
       "42  2139238999669147_3355663884693313   \n",
       "43  2139238999669147_3370989849827383   \n",
       "44  2139238999669147_3370971416495893   \n",
       "45  2139238999669147_3367071606885874   \n",
       "46  2139238999669147_3366477613611940   \n",
       "47  2139238999669147_3365106907082344   \n",
       "48  2139238999669147_3362409990685369   \n",
       "49  2139238999669147_3360960114163690   \n",
       "50  2139238999669147_3359640917628943   \n",
       "51  2139238999669147_3359623880963980   \n",
       "52  2139238999669147_3357632041163164   \n",
       "53  2139238999669147_3357043277888707   \n",
       "54  2139238999669147_3356342237958811   \n",
       "\n",
       "                                         post_message  \\\n",
       "0   @everyone for team training this week. A vast ...   \n",
       "1   @everyone for team training this week. A vast ...   \n",
       "2   @everyone for team training this week. A vast ...   \n",
       "3   @everyone for team training this week. A vast ...   \n",
       "4   @everyone for team training this week. A vast ...   \n",
       "5   @everyone for team training this week. A vast ...   \n",
       "6   @everyone for team training this week. A vast ...   \n",
       "7   How shocked would you be if I told you - there...   \n",
       "8   How shocked would you be if I told you - there...   \n",
       "9   How shocked would you be if I told you - there...   \n",
       "10  How shocked would you be if I told you - there...   \n",
       "11  How shocked would you be if I told you - there...   \n",
       "12  Why your morning routine may actually be NEGAT...   \n",
       "13  Why your morning routine may actually be NEGAT...   \n",
       "14  Why your morning routine may actually be NEGAT...   \n",
       "15  Calories in versus calories out (how do I over...   \n",
       "16  Calories in versus calories out (how do I over...   \n",
       "17  Calories in versus calories out (how do I over...   \n",
       "18  Calories in versus calories out (how do I over...   \n",
       "19  Calories in versus calories out (how do I over...   \n",
       "20  Calories in versus calories out (how do I over...   \n",
       "21  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "22  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "23  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "24  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "25  The humble back photo ðŸ”™\\n\\nIn my opinion, usua...   \n",
       "26  @everyone would love your help with the live t...   \n",
       "27  Have your ever tried on a pair of shorts - jus...   \n",
       "28                              Do you know your why?   \n",
       "29                              Do you know your why?   \n",
       "30                              Do you know your why?   \n",
       "31                              Do you know your why?   \n",
       "32  @everyone any Sydney Siders on here looking to...   \n",
       "33  Weights are king when it comes to body composi...   \n",
       "34  Weights are king when it comes to body composi...   \n",
       "35  Weights are king when it comes to body composi...   \n",
       "36  Weights are king when it comes to body composi...   \n",
       "37  Weights are king when it comes to body composi...   \n",
       "38  How do I eat the foods I enjoy and STILL lose ...   \n",
       "39  How do I eat the foods I enjoy and STILL lose ...   \n",
       "40  @everyone Live training Friday morning - I wil...   \n",
       "41  @everyone Live training Friday morning - I wil...   \n",
       "42  Being self conscious almost ruined my relation...   \n",
       "43  Q&A - protein, protein bars, does training aff...   \n",
       "44  Almost half of the world's population are not ...   \n",
       "45  If youâ€™re constantly worried about calories an...   \n",
       "46  Youâ€™ve heard the saying â€˜a dog is for life - n...   \n",
       "47  It would actually break your heart to read my ...   \n",
       "48  Being organised is the key to success ðŸ”‘\\n\\nThi...   \n",
       "49  Have you been doing spin classes with no resul...   \n",
       "50  @everyone Iâ€™m curious when it comes to weight ...   \n",
       "51  Meet Caitrin ðŸ™Œ\\n\\nCaitrin is almost with me a ...   \n",
       "52  ððžð«ð¬ð¨ð§ðšð¥ ð“ð«ðšð¢ð§ð¢ð§ð  ð¨ð« ðŽð§ð¥ð¢ð§ðž ð‚ð¨ðšðœð¡ð¢ð§ð ?\\n.\\n.\\n(...   \n",
       "53  I know itâ€™s hard to believe the creator of the...   \n",
       "54  ðŸŽ¯ Nutrition - Hierarchy of Importance ðŸŽ¯\\n.\\n.\\...   \n",
       "\n",
       "           post_created_time      comment_created_time  \\\n",
       "0   2023-03-21T19:11:52+0000  2023-03-21T20:45:46+0000   \n",
       "1   2023-03-21T19:11:52+0000  2023-03-21T21:25:54+0000   \n",
       "2   2023-03-21T19:11:52+0000  2023-03-21T23:31:32+0000   \n",
       "3   2023-03-21T19:11:52+0000  2023-03-22T03:42:17+0000   \n",
       "4   2023-03-21T19:11:52+0000  2023-03-22T04:33:53+0000   \n",
       "5   2023-03-21T19:11:52+0000  2023-03-22T04:34:42+0000   \n",
       "6   2023-03-21T19:11:52+0000  2023-03-22T18:53:06+0000   \n",
       "7   2023-03-21T19:02:42+0000  2023-03-22T05:39:10+0000   \n",
       "8   2023-03-21T19:02:42+0000  2023-03-22T05:39:10+0000   \n",
       "9   2023-03-21T19:02:42+0000  2023-03-22T05:39:10+0000   \n",
       "10  2023-03-21T19:02:42+0000  2023-03-22T05:39:10+0000   \n",
       "11  2023-03-21T19:02:42+0000  2023-03-22T05:39:10+0000   \n",
       "12  2023-03-20T18:56:34+0000  2023-03-21T04:42:48+0000   \n",
       "13  2023-03-20T18:56:34+0000  2023-03-21T04:42:48+0000   \n",
       "14  2023-03-20T18:56:34+0000  2023-03-21T04:42:48+0000   \n",
       "15  2023-03-15T07:02:37+0000  2023-03-15T13:38:20+0000   \n",
       "16  2023-03-15T07:02:37+0000  2023-03-15T07:39:21+0000   \n",
       "17  2023-03-15T07:02:37+0000  2023-03-15T07:39:21+0000   \n",
       "18  2023-03-15T07:02:37+0000  2023-03-15T07:39:21+0000   \n",
       "19  2023-03-15T07:02:37+0000  2023-03-15T07:39:21+0000   \n",
       "20  2023-03-15T07:02:37+0000  2023-03-15T07:39:21+0000   \n",
       "21  2023-03-14T19:04:59+0000  2023-03-14T20:28:40+0000   \n",
       "22  2023-03-14T19:04:59+0000  2023-03-14T20:43:52+0000   \n",
       "23  2023-03-14T19:04:59+0000  2023-03-14T20:50:22+0000   \n",
       "24  2023-03-14T19:04:59+0000  2023-03-14T23:38:14+0000   \n",
       "25  2023-03-14T19:04:59+0000  2023-03-15T02:06:26+0000   \n",
       "26  2023-03-13T07:29:09+0000  2023-03-13T07:55:08+0000   \n",
       "27  2023-03-12T18:50:47+0000  2023-03-13T08:16:03+0000   \n",
       "28  2023-03-09T19:03:27+0000  2023-03-10T00:20:34+0000   \n",
       "29  2023-03-09T19:03:27+0000  2023-03-10T01:57:44+0000   \n",
       "30  2023-03-09T19:03:27+0000  2023-03-09T23:09:54+0000   \n",
       "31  2023-03-09T19:03:27+0000  2023-03-10T09:33:47+0000   \n",
       "32  2023-03-08T22:23:29+0000  2023-03-09T08:14:04+0000   \n",
       "33  2023-03-06T18:49:47+0000  2023-03-07T10:53:51+0000   \n",
       "34  2023-03-06T18:49:47+0000  2023-03-07T10:53:51+0000   \n",
       "35  2023-03-06T18:49:47+0000  2023-03-07T10:53:51+0000   \n",
       "36  2023-03-06T18:49:47+0000  2023-03-07T10:53:51+0000   \n",
       "37  2023-03-06T18:49:47+0000  2023-03-07T10:53:51+0000   \n",
       "38  2023-03-02T19:15:06+0000  2023-03-02T21:03:53+0000   \n",
       "39  2023-03-02T19:15:06+0000  2023-03-05T21:07:12+0000   \n",
       "40  2023-02-28T19:10:28+0000  2023-02-28T19:26:21+0000   \n",
       "41  2023-02-28T19:10:28+0000  2023-02-28T21:28:47+0000   \n",
       "42  2023-02-27T18:55:30+0000  2023-02-28T04:20:50+0000   \n",
       "43  2023-03-22T20:00:34+0000                       NaN   \n",
       "44  2023-03-22T19:16:23+0000                       NaN   \n",
       "45  2023-03-16T18:50:55+0000                       NaN   \n",
       "46  2023-03-15T20:56:22+0000                       NaN   \n",
       "47  2023-03-13T18:45:59+0000                       NaN   \n",
       "48  2023-03-09T18:57:15+0000                       NaN   \n",
       "49  2023-03-07T18:44:52+0000                       NaN   \n",
       "50  2023-03-05T19:54:44+0000                       NaN   \n",
       "51  2023-03-05T19:14:57+0000                       NaN   \n",
       "52  2023-03-02T18:51:21+0000                       NaN   \n",
       "53  2023-03-01T21:25:04+0000                       NaN   \n",
       "54  2023-02-28T19:08:29+0000                       NaN   \n",
       "\n",
       "                               parent_comment_message        comment_id  \\\n",
       "0                                                 NaN               NaN   \n",
       "1                                                 NaN               NaN   \n",
       "2                                                 NaN               NaN   \n",
       "3                                                 NaN               NaN   \n",
       "4                                                 NaN               NaN   \n",
       "5                                                 NaN               NaN   \n",
       "6                                                 NaN               NaN   \n",
       "7                                           Ree Waugh  3370594463200255   \n",
       "8                                           Ree Waugh  3370594463200255   \n",
       "9                                           Ree Waugh  3370594463200255   \n",
       "10                                          Ree Waugh  3370594463200255   \n",
       "11                                          Ree Waugh  3370594463200255   \n",
       "12  Set my alarm for 5am today to walk Eddie and b...  3369936533266048   \n",
       "13  Set my alarm for 5am today to walk Eddie and b...  3369936533266048   \n",
       "14  Set my alarm for 5am today to walk Eddie and b...  3369936533266048   \n",
       "15  Thank you for the info Amanda.  I'm struggling...  3366252306967804   \n",
       "16                                        Thank you x  3366072910319077   \n",
       "17                                        Thank you x  3366072910319077   \n",
       "18                                        Thank you x  3366072910319077   \n",
       "19                                        Thank you x  3366072910319077   \n",
       "20                                        Thank you x  3366072910319077   \n",
       "21                                               ðŸ‘ðŸ™ŒðŸ‘ðŸ™Œ  3365809060345462   \n",
       "22                                      Fantastic!!!!  3365815597011475   \n",
       "23         wow amazing mama Gillian NÃ­ HEachthairn! ðŸ’ª  3365817977011237   \n",
       "24                                                NaN               NaN   \n",
       "25                                   Amazing results!  3365939723665729   \n",
       "26                                                NaN               NaN   \n",
       "27                                         Love this!  3364801680446200   \n",
       "28                                                NaN               NaN   \n",
       "29  Without a doubt, when Iâ€™m believe in and am pr...  3362592534000448   \n",
       "30  ðŸ’¯ agree with how you feel about yourself effec...  3362523780673990   \n",
       "31                                                 â¤ï¸  3362782370648131   \n",
       "32                                                NaN               NaN   \n",
       "33              Do you bulk up when you lift weights?  3360641684195533   \n",
       "34              Do you bulk up when you lift weights?  3360641684195533   \n",
       "35              Do you bulk up when you lift weights?  3360641684195533   \n",
       "36              Do you bulk up when you lift weights?  3360641684195533   \n",
       "37              Do you bulk up when you lift weights?  3360641684195533   \n",
       "38                                                NaN               NaN   \n",
       "39                                                NaN               NaN   \n",
       "40                                                NaN               NaN   \n",
       "41                                                NaN               NaN   \n",
       "42  So much appreciate the honesty to help all of us.  3355892908003744   \n",
       "43                                                NaN               NaN   \n",
       "44                                                NaN               NaN   \n",
       "45                                                NaN               NaN   \n",
       "46                                                NaN               NaN   \n",
       "47                                                NaN               NaN   \n",
       "48                                                NaN               NaN   \n",
       "49                                                NaN               NaN   \n",
       "50                                                NaN               NaN   \n",
       "51                                                NaN               NaN   \n",
       "52                                                NaN               NaN   \n",
       "53                                                NaN               NaN   \n",
       "54                                                NaN               NaN   \n",
       "\n",
       "                                        reply_message  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                 Zoe Leah itâ€™s good to see isnâ€™t it?   \n",
       "8                 Amanda Mc Loone yes, very much so ðŸ¤   \n",
       "9   Amanda Mc Loone this is so interesting to know...   \n",
       "10  K Bev Nyirenda scales donâ€™t always show body c...   \n",
       "11                        Amanda Mc Loone Definitely!   \n",
       "12  Lisa Calvert but you obvs needed the sleep ðŸ™Œ a...   \n",
       "13  Amanda Mc Loone I've asked politely a few time...   \n",
       "14                            Lisa Calvert nightmare!   \n",
       "15          Lorraine Wilmot Iâ€™m going to message you!   \n",
       "16             Jessica Protopapas did you enjoy this?   \n",
       "17  Amanda Mc Loone you always give great content....   \n",
       "18  Jessica Protopapas honestly bulking is SO HARD...   \n",
       "19  Amanda Mc Loone excellent.  My fitness pal foo...   \n",
       "20  Jessica Protopapas sounds like youâ€™re on track...   \n",
       "21             Emily Davy the best supportive crew â™¥ï¸   \n",
       "22                  Teresa Madden love the support â™¥ï¸   \n",
       "23          Melinda Quinlan mamas supporting mamas â™¥ï¸   \n",
       "24                                                NaN   \n",
       "25                                      Devani John ðŸ™Œ   \n",
       "26                                                NaN   \n",
       "27                   Devani John love the support ðŸ™Œâ¤ï¸   \n",
       "28                                                NaN   \n",
       "29             Emily Davy proof is in the pudding â¤ï¸ðŸ’ª   \n",
       "30  Samantha Flanagan yes that is exactly what Iâ€™m...   \n",
       "31                          Stacey MK did you relate?   \n",
       "32                                                NaN   \n",
       "33  K Bev Nyirenda great question! This is VERY ra...   \n",
       "34  Yes it does, Thank you. For me l find out that...   \n",
       "35  K Bev Nyirenda ironically volume (ie lots of r...   \n",
       "36                 Amanda Mc Loone nutrition is good.   \n",
       "37  K Bev Nyirenda also every individual is differ...   \n",
       "38                                                NaN   \n",
       "39                                                NaN   \n",
       "40                                                NaN   \n",
       "41                                                NaN   \n",
       "42     Hazel O'leary ah Iâ€™m so glad it helps Hazel â™¥ï¸   \n",
       "43                                                NaN   \n",
       "44                                                NaN   \n",
       "45                                                NaN   \n",
       "46                                                NaN   \n",
       "47                                                NaN   \n",
       "48                                                NaN   \n",
       "49                                                NaN   \n",
       "50                                                NaN   \n",
       "51                                                NaN   \n",
       "52                                                NaN   \n",
       "53                                                NaN   \n",
       "54                                                NaN   \n",
       "\n",
       "          reply_created_time          reply_id  \n",
       "0                        NaN               NaN  \n",
       "1                        NaN               NaN  \n",
       "2                        NaN               NaN  \n",
       "3                        NaN               NaN  \n",
       "4                        NaN               NaN  \n",
       "5                        NaN               NaN  \n",
       "6                        NaN               NaN  \n",
       "7   2023-03-22T06:20:38+0000  3370610399865328  \n",
       "8   2023-03-22T06:21:05+0000  3370610566531978  \n",
       "9   2023-03-22T06:29:21+0000  3370613349865033  \n",
       "10  2023-03-22T07:34:23+0000  3370641649862203  \n",
       "11  2023-03-22T08:25:20+0000  3370661996526835  \n",
       "12  2023-03-21T05:17:56+0000  3369948876598147  \n",
       "13  2023-03-21T05:31:10+0000  3369953436597691  \n",
       "14  2023-03-21T05:32:01+0000  3369953749930993  \n",
       "15  2023-03-15T21:19:52+0000  3366487800277588  \n",
       "16  2023-03-15T07:42:57+0000  3366074393652262  \n",
       "17  2023-03-15T08:06:22+0000  3366092883650413  \n",
       "18  2023-03-15T21:19:32+0000  3366487480277620  \n",
       "19  2023-03-15T21:21:27+0000  3366488646944170  \n",
       "20  2023-03-16T00:52:38+0000  3366569473602754  \n",
       "21  2023-03-14T20:46:02+0000  3365816430344725  \n",
       "22  2023-03-14T20:46:12+0000  3365816490344719  \n",
       "23  2023-03-14T20:53:32+0000  3365819093677792  \n",
       "24                       NaN               NaN  \n",
       "25  2023-03-15T02:45:53+0000  3365955733664128  \n",
       "26                       NaN               NaN  \n",
       "27  2023-03-13T08:30:22+0000  3364807133778988  \n",
       "28                       NaN               NaN  \n",
       "29  2023-03-10T02:38:52+0000  3362610037332031  \n",
       "30  2023-03-10T00:20:00+0000  3362550477337987  \n",
       "31  2023-03-10T22:03:05+0000  3363181773941524  \n",
       "32                       NaN               NaN  \n",
       "33  2023-03-07T18:47:13+0000  3360961760830192  \n",
       "34  2023-03-10T12:40:02+0000  3362882730638095  \n",
       "35  2023-03-10T22:04:39+0000  3363182303941471  \n",
       "36  2023-03-10T23:08:31+0000  3363207860605582  \n",
       "37  2023-03-11T00:25:57+0000  3363237553935946  \n",
       "38                       NaN               NaN  \n",
       "39                       NaN               NaN  \n",
       "40                       NaN               NaN  \n",
       "41                       NaN               NaN  \n",
       "42  2023-02-28T06:22:47+0000  3355943114665390  \n",
       "43                       NaN               NaN  \n",
       "44                       NaN               NaN  \n",
       "45                       NaN               NaN  \n",
       "46                       NaN               NaN  \n",
       "47                       NaN               NaN  \n",
       "48                       NaN               NaN  \n",
       "49                       NaN               NaN  \n",
       "50                       NaN               NaN  \n",
       "51                       NaN               NaN  \n",
       "52                       NaN               NaN  \n",
       "53                       NaN               NaN  \n",
       "54                       NaN               NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = merge_dataframes(comments_df, posts_df, replies)\n",
    "merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The resulting dataframe contains:\n",
    "- Posts from a given Facebook group. Function allows user to specify how many posts to retrieve.\n",
    "- All the comments from the retrieved posts.\n",
    "- All the replies to those comments.\n",
    "\n",
    "The intention was put all the posts, comments, and replies into a single table. Because of this, there are null values and duplicate values because:\n",
    "- Not all posts have comments and not all comments have replies. \n",
    "- Some posts have multiple comments and some comments have multiple replies; thus, some data is repeated.\n",
    "\n",
    "Depending on the task, the above dataframe can be wrangled further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
