{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pandas import json_normalize  \n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "from silvhua import *\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(r'C:\\ProgramData\\Anaconda3\\Scripts')\n",
    "# sys.path.append(r'C:\\ProgramData\\Anaconda3')\n",
    "# sys.path.append(r'C:\\ProgramData\\Anaconda3\\Library\\bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credentials.json\") as f:\n",
    "    access_token = json.load(f)['access_token']\n",
    "user_id = os.environ['fb_user_id']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_post(user_id, access_token, pages=5, filename=None,\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\raw',\n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim'):\n",
    "    user_id = str(user_id)\n",
    "    url_root = \"https://graph.facebook.com/v15.0/\"\n",
    "    url = f'{url_root}{user_id}/posts?access_token={access_token}'\n",
    "    response_json_dict = dict()\n",
    "    df_list = []\n",
    "    for page in range(1,pages+1):\n",
    "        response = requests.get(url)\n",
    "        print('Response status code: ',response.status_code)\n",
    "        response_json_dict[page] = response.json()\n",
    "        df_list.append(json_normalize(response_json_dict[page], record_path='data'))\n",
    "        try:\n",
    "            url = response_json_dict[page]['paging']['next']\n",
    "        except: \n",
    "            pass\n",
    "    df = pd.concat(df_list)\n",
    "    print('Number of posts:',len(df))\n",
    "    if filename:\n",
    "        try:\n",
    "            save_csv(df,filename,csv_path)\n",
    "            savepickle(response_json_dict,filename,'sav',json_path)\n",
    "        except:\n",
    "            print('Unable to save outputs')\n",
    "    return df, response_json_dict\n",
    "\n",
    "# SH 2023-01-16 16:58 Need to update this so that:\n",
    "    # The URL of the last request is returned in case you want to request posts further back\n",
    "    # If it is the last page, it won't just keep making request with the same endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5p, response_json_5p = get_user_post(user_id, access_token)\n",
    "df_5p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved:  C:/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/data/interim/my_fb_posts_5page_2023-01-12.csv\n",
      "File saved:  C:/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/data/raw/my_fb_posts_5page_2023-01-12.sav\n"
     ]
    }
   ],
   "source": [
    "json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\raw'\n",
    "csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim'\n",
    "filename='my_fb_posts_5page_2023-01-12'\n",
    "save_csv(df_5p,filename,csv_path)\n",
    "savepickle(response_json_5p,filename,'sav',json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (119, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-15T20:21:48+0000</td>\n",
       "      <td>Too good to share. Too bad there's none on exe...</td>\n",
       "      <td>10104327314119821_10104331500165951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-13T19:50:47+0000</td>\n",
       "      <td>It’s been 1 month since I finished my data sci...</td>\n",
       "      <td>10104327314119821_10104329950905681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-11T03:17:40+0000</td>\n",
       "      <td>There was a time when my only exercise was run...</td>\n",
       "      <td>10104327314119821_10104327972240941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-09T21:30:18+0000</td>\n",
       "      <td>For the US, \"Wearable technology (#1), strengt...</td>\n",
       "      <td>10104327314119821_10104326999794731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09T17:06:33+0000</td>\n",
       "      <td>Excited to see developments in wearable tech!\\...</td>\n",
       "      <td>10104327314119821_10104326849426071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-12-21T23:40:00+0000</td>\n",
       "      <td>Why the scale goes crazy during the holidays: ...</td>\n",
       "      <td>10104327314119821_10103960734697921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-12-17T05:59:42+0000</td>\n",
       "      <td>Feels like I am at a plateau with hand balanci...</td>\n",
       "      <td>10104327314119821_10103957435309921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-12-14T19:36:06+0000</td>\n",
       "      <td>New toy</td>\n",
       "      <td>10104327314119821_10103955698231041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-12-05T06:57:42+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104327314119821_10103949690400781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-12-05T06:57:26+0000</td>\n",
       "      <td>💛</td>\n",
       "      <td>10104327314119821_10103949690325931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_time  \\\n",
       "0   2023-01-15T20:21:48+0000   \n",
       "1   2023-01-13T19:50:47+0000   \n",
       "2   2023-01-11T03:17:40+0000   \n",
       "3   2023-01-09T21:30:18+0000   \n",
       "4   2023-01-09T17:06:33+0000   \n",
       "..                       ...   \n",
       "18  2021-12-21T23:40:00+0000   \n",
       "19  2021-12-17T05:59:42+0000   \n",
       "20  2021-12-14T19:36:06+0000   \n",
       "21  2021-12-05T06:57:42+0000   \n",
       "22  2021-12-05T06:57:26+0000   \n",
       "\n",
       "                                              message  \\\n",
       "0   Too good to share. Too bad there's none on exe...   \n",
       "1   It’s been 1 month since I finished my data sci...   \n",
       "2   There was a time when my only exercise was run...   \n",
       "3   For the US, \"Wearable technology (#1), strengt...   \n",
       "4   Excited to see developments in wearable tech!\\...   \n",
       "..                                                ...   \n",
       "18  Why the scale goes crazy during the holidays: ...   \n",
       "19  Feels like I am at a plateau with hand balanci...   \n",
       "20                                            New toy   \n",
       "21                                                NaN   \n",
       "22                                                  💛   \n",
       "\n",
       "                                     id  \n",
       "0   10104327314119821_10104331500165951  \n",
       "1   10104327314119821_10104329950905681  \n",
       "2   10104327314119821_10104327972240941  \n",
       "3   10104327314119821_10104326999794731  \n",
       "4   10104327314119821_10104326849426071  \n",
       "..                                  ...  \n",
       "18  10104327314119821_10103960734697921  \n",
       "19  10104327314119821_10103957435309921  \n",
       "20  10104327314119821_10103955698231041  \n",
       "21  10104327314119821_10103949690400781  \n",
       "22  10104327314119821_10103949690325931  \n",
       "\n",
       "[119 rows x 3 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim'\n",
    "df_5p = load_csv('my_fb_posts_5page_2023-01-12.csv', csv_path, column1_as_index=True)\n",
    "df_5p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'data': [{'created_time': '2023-01-15T20:21:48+0000',\n",
       "    'message': \"Too good to share. Too bad there's none on exercise science though.\",\n",
       "    'id': '10104327314119821_10104331500165951'},\n",
       "   {'created_time': '2023-01-13T19:50:47+0000',\n",
       "    'message': \"It’s been 1 month since I finished my data science program. When I finished university years ago, what helped me start my career was speaking to professionals in the industry and continuing to learn. I’m back to that process, this time in a new field. If you can give me some insight to help guide my career exploration, please let me know!\\n\\nWhile I would love a data scientist or machine learning role, I’m aware that these positions are usually given to those with more direct experience. I'm also interested in business analyst and product manager roles in health, fitness, and technology—especially if I can apply my expertise in health, exercise science, and behaviour change.\",\n",
       "    'id': '10104327314119821_10104329950905681'},\n",
       "   {'created_time': '2023-01-11T03:17:40+0000',\n",
       "    'message': 'There was a time when my only exercise was running. I figured that because it was the fastest way to feel breathless, it was the most efficient form of exercise.\\n\\nLook at this infographic, including the legend. “RT” stands for resistance training (”weight training”, or exercises targetting muscles) and “AT” stands for aerobic training (”cardio”).\\n\\nNotice that of the 8 categories of exercise benefits, 7 can be obtained from resistance exercise. Only cardiorespiratory function is unique to aerobic training.\\n\\nResistance training is essential for strength and preventing age-related muscle and bone loss, yet many exercisers don’t do it. Hopefully infographics such as this one help people learn that resistance training is the most impactful use of their exercise time.\\n\\nWhat barriers prevent you from doing resistance training, if any?',\n",
       "    'id': '10104327314119821_10104327972240941'},\n",
       "   {'created_time': '2023-01-09T21:30:18+0000',\n",
       "    'message': 'For the US, \"Wearable technology (#1), strength training with free weights (#2), and outdoor activities (#5) remain within the top five fitness trends, whereas home exercise gyms reveal a downward trend (#13, compared with #2 last year).\"\\n\\nThere\\'s no surprise that interest in wearable tech is rising. My questions is how much the increasing interest in fitness trackers is from people who are already exercising regularly, people who end up increasing their physical activity/health practices as a result of the device, or people with aspirations of improving fitness but remain sedentary.\\n\\nAs a fitness professional, I\\'m happy to see that interest in strength training is increasing!',\n",
       "    'id': '10104327314119821_10104326999794731'},\n",
       "   {'created_time': '2023-01-09T17:06:33+0000',\n",
       "    'message': 'Excited to see developments in wearable tech!\\n\\nIs there one you love or are excited about? If so, why?',\n",
       "    'id': '10104327314119821_10104326849426071'},\n",
       "   {'created_time': '2023-01-07T21:36:58+0000',\n",
       "    'message': 'Pomelos are one of my favourite fruits. It is also known as a Chinese grapefruit. I prefer them over regular grapefruits because they are not bitter and less watery. They are in season now, so try it out while they are available!\\n\\nWhat’s great about pomelos in general is how filling and nutritious they are while having a low calorie density. I like them as an alternative carbohydrate source to grains in a meal. \\n\\nPeople who aren’t familiar with pomelos are not sure how to prepare them, so these photos should help.',\n",
       "    'id': '10104327314119821_10104325303319481'},\n",
       "   {'created_time': '2023-01-06T19:39:51+0000',\n",
       "    'message': \"What's your favourite app or wearable that helps you live a healthier lifestyle?\\n\\nI'm actually a fan of Apple Health. I use it to track my sleep and steps. Women can also track menstrual cycle and related symptoms, which is helpful. Apple Health also integrates with many other apps/wearables so you can see your data on a single platform.\\n\\nMore recently, the sharing feature allows me to monitor my parents' data, including data related to risk of falls.\\n\\nThe data scientist in me wishes their interface had more data visualization and analysis features, but it's still pretty good for built-in free app.\\n\\n#datascience #datavisualization #health\",\n",
       "    'id': '10104327314119821_10104324466536401'},\n",
       "   {'created_time': '2023-01-05T01:47:06+0000',\n",
       "    'message': \"What is one habit you're looking to add right now?\",\n",
       "    'id': '10104327314119821_10104323209450611'},\n",
       "   {'created_time': '2023-01-03T20:34:34+0000',\n",
       "    'message': 'Gamify your goals\\n\\nDuolingo was one of the pioneers in the gamification space. I started using it last year to improve my Chinese and French. For me, the app\\'s most powerful feature is its streak count because:\\n\\n1. I don\\'t want to miss a day of lessons because I\\'ll lose my streak.\\n\\n2. At the same time, I have 1 or 2  banked \"streak freezes\" so I can keep my streak even if I miss a day (you need to earn or purchase the streak freezes).\\n\\nThis approach is great because it is process-oriented (e.g. do this habit) rather than outcome-oriented (e.g. lose weight), which has been shown scientifically to be better for long term adherence.\\n\\nYou don\\'t any app to \"gamify\" a habit you want to add. Crossing off days on a calendar will work equally if not better (the more this reminder is in plain sight, the better). If you like crossing items off a to-do list, add the habit there (I love Asana and Notion for managing tasks).\\n\\nWhat gamification strategies do you have?\\n\\nI just lost my 170+ day Duolingo streak because I missed my lesson on New Year\\'s Eve of all days. I guess the new year really IS a fresh start for me.',\n",
       "    'id': '10104327314119821_10104322209294931'},\n",
       "   {'created_time': '2022-12-31T19:03:58+0000',\n",
       "    'message': 'Exciting developments for athletes as Apple watch moves closer to being able to measure heart rate variability (HRV). Would this tempt you to become/remain an Apple watch user?\\n\\nA few years ago at the peak of my obsession with optimizing strength training, I used a Polar chest strap for 2 minutes each daily before getting out of bed to track my HRV. It was a bit of hassle as I had to keep a dish of water next to the bed to wet the sensor electrodes to avoid confounding the results by getting up. No surprise, I abandoned that daily measurement (my Oura ring measures HRV effortlessly while I sleep, though strength training is not as central to my life as it was before).\\n\\n',\n",
       "    'id': '10104327314119821_10104319695048501'},\n",
       "   {'created_time': '2022-12-30T02:06:59+0000',\n",
       "    'id': '10104327314119821_10104318387234371'},\n",
       "   {'created_time': '2022-12-27T20:45:10+0000',\n",
       "    'message': \"With power comes responsibility.\\n\\nIn the fitness space, people get excited about how AI can analyze movement, but what I am most excited about is how to use AI to help people adopt healthier lifestyles--we generally know it's important to exercise, but doing it is challenging.\\n\\nIf Netflix and YouTube can recommend content you'll find interesting, how can a health app recommend a health practice that you'll adopt to improve your health long term?\\n\\nThe recommendation will likely need to account for and adapt to your preferences, personality, knowledge/skills, and life stage. It also must be the right level of difficulty: If it's too challenging, you'll get discouraged and give up. If it's too easy, you might not get much benefit or lose motivation.\\n\\nWhat application of AI are you most excited about?\",\n",
       "    'id': '10104327314119821_10104316537146961'},\n",
       "   {'created_time': '2022-12-27T03:29:04+0000',\n",
       "    'message': 'While my podcast feed is mostly filled with podcasts on data science, health, and fitness, the Hidden Brain podcast is one that people from all industries will find interesting. This most recent episode features scientist and science communicator Katy Milkman, and it’s just in time for the new year, since it discusses strategies on how to follow through on our goals.',\n",
       "    'id': '10104327314119821_10104315957164251'},\n",
       "   {'created_time': '2022-12-22T19:26:12+0000',\n",
       "    'message': 'It’s not enough to have data.\\n\\nWhen I started my career, I assumed that having knowledge and data were the only important things for being good at my job. It didn’t take too long for me to realize that I could have all the technical knowledge I needed, but it wouldn’t matter if I couldn’t use it to influence people positively.\\n\\nScientists and analysts are all experienced with using figures and tables to show data, but even the best don’t necessarily communicate their findings in a way that is easy to interpret and translate. As someone who appreciates good data visualization, these are the points I will think about when I want to communicate more effectively with data:\\n\\n- The figure title should give the take-home message, not just the topic of the figure.\\n\\n- Use colours and colour intensity to emphasize the most important lines/points.\\n\\n- Annotate the figure so the reader can get the important context without reading the caption/text.\\n\\nA few years ago I decided to focus my professional development on behaviour change. It’s fun to think about this topic from a data science lens. \\n\\nWhat are your favourite examples of good data visualization?',\n",
       "    'id': '10104327314119821_10104312344733591'},\n",
       "   {'created_time': '2022-12-22T18:54:39+0000',\n",
       "    'message': \"If you want to give improve a try but aren't ready to commit to a course, Blind Tiger Comedy is offering a couple free classes the evening of Mon Jan 9. It's a way to play games, meet people, and exercise your brain!\\n\\n\",\n",
       "    'id': '10104327314119821_10104312327652821'},\n",
       "   {'created_time': '2022-12-21T22:42:06+0000',\n",
       "    'message': 'This neighboring house has these long sharp icicle hanging from all along its roof edges, while none of the other houses I saw had them. It got me thinking about the importance of good design; I would NOT want to be walking under one of these vanishing daggers if they dropped.\\n\\nHave you seen any similar icicles? Drop a photo in the comments!',\n",
       "    'id': '10104327314119821_10104311647386081'},\n",
       "   {'created_time': '2022-12-20T15:39:50+0000',\n",
       "    'message': 'A common piece of advice on applying for jobs is to apply even if you don’t meet all the requirements in the job posting. For those of you involved in hiring, how true is this?',\n",
       "    'id': '10104327314119821_10104310456083461'},\n",
       "   {'created_time': '2022-12-20T00:12:56+0000',\n",
       "    'message': 'There are already apps that do what personal trainers do: Creating goal-specific exercise programs, providing exercise demos, and even checking form. Will it put trainers out of work? \\nNo; here’s why:\\n1. The main challenges in fitness relate to getting people to adopt resistance training and continue long term, not simply knowing what to do. A good trainer doesn’t just check form; they help people DO the things that are aligned with their motivations and abilities.\\n\\n2. Even when computer vision becomes advanced enough to distinguish between subtle differences in exercise technique, differences in muscle activation patterns (which can make the difference between pain vs. no pain) cannot always be be seen, even by an expert coach. A good movement coach knows the right questions and cues to use for the individual in front of them.\\n\\nWhat WILL happen is that these AI-based fitness products will:\\n\\n- Allow more people to exercise smarter.\\n\\n- Weed out low quality exercise professionals and force remaining ones to up their standards.\\n\\n- Make it easier for exercisers and fitness professionals to make data-informed decisions through easier data tracking and visualization.\\n\\nWhat do you think?',\n",
       "    'id': '10104327314119821_10104309935257201'},\n",
       "   {'created_time': '2022-12-19T02:12:15+0000',\n",
       "    'message': 'In 2021 I got the audiobook Weapons of Math Destruction by Cathy O’Neil after joining a book club for women in STEM. It discusses the dangers of artificial intelligence algorithms in perpetuating social inequalities. I had no idea at the time that I would embark on a career where I would be developing AI algorithms. I’ll be relistening to this book, this time with the perspective of a data scientist.\\n\\nHave ideas on how to change AI to reduce social inqualities? Comment below!\\n\\n',\n",
       "    'id': '10104327314119821_10104309149586691'},\n",
       "   {'created_time': '2022-12-17T19:46:27+0000',\n",
       "    'message': 'Why walking is cardio are important, but not enough to keep you fit.\\n\\nLifting weights and resistance training are not just just for athletes or people who want to change their appearance; it helps to:\\n\\n- Increase strength. That way, you can do everyday activities more easily with less pain/injury.\\n- Counteract muscle imbalances. Most sports and cardio activities (e.g. running, cycling, hiking) inherently train some muscles and not others. A good resistance training program systematically targets the various parts of the body to help you maintain good posture and reduce aches/pains.\\n- Counteract the effects of ageing: Falls, broken hips, frailty, and stooped posture should not be accepted as inevitable.\\n\\nHave questions or want to discuss? Comment below as this is a topic I’m passionate about.',\n",
       "    'id': '10104327314119821_10104308112115791'},\n",
       "   {'created_time': '2022-12-15T20:52:22+0000',\n",
       "    'message': 'How doing just bodyweight 15 squats can change your body.\\n\\nEven with long work hours, you can sprinkle in moments of strength training. The research shows that it helps to improve metabolism (e.g. blood sugar control) AND may even support muscle building—just 15 squats can do the trick, according to this study.\\n\\nFor the past 3 months, I had very little time to do much else aside from trying to keep up with the material in my data science bootcamp. I was in no mindset to take a half hour to work out, but when I had to use the bathroom, I would do 2 pull ups and/or a pistol squat.\\n\\nDon’t let perfectionism stop you from being just a bit more active. Will you give this a try? \\n\\nRead about it here on Examine.com',\n",
       "    'id': '10104327314119821_10104306747690111'},\n",
       "   {'created_time': '2022-12-13T21:43:46+0000',\n",
       "    'message': 'I just finished my diploma in data science from Lighthouse Labs and am excited for the new opportunities this opens in the tech sector! \\n\\nA bit about me: I have Master of Science in kinesiology and been working as a kinesiologist and personal trainer since 2014. My ideal next step is to work in an organization that uses technology and products to promote health/fitness on a large scale, such as health apps, gyms, or fitness product manufacturers. \\n\\nMy ask: If you have a connection with such an organization and they are open to chat, I’d love to learn more about that business, even if there are no job current openings.',\n",
       "    'id': '10104327314119821_10104305474985621'},\n",
       "   {'created_time': '2022-12-06T16:38:38+0000',\n",
       "    'message': \"Hard to believe, but Friday at noon I'll be presenting my final project for my data science diploma. My project is titled Load-Velocity Profiling to Estimate 1-Repetition Maximums (I'm still a fitness professional, after all). I'm also excited to see what my classmates will be presenting; they're an ambitious, bright group who have helped me better understand the course material.\\n\\nIf you have an interest in data and machine learning, feel free to register to attend. https://hopin.com/events/national-demo-day-december-8\\n\\nThere will be multiple demos going on at once (including web security and web development); I'm in the data science program.\",\n",
       "    'id': '10104327314119821_10104300108759581'},\n",
       "   {'created_time': '2022-12-05T03:14:50+0000',\n",
       "    'message': \"I made a little web app to predict 1RM using machine learning. Here's a preview.\\n\\nIf you happen to know your squat velocity, this app will estimate your 1RM and plot the load-velocity profile for the barbell squat.\\n\\nHere's the app: https://silvhua-lighthouse-capstone-project-srcapp-wafhso.streamlit.app/\",\n",
       "    'id': '10104327314119821_10104298959318071'},\n",
       "   {'created_time': '2022-11-24T05:50:31+0000',\n",
       "    'message': 'https://medium.com/defy-time-fitness/data-visualization-of-canadas-fitness-as-measured-by-stats-canada-f4ed24c7d969\\n\\nDid you know that Stats Canada has been doing fitness testing for a representative sample of the population every 2 years?',\n",
       "    'id': '10104327314119821_10104290584441391'}],\n",
       "  'paging': {'previous': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&__previous=1&since=1673814108&until&__paging_token=enc_AdDUR13G4nqCJEhrZCCPN83BVhKFXipZCRS8PIpUWSaJACtxq3ty3B5tqJsnwHfJIOfjBOWCVDsAKOQUnpzPTa8pkYJWmIZBaq827HizpddY9dilPcmsWpgysLVowv4cKfZBzf0ZD',\n",
       "   'next': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&until=1669269031&since&__paging_token=enc_AdCwNWppC954M9olEmJHgooW0YzBPIMlJGWuraK137VkrRUSpoq70zrAaAwZCuQkbmPbyTjmCiaf4TpmFyfyK7aNTPzsR7VrUG3f15sgXQiMD6gpoAGhLQInQmWb9lDJomZB0ZD&__previous'}},\n",
       " 2: {'data': [{'created_time': '2022-11-17T03:29:10+0000',\n",
       "    'message': \"Hello, fellow lifters and coaches. Help me out? If you know your 1RM squat, this is for you. All you have to do is do a quick survey. \\n\\nI will have 2 weeks starting Nov 24 to work on a final project that involves machine learning (a subset of artificial intelligence). More data = more accurate predictions.\\n\\nThe goal of this project is to create an algorithm that can tell you how much weight to lift for the prescribed number of reps, desired effort level (reps in reserve), and your attributes. Here's why:\\n1. The charts/formulas based %1RM have a lot of error; they are based on population averages and may not apply to you as an individual. Let's find an estimate that is more accurate for YOU.\\n2. We need a way to select an appropriate weight even without recent 1RM testing.\\n\\nFor simplicity, I am collecting data only on the barbell squat. Front squat, back squat, and zercher squats are included as long as the data provided are all for the same exercise. Here's my request:\\n1. Look at your training log and fill in the following Google form. My algorithm will require a rating of effort based on reps in reserved (RIR). If you don't track your reps in reserve, do it on your next squat session and come back! You can submit anonymously.\\n2. Share this with your lifting friends! The more data I have, the more accurate the predictions will be.\\n3. If you have the right client data, you can enter that as well!\\n\\nThanks in advance!\",\n",
       "    'id': '10104327314119821_10104281613599031'},\n",
       "   {'created_time': '2022-11-07T05:16:16+0000',\n",
       "    'message': \"Hi, fellow lifters, kinesiologists, and fitness pros. I'm exploring options for a final project I will be doing for my data science program and could use your help.\\n\\nRep max estimation equations exist, but usually have a lot of error for any given individual and/or circumstances. It would be amazing to have a machine learning model that can estimate YOUR rep max given YOUR previously-logged reps/sets, RPE/RIR, and even whether it's a regular training session or a session you've peaked for. \\n\\nMy questions are:\\n 1. Does this type of app/algorithm already exist? I am pretty sure most just use the basic static equations.\\n 2. If not, I would LOVE to create this. The trouble would be getting enough data of training logs in order to sufficiently train and tune the model. Any ideas where I could go about getting adequate data for this purpose? \\n\\nI don't think looking at powerlifting/weightlifting competition results would the best data because:\\n 1. Most people don't train using maximal weight to failure most of the time (I envision a model that updates its estimations weekly). I want this algorithm to help people determine the right weight to use no matter what rep range, i.e. it should be able to estimate 1-15+ rep max.\\n 2. Repeated frequent data would be required so you won't have to do max testing for accurate rep max estimations.\\n\\nThanks in advance!\",\n",
       "    'id': '10104327314119821_10104254212615821'},\n",
       "   {'created_time': '2022-11-03T07:22:04+0000',\n",
       "    'message': 'Anyone have a cleaning service to recommend for East Vancouver?',\n",
       "    'id': '10104327314119821_10104240889695061'},\n",
       "   {'created_time': '2022-09-27T21:34:58+0000',\n",
       "    'message': 'Seeking ways to counteract my sedentary lifestyle as I will be glued to my computer 12 hours a day for the next couple months. Got this nifty fold up desk for my bike anf set up my old monitor. \\nHappy for more tips on reducing butt soreness. 😂\\n\\nLighthouse Labs\\n\\n#datascience #lighthouselabs',\n",
       "    'id': '10104327314119821_10104157173572841'},\n",
       "   {'created_time': '2022-09-18T20:44:28+0000',\n",
       "    'message': \"There’s an abundance of free training resources out there, so why bother paying for it? \\n\\nThe way I see it, my role is to apply my years of specialized education and experience to save people the guess work so they can just do the best bang-for-buck workouts AND still have time for other things. Online training can never replace in-person coaching, but I strive to provide the same professional guidance online as I do in person. That’s why I started making exercise videos. \\n\\nJulie* represents the type of client I most want to help: She has a high-stress career AND has 3 kids including a toddler. “I feel stronger, and more confident taking care of my baby daughter. I like the program you designed for me: it fits the tight time schedule I have, and I can always extend them when I have time (do 3 sets instead of 2). As the program stands now, I don't feel too pressured for time, and thus less stressed.”\\n\\nJulie has made progress despite having little time to herself, being glued to her computer all day, and training with just a 12 kg kettlebell, 2x3kg dumbbells, and some bands. This is because:\\n- Exercise sessions take as little as 10 minutes per day.\\n- The exercises in her program provide high return-on-investment. \\n- We constantly discuss how she can improve her sleep, nutrition, and recovery habits.\\n\\nThe deadlift with two bands is one such exercise in Julie’s program. It works many muscles, including muscles that help her improve her low back pain. All you need is 2 bands and an anchor (these are from Amazon).\\n\\nWhat do you do to take care of your body when you are short on time and energy? Comment below!\\n\\n* Name changed.\",\n",
       "    'id': '10104327314119821_10104150221879091'},\n",
       "   {'created_time': '2022-09-16T21:50:59+0000',\n",
       "    'message': 'Yelling improves strength. \\n\\nThanks to @coachjure and @anthony.agtarap for coaching throughout the years so I can add 1kg to my personal record every once in a while. Striving for mastery and performance is the only way to stay motivated to train long term.',\n",
       "    'id': '10104327314119821_10104148636146911'},\n",
       "   {'created_time': '2022-09-14T20:27:12+0000',\n",
       "    'message': '<3',\n",
       "    'id': '10104327314119821_10104147163054001'},\n",
       "   {'created_time': '2022-09-13T20:54:02+0000',\n",
       "    'message': 'Congrats to Sus An and Eric for finding happiness in each other and getting married last week. \\n\\nIt was a good time. Left my hair down for the first time in years. Managed to avoid spraining my ankles in heels.',\n",
       "    'id': '10104327314119821_10104146652771611'},\n",
       "   {'created_time': '2022-09-04T17:18:16+0000',\n",
       "    'message': 'https://www.agatsu.com/product/vancouver-kettlebell-certification/?fbclid=IwAR3H-zfF2wEiEMh6yfDDEY3EMbzWH4wOO34-BERVDQk6ckiWiUhyuUzvn48',\n",
       "    'id': '10104327314119821_10104136046307051'},\n",
       "   {'created_time': '2022-09-02T05:38:17+0000',\n",
       "    'message': \"In case you're looking to level up your kettlebell skills, my coach Anthony Agtarap will be teaching the Agatsu Kettlebell certification very soon.\",\n",
       "    'id': '10104327314119821_10104134119438511'},\n",
       "   {'created_time': '2022-08-30T19:30:16+0000',\n",
       "    'message': 'https://www.youtube.com/watch?v=keBZfGAmq2Q',\n",
       "    'id': '10104327314119821_10104132241506901'},\n",
       "   {'created_time': '2022-08-30T19:16:12+0000',\n",
       "    'message': 'My improv team got invited back to do a bonus show next week :) \\n\\n',\n",
       "    'id': '10104327314119821_10104132237080771'},\n",
       "   {'created_time': '2022-08-27T16:47:31+0000',\n",
       "    'message': '#STEM - Strength Training and #Ergonomics Minute!\\nThere are several reasons why inverted rows (aka TRX rows, ring rows, suspension trainer rows, bodyweight rows) stand out:\\n👉Compared to some other row variations, it puts negligible strain on the low back--great if you have low back pain.\\n👉Great as part of minimalist, time-efficient home workouts or travel workouts as the equipment is inexpensive, easy to pack, and allows for endless exercise options for the entire body.\\n👉You can vary the difficulty even with only one piece of equipment.\\n👉The demands of the movement compliment the strength curve of the muscles, i.e. the movement is hardest at your strongest position and easiest at your weakest position so the muscles get trained uniformly along the entire range of motion. Contrast this with rows using a band, which become heavier as the band stretches and become hardest at your weakest position.\\n👉Helps improve posture, improve shoulder health, and strengthen the core.•\\n•\\nHave more questions or want some more guidance on your fitness? Comment below! I help STEM professionals train and eat to get the bodies they want while eating carbs.',\n",
       "    'id': '10104327314119821_10104130436244661'},\n",
       "   {'created_time': '2022-08-18T22:10:23+0000',\n",
       "    'message': 'Finally finished this free course from Lighthouse Labs!',\n",
       "    'id': '10104327314119821_10104123845332901'},\n",
       "   {'created_time': '2022-08-16T20:38:04+0000',\n",
       "    'message': 'Posted @withregram • Blind Tiger Comedy Let’s meet your Bloc Tiger Comedy Fest groups!\\n\\nFirst up we have:\\n\\nFREE SANDWICHES\\n\\nEight assorted Intro 2 improvisers,\\n1 special summer combo.\\n\\nWe aim to serve up tasty, à la carte amusement but can’t promise any of it will be healthy.\\n\\nWatch them perform on Wednesday August 24th at 7pm!\\n\\nTickets at https://www.eventbrite.ca/e/bloc-tiger-comedy-fest-august-24-tickets-382640396727?aff=ebdsoporgprofile\\n\\n#bloctigercomedyfest',\n",
       "    'id': '10104327314119821_10104121939517171'},\n",
       "   {'created_time': '2022-08-10T21:27:15+0000',\n",
       "    'message': \"If you're up for some laughs, come to this improv show. My improv team, Free Sandwiches, will be among the performers. :)\\n\\n\",\n",
       "    'id': '10104327314119821_10104117211896361'},\n",
       "   {'created_time': '2022-08-08T05:30:54+0000',\n",
       "    'message': 'Did you know that Duolingo pioneered gamification in apps?',\n",
       "    'id': '10104327314119821_10104115569053631'},\n",
       "   {'created_time': '2022-08-06T19:02:28+0000',\n",
       "    'message': 'What’s that muscle popping in my right armpit in the jerk? 😂',\n",
       "    'id': '10104327314119821_10104114647330771'},\n",
       "   {'created_time': '2022-07-31T20:38:36+0000',\n",
       "    'message': 'I was craving some cake, then realized that I could simply make my paleo banana bread and whip up my own healthy protein peanut butter icing. Nutritious, no added sugar, delicious, and perfect for the #lazycook like me. 😋\\n\\n#dessert #bananabread',\n",
       "    'id': '10104327314119821_10104111228087961'},\n",
       "   {'created_time': '2022-07-21T17:03:08+0000',\n",
       "    'message': \"Food affects mental health. Here's a great infographic about it.\\n\\n\",\n",
       "    'id': '10104327314119821_10104104786980991'},\n",
       "   {'created_time': '2022-07-14T23:29:10+0000',\n",
       "    'id': '10104327314119821_10104101342463831'},\n",
       "   {'created_time': '2022-07-01T04:31:10+0000',\n",
       "    'message': 'We all need to do some single leg work to keep the back and knees healthy. If you don’t like them because you feel unstable doing them, you probably need them even more. Here are two good exercises that are suitable for even bare-bones gyms like in hotels and apartments: \\n✅ Cable single leg hip hinge to single arm row.\\n✅ Dumbbell split squat.',\n",
       "    'id': '10104327314119821_10104092000370461'},\n",
       "   {'created_time': '2022-07-01T04:29:42+0000',\n",
       "    'message': 'Chocolate fountain￼',\n",
       "    'id': '10104327314119821_10104091999866471'},\n",
       "   {'created_time': '2022-06-30T05:29:48+0000',\n",
       "    'message': 'Had the gym all to myself in the afternoon so I made good use of the wall for 70 minutes 😂',\n",
       "    'id': '10104327314119821_10104091232828621'}],\n",
       "  'paging': {'previous': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&since=1668655750&until&__previous=1&__paging_token=enc_AdDrJq4y7RxI5pgCWeD4EUGZCY1Q6YU8tZAOJjuyC90GP03tYy9wVEB8ljnGVHmx32OJV8BLbMFKvqMoYaRE69ZB72U8mUjIPqq4WWikPeyNFHzpuFhCsJCxBfggpp6YIY1xAQZD',\n",
       "   'next': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&since&until=1656566988&__paging_token=enc_AdAzzpTnTyDMnqmuXGAZA2neQyN7ZBLvjhGG08NV4aa1gPVfGb0MSVHUb63C5udSCFp0ETh2JI3uu66vI5VoBVt8fYEnbaAStyDoN4nDe4hNS62wK6Jq0QBv6GgeISMPBAUOYZD&__previous'}},\n",
       " 3: {'data': [{'created_time': '2022-06-30T05:10:55+0000',\n",
       "    'message': '3 platforms and 3 warm up areas going on at once! Was too close to fit it all in the video.',\n",
       "    'id': '10104327314119821_10104091225737831'},\n",
       "   {'created_time': '2022-06-06T00:49:27+0000',\n",
       "    'message': 'Does anyone have a recommendation for a family doctor who is accepting new patients? Preferrably in Vancouver.',\n",
       "    'id': '10104327314119821_10104075778209801'},\n",
       "   {'created_time': '2022-06-04T19:30:23+0000',\n",
       "    'message': 'Errors and practice are necessary for learning',\n",
       "    'id': '10104327314119821_10104074950099341'},\n",
       "   {'created_time': '2022-06-03T17:22:11+0000',\n",
       "    'id': '10104327314119821_10104074188745101'},\n",
       "   {'created_time': '2022-06-02T14:51:09+0000',\n",
       "    'message': 'This dude is insanely athletic',\n",
       "    'id': '10104327314119821_10104072896140491'},\n",
       "   {'created_time': '2022-05-30T17:45:21+0000',\n",
       "    'id': '10104327314119821_10104067688701241'},\n",
       "   {'created_time': '2022-05-28T16:54:01+0000',\n",
       "    'message': 'Walked by the gelato shop today. Apparently they will be giving a free scoop for first 100 people! Unfortunately they were still closed when I passed by.',\n",
       "    'id': '10104327314119821_10104065813833491'},\n",
       "   {'created_time': '2022-05-27T19:26:08+0000',\n",
       "    'id': '10104327314119821_10104065166575601'},\n",
       "   {'created_time': '2022-05-27T18:11:08+0000',\n",
       "    'id': '10104327314119821_10104065135393091'},\n",
       "   {'created_time': '2022-05-23T05:51:18+0000',\n",
       "    'id': '10104327314119821_10104062408203401'},\n",
       "   {'created_time': '2022-05-22T01:11:06+0000',\n",
       "    'message': \"Grateful for the opportunity to have shared with Drake Medox College students and alumni on how strength training should be a key strategy to keep healthcare workers healthy and avoid injuries.\\n\\nDo your workplace benefits include strength training? I'd love to hear what employers do to help workers thrive.\",\n",
       "    'id': '10104327314119821_10104061580387351'},\n",
       "   {'created_time': '2022-05-18T04:55:33+0000',\n",
       "    'id': '10104327314119821_10104059390191521'},\n",
       "   {'created_time': '2022-05-02T23:45:29+0000',\n",
       "    'id': '10104327314119821_10104048897324311'},\n",
       "   {'created_time': '2022-05-02T19:08:36+0000',\n",
       "    'message': '\"Despite the common usage of these performance supplements among female athletes, only 23% of participants were women, and 34% of the studies reviewed included at least one female athlete.\\nDespite the demand for female-specific sports science and sports medicine research, only 0-8% of the studies investigated supplement usage in women exclusively. Additionally, only 14% of studies including women tried to define menstrual status, and only three studies total included implementation of best practice methodologies to assess menstrual status.\"\\n\\nThe Female Athlete Program. (2022 April). STUDY SPOTLIGHT: AUDITING THE REPRESENTATION OF FEMALE VERSUS MALE ATHLETES IN SPORTS SCIENCE AND SPORTS MEDICINE RESEARCH: EVIDENCE-BASED PERFORMANCE SUPPLEMENTS. Female Athlete Newsletter, https://mailchi.mp/a597b5ede306/female-athlete-newsletter-april-2022?e=c14b6fce4e\\n\\nhttps://www.mdpi.com/2072-6643/14/5/953',\n",
       "    'id': '10104327314119821_10104048738053491'},\n",
       "   {'created_time': '2022-05-02T03:44:34+0000',\n",
       "    'message': \"I'm not going to remember any of this Python coding that I just learned. But 'twas fun to solve black-and-white problems.\",\n",
       "    'id': '10104327314119821_10104048371378311'},\n",
       "   {'created_time': '2022-04-29T19:17:52+0000',\n",
       "    'id': '10104327314119821_10104046720706271'},\n",
       "   {'created_time': '2022-04-28T04:49:36+0000',\n",
       "    'message': 'For women in STEM:\\n',\n",
       "    'id': '10104327314119821_10104045755735081'},\n",
       "   {'created_time': '2022-04-25T23:52:50+0000',\n",
       "    'message': 'Got this fluke on first attempt',\n",
       "    'id': '10104327314119821_10104044175591701'},\n",
       "   {'created_time': '2022-04-22T05:31:09+0000',\n",
       "    'message': 'This feels like earning a gold star in as an elementary school kid.',\n",
       "    'id': '10104327314119821_10104041516221101'},\n",
       "   {'created_time': '2022-04-17T04:40:02+0000',\n",
       "    'message': 'Having fun learning to code!',\n",
       "    'id': '10104327314119821_10104038470444861'},\n",
       "   {'created_time': '2022-04-17T04:40:02+0000',\n",
       "    'message': 'Having fun learning to code!',\n",
       "    'id': '10104327314119821_10104038470449851'},\n",
       "   {'created_time': '2022-04-15T20:16:13+0000',\n",
       "    'message': 'Fourth time’s a charm￼',\n",
       "    'id': '10104327314119821_10104037701306221'},\n",
       "   {'created_time': '2022-04-13T17:13:43+0000',\n",
       "    'message': 'I can get behind this',\n",
       "    'id': '10104327314119821_10104036527683171'},\n",
       "   {'created_time': '2022-04-10T20:55:00+0000',\n",
       "    'message': 'Look what memory popped up!\\n\\nLynda En, Kevin Chang , Denise Lin, Pammy Lee, Titus Varga, Alisa Lin, Viet Nguyen, Lia Lowe, Zelia Lim, Anran Luo, Mo Liu',\n",
       "    'id': '10104327314119821_10104035018702181'}],\n",
       "  'paging': {'previous': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&since=1656565855&until&__previous=1&__paging_token=enc_AdDfbZAZAdCr7QZCiUYJaZCRWzXu3lykmZAz4uyZA2h84Yfp4dwLXHC1mAz3myXvza7zPcjPpp5G4dVFJLQPIdUaabSIZArVpdfyaVGKZAAKoKbhCyyu2atrZA94wjn1ZAQqRNY3Bn1ngZD',\n",
       "   'next': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&since&until=1649624100&__paging_token=enc_AdAwZAkZAMFbIOqlKXBuW7ZBT3wiDgoo5fRGsIYwjWIsHrl8Fmx7snAN5wMuAefE09r6uMMetICnlQ8gpfTnMmfIBz1i7hGZAo60aByObGCyaxefMhdp4Ha8SXUZAZBvcHevGvJeMZD&__previous'}},\n",
       " 4: {'data': [{'created_time': '2022-04-04T06:01:44+0000',\n",
       "    'message': 'This guy’s a fast eater',\n",
       "    'id': '10104327314119821_10104031384814521'},\n",
       "   {'created_time': '2022-04-03T17:45:01+0000',\n",
       "    'message': 'Errors and small wins.',\n",
       "    'id': '10104327314119821_10104030950290311'},\n",
       "   {'created_time': '2022-03-28T23:40:19+0000',\n",
       "    'message': 'Ube protein cheesecake attempt #2 \\n\\n#protein #cheesecake #proteincheesecake #healthyrecipes #healthydesserts #foodporn #cooking #lowfatdesserts #lowcarbdesserts',\n",
       "    'id': '10104327314119821_10104027633342501'},\n",
       "   {'created_time': '2022-03-26T03:33:01+0000',\n",
       "    'message': 'Performance doesn’t improve linearly, so persistence is key to make progress. What skill are you working on? It could be an instrument, dance, or sport.\\n\\nIt felt like I had regressed with my hand balancing skills. I took a week off of handstands practice to reduce fatigue before my Olympic lifting competition, and that allowed an improvement in hand balancing to finally reveal itself. \\n\\nPeople are surprised that there is such thing as a handstands class. You have to try it to understand the difficulty and variations. I had a  revelation just this week about how to better stabilize with the core—tensing the right places, the right amount, at the right time.',\n",
       "    'id': '10104327314119821_10104025813763951'},\n",
       "   {'created_time': '2022-03-21T06:58:08+0000',\n",
       "    'id': '10104327314119821_10104022820592291'},\n",
       "   {'created_time': '2022-03-21T00:06:07+0000',\n",
       "    'id': '10104327314119821_10104022592294801'},\n",
       "   {'created_time': '2022-03-18T16:00:07+0000',\n",
       "    'message': 'Anthony Agtarap will be coaching me again at tomorrow’s Master’s Provincial Championships.',\n",
       "    'id': '10104327314119821_10104020848943491'},\n",
       "   {'created_time': '2022-03-16T06:00:55+0000',\n",
       "    'message': 'Insane save in the clean and jerk!\\n\\n',\n",
       "    'id': '10104327314119821_10104019463854221'},\n",
       "   {'created_time': '2022-03-10T00:51:25+0000',\n",
       "    'message': 'Ube (purple yam) protein cheesecake',\n",
       "    'id': '10104327314119821_10104015510357061'},\n",
       "   {'created_time': '2022-02-26T22:56:13+0000',\n",
       "    'message': \"My coach's business is being nominated for a Small Business BC award! Please consider voting for Engineered Bodies Strength & Conditioning\\nIn addition to creating a great community (not just a gym), Anthony Agtarap and Samantha Agtarap have been advocating for independent gym owners and their clients throughout the pandemic.\\n\\n\",\n",
       "    'id': '10104327314119821_10104008279033691'},\n",
       "   {'created_time': '2022-02-21T20:25:42+0000',\n",
       "    'message': 'Rest day means motor skills practice day. \\n\\nHow do you move on rest days?',\n",
       "    'id': '10104327314119821_10104004560680301'},\n",
       "   {'created_time': '2022-02-18T05:45:46+0000',\n",
       "    'message': \"Here's an event to promote STEM fields to high school girls.\",\n",
       "    'id': '10104327314119821_10104001498237461'},\n",
       "   {'created_time': '2022-02-13T03:15:56+0000',\n",
       "    'message': 'Made a green tea durian cheesecake',\n",
       "    'id': '10104327314119821_10103998087727151'},\n",
       "   {'created_time': '2022-02-12T17:42:33+0000',\n",
       "    'message': 'Chocolate and custard is a good combo￼',\n",
       "    'id': '10104327314119821_10103997754654631'},\n",
       "   {'created_time': '2022-02-09T07:20:17+0000',\n",
       "    'message': 'Zahra Jamal, this is how to make taro paste. Too mich work for this lazy cook haha.',\n",
       "    'id': '10104327314119821_10103995817571561'},\n",
       "   {'created_time': '2022-02-08T23:52:13+0000',\n",
       "    'message': 'I think this flavour of protein cheesecake has been the biggest hit with my parents. Each serving or 1/4 of the recipe has 20 g of protein and 212 calories as long as you use a 0 cal sweetener such as @voluptafoods and 1% dry curd cottage cheese. \\n\\nI used 170 g of durian, so you can adjust the amount of durian according to preference.\\n\\n#protein #cheesecake #proteincheesecake #ketorecipes #healthyrecipes #healthydesserts #foodporn #cooking #lowfatdesserts #lowcarbdesserts #easyrecipes #durian #lunarnewyear',\n",
       "    'id': '10104327314119821_10103995601474621'},\n",
       "   {'created_time': '2022-02-06T22:47:13+0000',\n",
       "    'message': 'For a while it felt like I was at a plateau with my handstand balancing. Despite that, I kept practising as my coaches told me that was normal and that takes a long time. I’m feeling better at balancing, particularly with the version facing away from the wall.\\n\\nWhat skills are you working on?',\n",
       "    'id': '10104327314119821_10103994401708961'},\n",
       "   {'created_time': '2022-01-31T00:20:34+0000',\n",
       "    'message': 'It’s been interesting to experiment with little tweaks tension, position, and weight shift with #handstands',\n",
       "    'id': '10104327314119821_10103988597111421'},\n",
       "   {'created_time': '2022-01-29T23:36:43+0000',\n",
       "    'message': 'A couple of times someone ￼recognized me as I was out and about with my mask on. I was impressed they could tell who I was because I did not recognize them with the mask out of context. ￼￼\\n\\nMy friend posted this and at first I thought was that it was cool to see an Asian female athlete on TV. And then I read what he wrote. ￼￼',\n",
       "    'id': '10104327314119821_10103987833381941'},\n",
       "   {'created_time': '2022-01-28T05:59:02+0000',\n",
       "    'id': '10104327314119821_10103986682139041'},\n",
       "   {'created_time': '2022-01-21T18:12:40+0000',\n",
       "    'message': 'I recommend this certification for trainers snd kinesiologists to have a great system for assessing and training clients.',\n",
       "    'id': '10104327314119821_10103981863585461'},\n",
       "   {'created_time': '2022-01-17T04:09:15+0000',\n",
       "    'message': \"I like to indulge in a show while I cycle, something that doesn't require me to think.\\n\\nSadly, I have finished the entirety of Brooklyn Nine-Nine on Netflix. It was hilarious yet clever and even action-packed. I started watching Seinfeld but it's just not up to par. \\n\\nAny other recommendations for an equivalent laugh out loud comedy to stream on Netflix or Amazon?\",\n",
       "    'id': '10104327314119821_10103978933212951'},\n",
       "   {'created_time': '2022-01-16T23:14:17+0000',\n",
       "    'message': 'https://pubmed.ncbi.nlm.nih.gov/34868603/\\n\\nTL; dr?\\nhttps://examine.com/members/summaries/issue/january-2022/summary-1rNRp1',\n",
       "    'id': '10104327314119821_10103978732545091'}],\n",
       "  'paging': {'previous': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&since=1649052104&until&__previous=1&__paging_token=enc_AdDO7DxTvAHNHuuxrsl6IBgl3hVkRwtscwc9X5eyWpTl7fyqMIxCpOhGTQV9zEpsfMVu0534nDJCxUHiubDN4ZBlMnNZBf8N6Pq5uJZB2owwRNYb8RpIZCvwNgyoAB8dNWBW3AAZD',\n",
       "   'next': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&since&until=1642374857&__paging_token=enc_AdDTmugUyNZAEZBUMMTOgy1ZBeZBslXcER9ZACP9h6AcvUX30QXzdKethwWoiUfyZCrNvpvvDRNszA9NK1W9lvk4762q5HbCLJ5Jq36aNr9WscVGvx0aSoqzXV5SMOP0wj6jKVlZAoZD&__previous'}},\n",
       " 5: {'data': [{'created_time': '2022-01-16T02:31:29+0000',\n",
       "    'id': '10104327314119821_10103978097767191'},\n",
       "   {'created_time': '2022-01-12T00:35:00+0000',\n",
       "    'message': \"Get Over the Fear: How to Do Your First Handstand Hold (video linked in the comments)\\n\\nThe wall-facing handstand is basically an advanced plank! It does emphasize shoulder stability more than the standard plank.\\n\\nThese are the benefits of handstands, even if you have a desk job:\\n• They train your core and glutes to support a healthy back.\\n• They help you maintain good posture: To do a handstand, you need adequate overhead mobility and thoracic mobility, which we don't tend to challenge enough in our day to day activities (use it or lose it!).\\n• They strengthen the muscles that help improve posture and keep your shoulders pain-free, such as the rotator cuff, serratus anterior, and lower trapezius. \\n\\nSteps:\\n1. Keep your abs tight as you walk your hands and feet up into the handstand position.\\n2. As you hold, push the floor away from to keep your shoulder muscles active.\\n3. Ensure good core stability by keeping your ribs pulled towards your spine. In other words, maintain a good hollow body position. The muscles of the butt and front of the thighs should also be tense, not just the upper body and core.\\n4. While the goal is to bring your hands as close to the wall as you can, start in a more horizontal position if needed and gradually work towards a more vertical position as you improve strength and stability.\\nWhatever position you choose, always push the floor away and keep your ribs pulled towards your spine. \\n\\nIf you give this a try, leave a comment on how this goes for you.\",\n",
       "    'id': '10104327314119821_10103975075513811'},\n",
       "   {'created_time': '2022-01-09T16:44:00+0000',\n",
       "    'message': 'Kid humour by Justin Hua back when everyone used MSN messenger for status updates.',\n",
       "    'id': '10104327314119821_10103973452675991'},\n",
       "   {'created_time': '2022-01-08T18:01:49+0000',\n",
       "    'message': \"Just when I was hopeful the ice would melt away so I could walk without worrying about slipping, it's snowing again. \\n\\nI'll just have to get my daily steps inside.\",\n",
       "    'id': '10104327314119821_10103972773217631'},\n",
       "   {'created_time': '2022-01-04T05:24:18+0000',\n",
       "    'message': 'For my friends who are parents of  young kids :)',\n",
       "    'id': '10104327314119821_10103969805789381'},\n",
       "   {'created_time': '2022-01-03T17:25:34+0000',\n",
       "    'message': \"That time I put more makeup on Vivian T than she had used in her entire life before that. It's been a while since I've done the blue smokey eye on myself.\",\n",
       "    'id': '10104327314119821_10103969301989001'},\n",
       "   {'created_time': '2022-01-01T04:56:22+0000',\n",
       "    'message': 'It\\'s a new year. The time when the fitness industry likes to guilt you into buying their products and services. Or get you \"motivated\" to make a grand transformation by crushing yourself.\\n \\nThe reality is that for most people who struggle with fitness on top of career, family, and social life, this type of mindset does not lead to long lasting health change.\\n \\nHere\\'s what will work for these people:\\n✔️Approaching health and exercise with incremental sustainable changes instead of going all-in or not bothering at all. If you\\'re a type-A personality, I know this is hard!\\n✔️Instead thinking that a lack of \"motivation\" is what\\'s stopping them, they take a small step that provides evidence they are capable of making the change. You don\\'t need motivation for action; motivation can come AFTER action. It can literally be one squat. \\n \\nWorking out at home is not fun (especially in a cold garage). I never feel \"motivated\" to train. But every day, I reluctantly start training by massaging my shoulder with the lacrosse ball before going onto the next exercise. I tell myself that I don\\'t have to finish the prescribed sets and reps, as long as I get SOMETHING done (though I usually do). I don\\'t train to \"transform\" my body, but to take care of it, to practice challenging skills, and to feel happy about the physical feats I can do. And while I\\'ll never have a huge social media following, I hope I can be relatable to the average working adult who would otherwise not bother training their muscles.\\n \\nDo you feel guilty about your health habits? Could you reframe the situation to help you feel good about what you\\'re doing well, or to help you move closer to your goals?',\n",
       "    'id': '10104327314119821_10103967587719411'},\n",
       "   {'created_time': '2022-01-01T01:59:39+0000',\n",
       "    'message': 'New year, new handstand hold personal record. Hope it’s not a fluke!',\n",
       "    'id': '10104327314119821_10103967479521241'},\n",
       "   {'created_time': '2021-12-31T17:22:17+0000',\n",
       "    'message': \"How to Make Progress with Home Workouts: 4 Push Up Exercise Variations\\n\\nAs you get better at push ups, eventually you'd need to do way too many reps to get a good training effect. I'm all about being time-efficient, so instead of doing endless reps of the standard push up, here are 4 push up progressions that will help you get stronger and gain muscle while saving time:\\n👉Decline push up\\n👉Banded decline push up\\n👉Deficit decline push up\\n👉Banded deficit decline push up\\n \\nIn addition to saving time, you'll be leveraging science and physics with these push up variations that you can do at home without equipment aside from stuff around the house!\\n✔️Elevating the feet shifts more of your bodyweight to your upper body.\\n✔️The band provides additional resistance, but even better is that it is an accommodating resistance. In other words, it adds more weight in the positions where you are stronger so you are challenged uniformly throughout the movement (otherwise, it gets very easy as you reach the top).\\n✔️Elevating the hands as shown allows you to descend lower relative to the hands. Using a greater motion enhances muscle growth.\\n\\nWill you give any of these a try? Let me know how it goes!\\n#stem #science #technology #engineer #medicine #scientist #research #academic #homeworkout #vancouver #yvr #personaltrainer #kinesiology #workout\",\n",
       "    'id': '10104327314119821_10103967168274981'},\n",
       "   {'created_time': '2021-12-31T05:12:25+0000',\n",
       "    'message': 'Since gyms are closed, some of you strong folks may find this helpful\\n\\n',\n",
       "    'id': '10104327314119821_10103966922796921'},\n",
       "   {'created_time': '2021-12-29T04:17:57+0000',\n",
       "    'message': 'Exercise is a real fountain of youth that helps you defy time!\\n\\nhttps://examine.com/members/summaries/issue/december-2021/summary-9DKob0',\n",
       "    'id': '10104327314119821_10103965428626251'},\n",
       "   {'created_time': '2021-12-25T19:50:59+0000',\n",
       "    'message': 'Watching @nbcbrooklyn99 during handstands practice and got distracted by the hilarity of Captain Holt.',\n",
       "    'id': '10104327314119821_10103963089399081'},\n",
       "   {'created_time': '2021-12-24T22:30:34+0000',\n",
       "    'message': 'Why the scale goes crazy during the holidays: part 3/3.\\n \\nAside from holiday noms, some other things that increase scale weight that aren\\'t due to fat gain include:\\n- Water retention during the luteal phase of the menstrual cycle (i.e. the days before the period starts).\\n- Water retention due to stress. If you\\'re a little less stressed￼ now, you may even find the scale goes down!\\n- Water retention from certain medications.\\n \\nThis year has been my best year yet as stress has been at an all-time low, which has helped my body get objectively healthier (as confirmed with lab tests) despite no longer sticking with \"clean\" eating and putting on body fat. Did you learn something from this series? Any more questions? Comment below!',\n",
       "    'id': '10104327314119821_10103962563458071'},\n",
       "   {'created_time': '2021-12-24T00:12:24+0000',\n",
       "    'message': 'https://www.precisionnutrition.com/effects-of-stress-on-the-body-infographic',\n",
       "    'id': '10104327314119821_10103961922183191'},\n",
       "   {'created_time': '2021-12-23T23:32:48+0000',\n",
       "    'message': \"Why the scale goes crazy during the holidays: part 2/3.\\n \\nIt takes a surplus or deficit of ~3500 calories to gain or lose a pound of fat, which is more than what your average person consumes on an average day. Here are some explanations for large weight fluctuations that have nothing to do with true fat or muscle changes, but rather to do eating differently than normal during celebrations:\\n- Higher food residue in the digestive tract due to higher fibre intake.\\n- If you're constipated due to eating stuff you're not used to (like we did at the Indian buffet pictured), the food remaining in your gut will also add weight.\\n- Less time between the last meal and when you weigh yourself from late night eating.\\n \\nWhat's the largest weight fluctuation you've experienced from one day to another, and why did that happen? I once did some targeted food, hydration, and salt manipulation to reduce my scale weight by 3 kg in 1 week for a lifting competition. It had nothing to do with fat loss.\\n \\nIn part 3, I'll go over some reasons for weight fluctuations that are neither due to fat gain nor diet.\",\n",
       "    'id': '10104327314119821_10103961904094441'},\n",
       "   {'created_time': '2021-12-23T20:28:21+0000',\n",
       "    'message': 'My weightlifting coach Anthony Agtarap from Engineered Bodies Strength & Conditioning is doing some advocacy work and trying to get data on why gyms need to shut down when casinos and churches are not.\\n\\nIf you agree, please sign this petition to allow small gyms to open: https://www.change.org/p/allow-small-independent-gyms-in-bc-to-open?recruiter=1214191800&utm_source=share_petition&utm_medium=facebook&utm_campaign=psf_combo_share_initial&utm_term=petition_dashboard&recruited_by_id=18299360-dc7e-11eb-8458-9328a5621718&utm_content=fht-31796711-en-ca%3A2',\n",
       "    'id': '10104327314119821_10103961804988051'},\n",
       "   {'created_time': '2021-12-22T22:29:20+0000',\n",
       "    'message': 'Sent a letter to our Minister of Health, Adrian Dix. https://adrian.dix.mla.bcndpcaucus.ca/contact/\\n\\nIf you agree, please sign this petition to allow small gyms to open: https://www.change.org/p/allow-small-independent-gyms-in-bc-to-open?recruiter=1214191800&utm_source=share_petition&utm_medium=facebook&utm_campaign=psf_combo_share_initial&utm_term=petition_dashboard&recruited_by_id=18299360-dc7e-11eb-8458-9328a5621718&utm_content=fht-31796711-en-ca%3A2',\n",
       "    'id': '10104327314119821_10103961271746671'},\n",
       "   {'created_time': '2021-12-22T18:06:56+0000',\n",
       "    'message': 'Churches are allowed to continue services. They meet people’s spiritual and social needs, both of which support health. \\n\\nGyms and fitness centres allow people to train various aspects of fitness; they meet people’s physical health needs. Similar to churches, they ALSO help people meet their social needs. Many people also find that training in a fitness facility provides them a greater sense of purpose than simply doing random exercise. \\n\\nThe gym closures are taking away many people’s means of meeting their physical, social, existential, and financial needs. If churches and movie theatres can still operate with safety precautions, I fail to see why gyms are not. Especially the boutique gyms which are at risk of going bankrupt. \\n\\nPlease sign the petition so the Government of British Columbia will hear us out.',\n",
       "    'id': '10104327314119821_10103961149127401'},\n",
       "   {'created_time': '2021-12-21T23:40:00+0000',\n",
       "    'message': \"Why the scale goes crazy during the holidays: part 1/3.\\n \\nDo you get emotional (or simply curious) about the number on the scale fluctuating a couple (or more) pounds day to day?\\n \\nIt takes a surplus or deficit of ~3500 calories to gain or lose a pound of fat, which is unlikely to happen from a day or two. When we eat much differently than usual (e.g. due to holiday festivities), here are some explanations for large weight fluctuations that have nothing to do with true fat or muscle changes:\\n- Water retention due to higher salt intake than normal.\\n- Muscles being fuller with glycogen and water, e.g. due to higher carbohydrate intake. For every gram of carbohydrate stored in the muscle (glycogen), we store 3-4 g of water.\\n \\nI'm super grateful to be able to reconnect with with friends over food. In part 2, I'll cover some additional factors that make that scale weight spike up. Did anything in this post surprise you?\",\n",
       "    'id': '10104327314119821_10103960734697921'},\n",
       "   {'created_time': '2021-12-17T05:59:42+0000',\n",
       "    'message': 'Feels like I am at a plateau with hand balancing. But did you know performance and motor learning are not the same thing?',\n",
       "    'id': '10104327314119821_10103957435309921'},\n",
       "   {'created_time': '2021-12-14T19:36:06+0000',\n",
       "    'message': 'New toy',\n",
       "    'id': '10104327314119821_10103955698231041'},\n",
       "   {'created_time': '2021-12-05T06:57:42+0000',\n",
       "    'id': '10104327314119821_10103949690400781'},\n",
       "   {'created_time': '2021-12-05T06:57:26+0000',\n",
       "    'message': '💛',\n",
       "    'id': '10104327314119821_10103949690325931'}],\n",
       "  'paging': {'previous': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&since=1642300289&until&__previous=1&__paging_token=enc_AdBZC8AgTbFJQEmnGKfWIzlWW4nPX4uznPZAmNsPGwack6vY1gVhZAzYoI74GScYQ40nJzoYTQO6H25wOB1jZBZAy8M3TZCxpP3JNrH9ArcMzcOjk760bpD4mjUPNhdh1cPQ9ugF4ZD',\n",
       "   'next': 'https://graph.facebook.com/v15.0/10104327314119821/posts?access_token=EAAKEofVXnvEBAJvRKL6ZAuF8T5dcb648r3cSuVfbmKy7ezBI6YogipCPU5U5VyvjMZCk1nsTWd4TGlWP4ZAkdxd7Eg3fuKkI0IZC4NdEVVAZAxfMXSZC76RsO2O00wKKu5O1OHCSLNHhNfa8zYX5dYeONh7pNjV8WhGSZBrYHBI2JeZAaDPFvRzJXOJ9bZAyJk8qGmZC2h5WXwr6KpsNyISodY53XTirvHNIYZD&since&until=1638687446&__paging_token=enc_AdAO4nnVPzdicIaMdJcnQUsA6nA3wdcS1h0LL4Xdtqg76kR9WgXftPCOxoSZCzZCM5VhoCG1ZCZC2cbEdtaCsq3I61sDwmEOIviaJF35drWKZC7eo06Js1hzIBQjnafRJtzfgR04ZD&__previous'}}}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\raw'\n",
    "filename='my_fb_posts_5page_2023-01-12.sav'\n",
    "response_json_5p = loadpickle(filename, json_path)\n",
    "response_json_5p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-15 20:21:48+00:00</td>\n",
       "      <td>Too good to share. Too bad there's none on exe...</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20:21:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-13 19:50:47+00:00</td>\n",
       "      <td>It’s been 1 month since I finished my data sci...</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19:50:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-11 03:17:40+00:00</td>\n",
       "      <td>There was a time when my only exercise was run...</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>03:17:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  \\\n",
       "0 2023-01-15 20:21:48+00:00   \n",
       "1 2023-01-13 19:50:47+00:00   \n",
       "2 2023-01-11 03:17:40+00:00   \n",
       "\n",
       "                                                text        date  year  month  \\\n",
       "0  Too good to share. Too bad there's none on exe...  2023-01-15  2023      1   \n",
       "1  It’s been 1 month since I finished my data sci...  2023-01-13  2023      1   \n",
       "2  There was a time when my only exercise was run...  2023-01-11  2023      1   \n",
       "\n",
       "   day_of_week      time  \n",
       "0            6  20:21:48  \n",
       "1            4  19:50:47  \n",
       "2            2  03:17:40  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def process_post_df(df):\n",
    "    \"\"\"\n",
    "    Convert dates in the json-derived dataframe into different formats.\n",
    "    \"\"\"\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    regex_date = r'.+T'\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['timestamp'] = pd.to_datetime(df['created_time'])\n",
    "    df2['text'] = df['message']\n",
    "    df2['date'] = df2['timestamp'].dt.date\n",
    "    df2['year'] = df2['timestamp'].dt.year\n",
    "    df2['month'] = df2['timestamp'].dt.month\n",
    "    df2['day_of_week'] = df2['timestamp'].dt.dayofweek\n",
    "    df2['time'] = df2['timestamp'].dt.time\n",
    "    df2['time'] = df2['timestamp'].dt.time\n",
    "    return df2\n",
    "\n",
    "process_post_df(df_5p.head(3).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp      datetime64[ns, UTC]\n",
       "text                        object\n",
       "date                        object\n",
       "year                         int64\n",
       "month                        int64\n",
       "day_of_week                  int64\n",
       "time                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_post_df(df_5p.head(3).copy()).dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Photos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_user_photos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_photos(user_id, access_token, pages=5, filename=None,\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\raw',\n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim'):\n",
    "    user_id = str(user_id)\n",
    "    url_root = \"https://graph.facebook.com/v15.0/\"\n",
    "    url = f'{url_root}{user_id}/photos?type=uploaded&access_token={access_token}'\n",
    "    response_json_dict = dict()\n",
    "    df_list = []\n",
    "    for page in range(1,pages+1):\n",
    "        response = requests.get(url)\n",
    "        print('Response status code: ',response.status_code)\n",
    "        response_json_dict[page] = response.json()\n",
    "        df_list.append(json_normalize(response_json_dict[page], record_path='data'))\n",
    "        try:\n",
    "            url = response_json_dict[page]['paging']['next']\n",
    "        except: \n",
    "            pass\n",
    "    df = pd.concat(df_list)\n",
    "    print('Number of photos:',len(df))\n",
    "    if filename:\n",
    "        try:\n",
    "            save_csv(df,filename,csv_path)\n",
    "            savepickle(response_json_dict,filename,'sav',json_path)\n",
    "        except:\n",
    "            print('Unable to save outputs')\n",
    "    return df, response_json_dict\n",
    "# SH 2023-01-16 16:58 Need to update this so that:\n",
    "    # The URL of the last request is returned in case you want to request posts further back\n",
    "    # If it is the last page, it won't just keep making request with the same endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code:  200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [138], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_photos, response_json_photos \u001b[39m=\u001b[39m get_user_photos(user_id, access_token, pages\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [137], line 10\u001b[0m, in \u001b[0;36mget_user_photos\u001b[1;34m(user_id, access_token, pages, filename, json_path, csv_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m df_list \u001b[39m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,pages\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url)\n\u001b[0;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mResponse status code: \u001b[39m\u001b[39m'\u001b[39m,response\u001b[39m.\u001b[39mstatus_code)\n\u001b[0;32m     12\u001b[0m     response_json_dict[page] \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m         )\n\u001b[0;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\cloudEnv\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\cloudEnv\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\cloudEnv\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\cloudEnv\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\cloudEnv\\lib\\ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\cloudEnv\\lib\\ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_photos, response_json_photos = get_user_photos(user_id, access_token, pages=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-13T19:50:47+0000</td>\n",
       "      <td>It’s been 1 month since I finished my data sci...</td>\n",
       "      <td>10104329950835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-07T21:36:58+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104325301812501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-07T21:36:58+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104325301787551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-07T21:36:58+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104325301737651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-07T21:36:58+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104325301687751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-06T19:39:51+0000</td>\n",
       "      <td>What's your favourite app or wearable that hel...</td>\n",
       "      <td>10104324466511451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-03T20:34:34+0000</td>\n",
       "      <td>Gamify your goals\\n\\nDuolingo was one of the p...</td>\n",
       "      <td>10104322209175171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-12-30T02:06:59+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104318386994851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-12-30T02:06:59+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104318386959921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-12-27T07:56:46+0000</td>\n",
       "      <td>While my podcast feed is mostly filled with po...</td>\n",
       "      <td>10104316147467881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_time  \\\n",
       "0  2023-01-13T19:50:47+0000   \n",
       "1  2023-01-07T21:36:58+0000   \n",
       "2  2023-01-07T21:36:58+0000   \n",
       "3  2023-01-07T21:36:58+0000   \n",
       "4  2023-01-07T21:36:58+0000   \n",
       "5  2023-01-06T19:39:51+0000   \n",
       "6  2023-01-03T20:34:34+0000   \n",
       "7  2022-12-30T02:06:59+0000   \n",
       "8  2022-12-30T02:06:59+0000   \n",
       "9  2022-12-27T07:56:46+0000   \n",
       "\n",
       "                                                name                 id  \n",
       "0  It’s been 1 month since I finished my data sci...  10104329950835821  \n",
       "1                                                NaN  10104325301812501  \n",
       "2                                                NaN  10104325301787551  \n",
       "3                                                NaN  10104325301737651  \n",
       "4                                                NaN  10104325301687751  \n",
       "5  What's your favourite app or wearable that hel...  10104324466511451  \n",
       "6  Gamify your goals\\n\\nDuolingo was one of the p...  10104322209175171  \n",
       "7                                                NaN  10104318386994851  \n",
       "8                                                NaN  10104318386959921  \n",
       "9  While my podcast feed is mostly filled with po...  10104316147467881  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_photos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved:  C:/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/data/interim/my_fb_photos_2023-01-14.csv\n",
      "File saved:  C:/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/data/raw/my_fb_photos_2023-01-14.sav\n"
     ]
    }
   ],
   "source": [
    "json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\raw'\n",
    "csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim'\n",
    "filename='my_fb_photos_2023-01-14'\n",
    "save_csv(df_photos,filename,csv_path)\n",
    "savepickle(response_json_photos,filename,'sav',json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_response(df, response_json, filename,\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\raw',\n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim'):\n",
    "    \"\"\"\n",
    "    Save the data frame and json_response from the Facebook API request.\n",
    "    \"\"\"\n",
    "    save_csv(df,filename,csv_path)\n",
    "    savepickle(response_json,filename,'sav',json_path)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling AM's Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credentials.json\") as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "access_token = credentials['access_token']\n",
    "am_user_id = credentials['am_user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "Response status code:  200\n",
      "File saved:  C:/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/data/interim/AM_fb_posts_50page_2023-01-16.csv\n",
      "File saved:  C:/Users/silvh/OneDrive/lighthouse/portfolio-projects/online-PT-social-media-NLP/data/raw/AM_fb_posts_50page_2023-01-16.sav\n"
     ]
    }
   ],
   "source": [
    "df_50p, response_json_50p = get_user_post(am_user_id, access_token, pages=50, \n",
    "    filename='AM_fb_posts_50page_2023-01-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>message</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-04T15:06:57+0000</td>\n",
       "      <td>Charity event in Roscommon - Saturday 7th Janu...</td>\n",
       "      <td>545505737609234_537318481761293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-29T18:55:49+0000</td>\n",
       "      <td>Nutrition and Training Workshop 💪\\n\\nMy ethos ...</td>\n",
       "      <td>545505737609234_509802061179602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-04T22:39:50+0000</td>\n",
       "      <td>‘Why your metabolism is not broken’\\n\\nReally ...</td>\n",
       "      <td>545505737609234_467470882079387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-18T20:34:20+0000</td>\n",
       "      <td>Anyone else on TikTok? 🎯</td>\n",
       "      <td>545505737609234_455027709990371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-18T06:19:36+0000</td>\n",
       "      <td>Completed it mate ✅</td>\n",
       "      <td>545505737609234_454597556700053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-09-15T19:20:59+0000</td>\n",
       "      <td>Anyone doing Blackmores - marathon/half or 10km?</td>\n",
       "      <td>545505737609234_452894803536995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-08-23T08:49:02+0000</td>\n",
       "      <td>We had the most stunning time in Fiji 🇫🇯\\n\\nHa...</td>\n",
       "      <td>545505737609234_436768241816318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-08-16T02:04:54+0000</td>\n",
       "      <td>If you can’t beat ‘em, join em 🍸</td>\n",
       "      <td>545505737609234_431993685627107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-08-14T23:22:47+0000</td>\n",
       "      <td>Bingo Loco 🫶</td>\n",
       "      <td>545505737609234_431270869032722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-08-10T21:13:31+0000</td>\n",
       "      <td>First night out out in awhile 🫶</td>\n",
       "      <td>545505737609234_428638645962611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-08-01T05:12:00+0000</td>\n",
       "      <td>Christmas in July 🎄❤️</td>\n",
       "      <td>545505737609234_422429943250148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-06-02T20:18:43+0000</td>\n",
       "      <td>❤️❤️❤️</td>\n",
       "      <td>545505737609234_382682757224867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-05-29T08:12:02+0000</td>\n",
       "      <td>I’d love to see what you’d caption this 😅\\n\\n⬇...</td>\n",
       "      <td>545505737609234_379552780871198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-02-07T19:29:39+0000</td>\n",
       "      <td>Last of the comp Spam I promise 🤣</td>\n",
       "      <td>545505737609234_307769374716206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-02-02T19:07:05+0000</td>\n",
       "      <td>Preparing for our first external comp 🥳</td>\n",
       "      <td>545505737609234_304784511681359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-01-29T10:16:48+0000</td>\n",
       "      <td>Me and Lillie Allen representing the ladies in...</td>\n",
       "      <td>545505737609234_302093805283763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-01-29T10:16:04+0000</td>\n",
       "      <td>First In House Comp of the year 🙌</td>\n",
       "      <td>545505737609234_302093515283792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-01-27T20:33:16+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>545505737609234_301203155372828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-01-03T06:40:22+0000</td>\n",
       "      <td>Expires Tonight. Invitation for women who are ...</td>\n",
       "      <td>545505737609234_286353056857838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-12-19T19:15:22+0000</td>\n",
       "      <td>Run up to Christmas in Sydney 🙏</td>\n",
       "      <td>545505737609234_277533934406417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-11-16T07:47:31+0000</td>\n",
       "      <td>Right who here Squats???\\n\\nI'm going to be ho...</td>\n",
       "      <td>545505737609234_257020856457725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-11-09T06:31:04+0000</td>\n",
       "      <td>Hey All,\\n\\n- Are you clueless about resistanc...</td>\n",
       "      <td>545505737609234_252527030240441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-11-03T19:17:52+0000</td>\n",
       "      <td>Any goals you'd like to achieve by the end of ...</td>\n",
       "      <td>545505737609234_249141407245670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-11-02T23:38:46+0000</td>\n",
       "      <td>Anyone out there still use a written diary or ...</td>\n",
       "      <td>545505737609234_248645757295235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-01T18:41:07+0000</td>\n",
       "      <td>What have you done recently that made you real...</td>\n",
       "      <td>545505737609234_247962924030185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-06T23:21:49+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>545505737609234_230971169062694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-29T05:20:58+0000</td>\n",
       "      <td>Last Chance people, if you're interested in my...</td>\n",
       "      <td>545505737609234_226206536205824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-20T20:20:52+0000</td>\n",
       "      <td>If anyone is interested in getting some help a...</td>\n",
       "      <td>545505737609234_220738340085977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-09T06:51:17+0000</td>\n",
       "      <td>𝙄𝙢𝙖𝙜𝙞𝙣𝙚 𝙉𝙊𝙏 𝙛𝙚𝙖𝙧𝙞𝙣𝙜 𝙖 𝙗𝙞𝙠𝙞𝙣𝙞 👙 ✖\\n.\\n.\\n𝐈𝐦𝐚𝐠𝐢𝐧...</td>\n",
       "      <td>545505737609234_213187764174368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-09-02T06:56:40+0000</td>\n",
       "      <td>One Space left for Monday 6th. If you're inter...</td>\n",
       "      <td>545505737609234_208650987961379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-08-31T05:28:24+0000</td>\n",
       "      <td>28 Day Kickstarter \\n\\n‼️I'm looking for 5 lad...</td>\n",
       "      <td>545505737609234_207336971426114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-08-30T05:55:19+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>545505737609234_206695284823616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-08-28T10:04:22+0000</td>\n",
       "      <td>Crossfit or body-building? 🤔</td>\n",
       "      <td>545505737609234_205475808278897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-08-18T04:21:26+0000</td>\n",
       "      <td>I did Front Foot Elevated Split Squats today f...</td>\n",
       "      <td>545505737609234_198907928935685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-08-16T09:27:13+0000</td>\n",
       "      <td>If you're not already involved, get into this ...</td>\n",
       "      <td>545505737609234_197756439050834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-08-13T01:30:43+0000</td>\n",
       "      <td>Anyone interested in why you don't achieve res...</td>\n",
       "      <td>545505737609234_195604925932652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-08-10T23:06:29+0000</td>\n",
       "      <td>Favourite high protein breakfast? Minus eggs.....</td>\n",
       "      <td>545505737609234_194233939403084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-08-01T07:53:38+0000</td>\n",
       "      <td>‼️I'm looking for 5 ladies who want to become ...</td>\n",
       "      <td>545505737609234_187816276711517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-07-30T07:57:14+0000</td>\n",
       "      <td>Movie Suggestions? 🤔</td>\n",
       "      <td>545505737609234_186517523508059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-07-19T04:38:56+0000</td>\n",
       "      <td>https://www.coachmcloone.com/\\n\\nFinally have ...</td>\n",
       "      <td>545505737609234_178816784278133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-07-16T10:00:08+0000</td>\n",
       "      <td>If you knew Covid was coming.\\n\\nWhat would yo...</td>\n",
       "      <td>545505737609234_176622584497553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-07-01T06:13:39+0000</td>\n",
       "      <td>‼️I'm looking for 5 ladies who want to become ...</td>\n",
       "      <td>545505737609234_166417258851419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-06-30T22:53:38+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>545505737609234_166240302202448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-06-26T11:51:06+0000</td>\n",
       "      <td>Anyone interested in gaining some nutrition kn...</td>\n",
       "      <td>545505737609234_163057309187414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-06-16T04:22:08+0000</td>\n",
       "      <td>What are people's favourite FB Groups to be ap...</td>\n",
       "      <td>545505737609234_156435016516310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-06-07T10:48:27+0000</td>\n",
       "      <td>https://www.facebook.com/100000504382136/posts...</td>\n",
       "      <td>545505737609234_150885450404600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-05-11T05:30:40+0000</td>\n",
       "      <td>Aoibheann's Experience:\\n.\\n.\\nI started the p...</td>\n",
       "      <td>545505737609234_133207925505686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-05-06T04:43:38+0000</td>\n",
       "      <td>If you could eat one food and still achieve yo...</td>\n",
       "      <td>545505737609234_129813195845159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-03T00:12:56+0000</td>\n",
       "      <td>‼️I'm looking for 5 ladies who want to become ...</td>\n",
       "      <td>545505737609234_128188466007632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-27T04:45:39+0000</td>\n",
       "      <td>Snack Options ✅\\n.\\n.\\nA question I get so fre...</td>\n",
       "      <td>545505737609234_126493706177108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-12T00:33:05+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>545505737609234_109633854529760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-12T00:25:29+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>545505737609234_109630651196747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1991-02-12T08:00:00+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>545505737609234_109626264530519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_time  \\\n",
       "0   2023-01-04T15:06:57+0000   \n",
       "1   2022-11-29T18:55:49+0000   \n",
       "2   2022-10-04T22:39:50+0000   \n",
       "3   2022-09-18T20:34:20+0000   \n",
       "4   2022-09-18T06:19:36+0000   \n",
       "5   2022-09-15T19:20:59+0000   \n",
       "6   2022-08-23T08:49:02+0000   \n",
       "7   2022-08-16T02:04:54+0000   \n",
       "8   2022-08-14T23:22:47+0000   \n",
       "9   2022-08-10T21:13:31+0000   \n",
       "10  2022-08-01T05:12:00+0000   \n",
       "11  2022-06-02T20:18:43+0000   \n",
       "12  2022-05-29T08:12:02+0000   \n",
       "13  2022-02-07T19:29:39+0000   \n",
       "14  2022-02-02T19:07:05+0000   \n",
       "15  2022-01-29T10:16:48+0000   \n",
       "16  2022-01-29T10:16:04+0000   \n",
       "17  2022-01-27T20:33:16+0000   \n",
       "18  2022-01-03T06:40:22+0000   \n",
       "19  2021-12-19T19:15:22+0000   \n",
       "20  2021-11-16T07:47:31+0000   \n",
       "21  2021-11-09T06:31:04+0000   \n",
       "22  2021-11-03T19:17:52+0000   \n",
       "23  2021-11-02T23:38:46+0000   \n",
       "0   2021-11-01T18:41:07+0000   \n",
       "1   2021-10-06T23:21:49+0000   \n",
       "2   2021-09-29T05:20:58+0000   \n",
       "3   2021-09-20T20:20:52+0000   \n",
       "4   2021-09-09T06:51:17+0000   \n",
       "5   2021-09-02T06:56:40+0000   \n",
       "6   2021-08-31T05:28:24+0000   \n",
       "7   2021-08-30T05:55:19+0000   \n",
       "8   2021-08-28T10:04:22+0000   \n",
       "9   2021-08-18T04:21:26+0000   \n",
       "10  2021-08-16T09:27:13+0000   \n",
       "11  2021-08-13T01:30:43+0000   \n",
       "12  2021-08-10T23:06:29+0000   \n",
       "13  2021-08-01T07:53:38+0000   \n",
       "14  2021-07-30T07:57:14+0000   \n",
       "15  2021-07-19T04:38:56+0000   \n",
       "16  2021-07-16T10:00:08+0000   \n",
       "17  2021-07-01T06:13:39+0000   \n",
       "18  2021-06-30T22:53:38+0000   \n",
       "19  2021-06-26T11:51:06+0000   \n",
       "20  2021-06-16T04:22:08+0000   \n",
       "21  2021-06-07T10:48:27+0000   \n",
       "22  2021-05-11T05:30:40+0000   \n",
       "23  2021-05-06T04:43:38+0000   \n",
       "0   2021-05-03T00:12:56+0000   \n",
       "1   2021-04-27T04:45:39+0000   \n",
       "2   2021-03-12T00:33:05+0000   \n",
       "3   2021-03-12T00:25:29+0000   \n",
       "4   1991-02-12T08:00:00+0000   \n",
       "\n",
       "                                              message  \\\n",
       "0   Charity event in Roscommon - Saturday 7th Janu...   \n",
       "1   Nutrition and Training Workshop 💪\\n\\nMy ethos ...   \n",
       "2   ‘Why your metabolism is not broken’\\n\\nReally ...   \n",
       "3                            Anyone else on TikTok? 🎯   \n",
       "4                                 Completed it mate ✅   \n",
       "5    Anyone doing Blackmores - marathon/half or 10km?   \n",
       "6   We had the most stunning time in Fiji 🇫🇯\\n\\nHa...   \n",
       "7                    If you can’t beat ‘em, join em 🍸   \n",
       "8                                        Bingo Loco 🫶   \n",
       "9                     First night out out in awhile 🫶   \n",
       "10                              Christmas in July 🎄❤️   \n",
       "11                                             ❤️❤️❤️   \n",
       "12  I’d love to see what you’d caption this 😅\\n\\n⬇...   \n",
       "13                  Last of the comp Spam I promise 🤣   \n",
       "14            Preparing for our first external comp 🥳   \n",
       "15  Me and Lillie Allen representing the ladies in...   \n",
       "16                  First In House Comp of the year 🙌   \n",
       "17                                                NaN   \n",
       "18  Expires Tonight. Invitation for women who are ...   \n",
       "19                    Run up to Christmas in Sydney 🙏   \n",
       "20  Right who here Squats???\\n\\nI'm going to be ho...   \n",
       "21  Hey All,\\n\\n- Are you clueless about resistanc...   \n",
       "22  Any goals you'd like to achieve by the end of ...   \n",
       "23  Anyone out there still use a written diary or ...   \n",
       "0   What have you done recently that made you real...   \n",
       "1                                                 NaN   \n",
       "2   Last Chance people, if you're interested in my...   \n",
       "3   If anyone is interested in getting some help a...   \n",
       "4   𝙄𝙢𝙖𝙜𝙞𝙣𝙚 𝙉𝙊𝙏 𝙛𝙚𝙖𝙧𝙞𝙣𝙜 𝙖 𝙗𝙞𝙠𝙞𝙣𝙞 👙 ✖\\n.\\n.\\n𝐈𝐦𝐚𝐠𝐢𝐧...   \n",
       "5   One Space left for Monday 6th. If you're inter...   \n",
       "6   28 Day Kickstarter \\n\\n‼️I'm looking for 5 lad...   \n",
       "7                                                 NaN   \n",
       "8                        Crossfit or body-building? 🤔   \n",
       "9   I did Front Foot Elevated Split Squats today f...   \n",
       "10  If you're not already involved, get into this ...   \n",
       "11  Anyone interested in why you don't achieve res...   \n",
       "12  Favourite high protein breakfast? Minus eggs.....   \n",
       "13  ‼️I'm looking for 5 ladies who want to become ...   \n",
       "14                               Movie Suggestions? 🤔   \n",
       "15  https://www.coachmcloone.com/\\n\\nFinally have ...   \n",
       "16  If you knew Covid was coming.\\n\\nWhat would yo...   \n",
       "17  ‼️I'm looking for 5 ladies who want to become ...   \n",
       "18                                                NaN   \n",
       "19  Anyone interested in gaining some nutrition kn...   \n",
       "20  What are people's favourite FB Groups to be ap...   \n",
       "21  https://www.facebook.com/100000504382136/posts...   \n",
       "22  Aoibheann's Experience:\\n.\\n.\\nI started the p...   \n",
       "23  If you could eat one food and still achieve yo...   \n",
       "0   ‼️I'm looking for 5 ladies who want to become ...   \n",
       "1   Snack Options ✅\\n.\\n.\\nA question I get so fre...   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "\n",
       "                                 id  \n",
       "0   545505737609234_537318481761293  \n",
       "1   545505737609234_509802061179602  \n",
       "2   545505737609234_467470882079387  \n",
       "3   545505737609234_455027709990371  \n",
       "4   545505737609234_454597556700053  \n",
       "5   545505737609234_452894803536995  \n",
       "6   545505737609234_436768241816318  \n",
       "7   545505737609234_431993685627107  \n",
       "8   545505737609234_431270869032722  \n",
       "9   545505737609234_428638645962611  \n",
       "10  545505737609234_422429943250148  \n",
       "11  545505737609234_382682757224867  \n",
       "12  545505737609234_379552780871198  \n",
       "13  545505737609234_307769374716206  \n",
       "14  545505737609234_304784511681359  \n",
       "15  545505737609234_302093805283763  \n",
       "16  545505737609234_302093515283792  \n",
       "17  545505737609234_301203155372828  \n",
       "18  545505737609234_286353056857838  \n",
       "19  545505737609234_277533934406417  \n",
       "20  545505737609234_257020856457725  \n",
       "21  545505737609234_252527030240441  \n",
       "22  545505737609234_249141407245670  \n",
       "23  545505737609234_248645757295235  \n",
       "0   545505737609234_247962924030185  \n",
       "1   545505737609234_230971169062694  \n",
       "2   545505737609234_226206536205824  \n",
       "3   545505737609234_220738340085977  \n",
       "4   545505737609234_213187764174368  \n",
       "5   545505737609234_208650987961379  \n",
       "6   545505737609234_207336971426114  \n",
       "7   545505737609234_206695284823616  \n",
       "8   545505737609234_205475808278897  \n",
       "9   545505737609234_198907928935685  \n",
       "10  545505737609234_197756439050834  \n",
       "11  545505737609234_195604925932652  \n",
       "12  545505737609234_194233939403084  \n",
       "13  545505737609234_187816276711517  \n",
       "14  545505737609234_186517523508059  \n",
       "15  545505737609234_178816784278133  \n",
       "16  545505737609234_176622584497553  \n",
       "17  545505737609234_166417258851419  \n",
       "18  545505737609234_166240302202448  \n",
       "19  545505737609234_163057309187414  \n",
       "20  545505737609234_156435016516310  \n",
       "21  545505737609234_150885450404600  \n",
       "22  545505737609234_133207925505686  \n",
       "23  545505737609234_129813195845159  \n",
       "0   545505737609234_128188466007632  \n",
       "1   545505737609234_126493706177108  \n",
       "2   545505737609234_109633854529760  \n",
       "3   545505737609234_109630651196747  \n",
       "4   545505737609234_109626264530519  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_50p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_post(user_id, access_token, pages=5, filename=None,\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\raw',\n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim'):\n",
    "    user_id = str(user_id)\n",
    "    url_root = \"https://graph.facebook.com/v15.0/\"\n",
    "    url = f'{url_root}{user_id}/posts?access_token={access_token}'\n",
    "    response_json_dict = dict()\n",
    "    df_list = []\n",
    "    for page in range(1,pages+1):\n",
    "        response = requests.get(url)\n",
    "        print('Request URL:', url)\n",
    "        print('Response status code: ',response.status_code)\n",
    "        response_json_dict[page] = response.json()\n",
    "        df_list.append(json_normalize(response_json_dict[page], record_path='data'))\n",
    "        try:\n",
    "            url = response_json_dict[page]['paging']['next']\n",
    "        except: \n",
    "            pass\n",
    "    df = pd.concat(df_list)\n",
    "    print('Number of posts:',len(df))\n",
    "    if filename:\n",
    "        try:\n",
    "            save_csv(df,filename,csv_path)\n",
    "            savepickle(response_json_dict,filename,'sav',json_path)\n",
    "        except:\n",
    "            print('Unable to save outputs')\n",
    "    return df, response_json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_photos_am, response_json_photos_am = get_user_photos(am_user_id, access_token, pages=50,\n",
    "    filename='AM_fb_photos_50page_2023-01-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-04T15:06:57+0000</td>\n",
       "      <td>Charity event in Roscommon - Saturday 7th Janu...</td>\n",
       "      <td>537318171761324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-29T18:55:49+0000</td>\n",
       "      <td>Nutrition and Training Workshop 💪\\n\\nMy ethos ...</td>\n",
       "      <td>509802031179605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-04T22:39:50+0000</td>\n",
       "      <td>‘Why your metabolism is not broken’\\n\\nReally ...</td>\n",
       "      <td>467470492079426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-18T06:19:36+0000</td>\n",
       "      <td>Completed it mate ✅</td>\n",
       "      <td>454597496700059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-23T08:49:02+0000</td>\n",
       "      <td>We had the most stunning time in Fiji 🇫🇯\\n\\nHa...</td>\n",
       "      <td>436768148482994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-12T00:33:05+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109633777863101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-12T00:25:31+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109630624530083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-27T04:45:39+0000</td>\n",
       "      <td>Snack Options ✅\\n.\\n.\\nA question I get so fre...</td>\n",
       "      <td>126493682843777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-12T00:33:05+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109633777863101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-12T00:25:31+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109630624530083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_time  \\\n",
       "0   2023-01-04T15:06:57+0000   \n",
       "1   2022-11-29T18:55:49+0000   \n",
       "2   2022-10-04T22:39:50+0000   \n",
       "3   2022-09-18T06:19:36+0000   \n",
       "4   2022-08-23T08:49:02+0000   \n",
       "..                       ...   \n",
       "1   2021-03-12T00:33:05+0000   \n",
       "2   2021-03-12T00:25:31+0000   \n",
       "0   2021-04-27T04:45:39+0000   \n",
       "1   2021-03-12T00:33:05+0000   \n",
       "2   2021-03-12T00:25:31+0000   \n",
       "\n",
       "                                                 name               id  \n",
       "0   Charity event in Roscommon - Saturday 7th Janu...  537318171761324  \n",
       "1   Nutrition and Training Workshop 💪\\n\\nMy ethos ...  509802031179605  \n",
       "2   ‘Why your metabolism is not broken’\\n\\nReally ...  467470492079426  \n",
       "3                                 Completed it mate ✅  454597496700059  \n",
       "4   We had the most stunning time in Fiji 🇫🇯\\n\\nHa...  436768148482994  \n",
       "..                                                ...              ...  \n",
       "1                                                 NaN  109633777863101  \n",
       "2                                                 NaN  109630624530083  \n",
       "0   Snack Options ✅\\n.\\n.\\nA question I get so fre...  126493682843777  \n",
       "1                                                 NaN  109633777863101  \n",
       "2                                                 NaN  109630624530083  \n",
       "\n",
       "[194 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_photos_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'537318171761324'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "# df_photos_am.loc[index,\"id\"]\n",
    "df_photos_am.reset_index(drop=True).loc[0,'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo(df_photos, index, access_token=access_token, filename=None,\n",
    "    path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim\\individual_photo_data'):\n",
    "    \"\"\"\n",
    "    Get the url for the photo. This requires that the access token be active for the user of the photo.\n",
    "    Parameters:\n",
    "        - df_photos: DataFrame containing the API response.\n",
    "        - index (int or list): Index in df_photos for which to obtain the url.\n",
    "    Returns: URL for the photo.\n",
    "    \"\"\"\n",
    "    df_photos.reset_index(drop=True, inplace=True)\n",
    "    url_root = \"https://graph.facebook.com/v15.0/\"\n",
    "    index_list = []\n",
    "    url_list = []\n",
    "    index_list.append(index)\n",
    "    for index in index_list:\n",
    "        request_url = f'{url_root}{str(df_photos.reset_index(drop=True).loc[index,\"id\"])}/picture?access_token='\n",
    "        print('Request URL without access token:', request_url)\n",
    "        request_url += access_token\n",
    "        response = requests.get(request_url)\n",
    "        print('Response status code: ',response.status_code)\n",
    "        url_list.append(response.request.url)\n",
    "    if filename:\n",
    "        try:\n",
    "            savepickle(url_list,filename+'_picture_url_'+str(index),'sav',json_path)\n",
    "            savepickle(url_list,filename+'_api_response_'+str(index),'sav',json_path)\n",
    "        except:\n",
    "            print('Unable to save outputs')\n",
    "\n",
    "    return url_list, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list, response = get_photo(df_photos, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://scontent.fcxh3-1.fna.fbcdn.net/v/t39.30808-6/325443079_709033990789318_5257377445815459026_n.jpg?stp=cp1_dst-jpg_p960x960&_nc_cat=110&ccb=1-7&_nc_sid=453a68&_nc_ohc=UhhHUM1TfuQAX95CI46&_nc_ht=scontent.fcxh3-1.fna&edm=AIv30VUEAAAA&oh=00_AfAzjFiZEmfvHgXEU29sj6ue-bcNRBP9rxz4JEsFkbYgtw&oe=63CB06AC']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request URL without access token: https://graph.facebook.com/v15.0/537318171761324/picture?access_token=\n",
      "Response status code:  400\n"
     ]
    }
   ],
   "source": [
    "url_list_am0, response_am0 = get_photo(df_photos_am, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_media(user_id, access_token, pages=5, type='videos',filename=None,\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\raw',\n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim'):\n",
    "\n",
    "    \"\"\"\n",
    "    Parmeters:\n",
    "        - type ('videos' (default) or 'photos')\n",
    "    \"\"\"\n",
    "    user_id = str(user_id)\n",
    "    url_root = \"https://graph.facebook.com/v15.0/\"\n",
    "    url = f'{url_root}{user_id}/{type}?type=uploaded&access_token={access_token}'\n",
    "    response_json_dict = dict()\n",
    "    df_list = []\n",
    "    for page in range(1,pages+1):\n",
    "        response = requests.get(url)\n",
    "        print('Request URL:', url)\n",
    "        print('Response status code: ',response.status_code)\n",
    "        response_json_dict[page] = response.json()\n",
    "        df_list.append(json_normalize(response_json_dict[page], record_path='data'))\n",
    "        try:\n",
    "            url = response_json_dict[page]['paging']['next']\n",
    "        except: \n",
    "            pass\n",
    "    df = pd.concat(df_list)\n",
    "    print('Number of photos:',len(df))\n",
    "    if filename:\n",
    "        try:\n",
    "            save_csv(df,filename,csv_path)\n",
    "            savepickle(response_json_dict,filename,'sav',json_path)\n",
    "        except:\n",
    "            print('Unable to save outputs')\n",
    "    return df, response_json_dict\n",
    "\n",
    "df_videos_am, response_json_videos_am = get_user_media(am_user_id, access_token, pages=50,\n",
    "    filename='AM_fb_videos_50page_2023-01-16')\n",
    "df_videos_am\n",
    "\n",
    "# SH 2023-01-16 16:01 Error message using Graph API explorer:\n",
    "    # \"(#10) This endpoint requires the 'pages_read_engagement' permission or the 'Page Public Content Access' feature. Refer to https://developers.facebook.com/docs/apps/review/login-permissions#manage-pages and https://developers.facebook.com/docs/apps/review/feature#reference-PAGES_ACCESS for details.\","
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a Long-Lived User Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credentials.json\") as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "access_token = credentials['access_token']\n",
    "app_id = credentials['app_id']\n",
    "app_secret = credentials['app_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code:  200\n",
      "Updated token expiry: 2023-03-18 21:09\n",
      "New credentials file created: credentials_long_lived.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def prolong_access_token(credentials_json='credentials.json', access_token_key='access_token', \n",
    "    new_credentials_filename='credentials_long_lived.json'):\n",
    "    \"\"\"\n",
    "    - Convert an access token to a Long-Lived User Access Token, which should last 60 days instead\n",
    "    of 2 hours. \n",
    "    - Print the date and time of updated access_token expiry.\n",
    "    - Create a new credentials JSON file with the Long-Lived User Access Token.\n",
    "\n",
    "    Parameters:\n",
    "        - credentials.json : JSON file containing the following fields:\n",
    "            - 'access_token' or other key: User access token.\n",
    "            - 'app_id'\n",
    "            - 'app_secret'\n",
    "        - access_token_key (str): Key to the relevant access_token in the \n",
    "            JSON file if different from 'access_token'\n",
    "        - new_credentials_filename (str): Filename for saving the credentials file \n",
    "            with the long-lived user access token.\n",
    "    Returns:\n",
    "        - token_response: JSON object containing API GET response.\n",
    "\n",
    "    Relevant API documentation:\n",
    "    https://developers.facebook.com/docs/facebook-login/guides/access-tokens/get-long-lived\n",
    "    \"\"\"\n",
    "    # Retrieve credentials\n",
    "    with open(\"credentials.json\") as f:\n",
    "        credentials = json.load(f)\n",
    "    access_token = credentials[access_token_key]\n",
    "    app_id = credentials['app_id']\n",
    "    app_secret = credentials['app_secret']\n",
    "\n",
    "    # Make API request: Query the GET oauth/access_token endpoint\n",
    "    url_root = \"https://graph.facebook.com/v15.0/oauth/access_token\"\n",
    "    request_url = f'{url_root}?grant_type=fb_exchange_token&client_id={app_id}&client_secret={app_secret}&fb_exchange_token={access_token}'\n",
    "    response = requests.get(request_url)\n",
    "    print('Response status code: ',response.status_code)\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "        response_json['request_url'] = request_url\n",
    "        try:\n",
    "            new_access_token = response_json['access_token']\n",
    "            credentials[access_token_key] = new_access_token\n",
    "            time_to_expiry = timedelta(seconds=response_json['expires_in'])\n",
    "            now = datetime.now()\n",
    "            credentials['token_expiry'] = (datetime.now() + time_to_expiry).strftime(\"%Y-%m-%d %H:%M\")\n",
    "            print('Updated token expiry:', credentials['token_expiry'])\n",
    "            with open(new_credentials_filename,'w') as json_file:\n",
    "                json.dump(credentials, json_file)\n",
    "                print('New credentials file created:', new_credentials_filename)\n",
    "        except:\n",
    "            print('Unable to save new credentials; check request response')\n",
    "        return response_json\n",
    "    except:\n",
    "        print('Unable to get response JSON; check request response')\n",
    "        return response\n",
    "\n",
    "token_response = prolong_access_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the new credentials file loads properly\n",
    "new_credentials_filename='credentials_long_lived.json'\n",
    "\n",
    "with open(new_credentials_filename) as json_file:\n",
    "    credentials2 = json.load(json_file)\n",
    "credentials2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get group feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_response = prolong_access_token(access_token_key='am_access_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint for Strong and Sassy group\n",
    "group_feed_url = \"https://graph.facebook.com/v15.0/2139238999669147/feed?access_token=\"+access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_feed(credentials_json='credentials.json', group_id_key='SSC_group_id', \n",
    "    access_token_key='am_access_token',\n",
    "    json_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\raw',\n",
    "    csv_path=r'C:\\Users\\silvh\\OneDrive\\lighthouse\\portfolio-projects\\online-PT-social-media-NLP\\data\\interim'):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - credentials.json : JSON file containing the required credentials:\n",
    "            - group_id for the Facebook group.\n",
    "            - access_token for the user.\n",
    "        - group_id_key and access_token_key (str): Keys to the relevant group_id and access_token in the \n",
    "            JSON file.\n",
    "    Returns:\n",
    "        - \n",
    "    \"\"\"\n",
    "    # Retrieve credentials\n",
    "    with open(\"credentials.json\") as f:\n",
    "        credentials = json.load(f)\n",
    "    access_token = credentials[access_token_key]\n",
    "    group_id = credentials[group_id_key]\n",
    "\n",
    "    # Make API request:\n",
    "    url_root = \"https://graph.facebook.com/v15.0/\"\n",
    "    url = f'{url_root}{group_id}/feed?access_token={access_token}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86576fc1f72bb8252e2f1578cc878ed2c12b40840637cdef083c8fb979cf67d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
